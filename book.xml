<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<?asciidoc-toc?>
<?asciidoc-numbered?>

<article lang="en">
<articleinfo>
    <title>Continuous Enterprise Development in Java</title>
</articleinfo>
<section id="_prélude">
<title>Prélude</title>
<simpara><emphasis>« La simplicité est la sophistication suprême.» - Léonard De Vinci</emphasis></simpara>
<simpara>Le développement de logiciel pour le web moderne continue à évoluer à très grande vitesse. Ces dernières années nous avons vu l'état du client migrer vers le serveur avant de revenir en arrière. Malgré les services rendu par JavaScript, deux ingénieurs donneront probablement trois avis différents sur ses mérites. L&#8217;arrivée d&#8217;HTML5 s&#8217;accompagne du support d&#8217;une armada de contenus riches et de la concurrence directement dans le navigateur. Le modèle de données relationnel, valide depuis plus de quarante ans, n&#8217;est plus à la mode remplacé par les systèmes NoSQL pleins de morgue. Nos systèmes de gestion de configuration ont été remanié en profondeur tant du point de vue de l&#8217;implémentation que du paradigme.</simpara>
<simpara>Nos outils deviennent des prescriptions pour un buffet en perpétuel changement, choisir parmi cette montagne de possibilités est un exercice vertigineux.</simpara>
<simpara>En même temps, les ingénieurs font toujours face aux mêmes défis soulevés par la réalisation d&#8217;un proramme multi-utilisateur; nous aimons que notre code soit élégant et maintenable. Nous avons besoin qu&#8217;il s&#8217;exécute de manière efficace et sécurisée. Nous devons nous assurer qu&#8217;il est correct.</simpara>
<simpara>Dans le monde Java, de nombreuses réponses ont été apportées par un jeu de spécifications regroupées sous le titre <emphasis>Java Enterprise Edition</emphasis>.  Le but fondamental ce cet effort est toujours présent : cacher la complexité syntaxique inhérente au développement logiciel et essayer de fournir un modèle standard clair sur lequel construire le logiciel. En d&#8217;autres termes, la Plateforme JAVA EE est une trousse à outils en évolution, mais qui reste faillible.</simpara>
<simpara>Donc, il y a quelques années nous avons décidé de remplir certains des trous non spécifiés par Java EE et nous nous sommes retrouvés aux commandes d&#8217;un framework de test qui inspira notre imagination et se trouva beaucoup plus polyvalent que nous ne l&#8217;avions envisagé. Alors que nous donnions corps à nos idées afin de partager au mieux les leçons que nous avions apprises, it devint clair que nous n&#8217;avions pas besoin de documenter une  technologie en particulier. C&#8217;est d&#8217;une carte cohérente pour naviguer dans les eaux troubles de Java EE, ses frameworks et ses services dont ont besoin les développeurs.</simpara>
<simpara>Ce teste ne décrit pas une spécification. Ces tomes peuvent être obtenus par ailleurs car nous avons découvert que cela avait peu de sens que de commencer notre apprentissage par les Solutions.</simpara>
<simpara>Au lieu de cela, commençons par les Problèmes.  C&#8217;est au travers de cas d&#8217;utilisation que nous appréhendrons le développement testable Java d&#8217;entreprise. Chaque chapitre, après un peu de théorie préliminaire et une légère présentation des bases requises s&#8217;attaquera à un unique problème de haut niveau. Les solutions que nous proposons peuvent aller de l&#8217;interface utilisateur au stockage persistent, touchant de nombreux standards ou projets tiers en chemin.  Tous les exemples sont exécutables, pour preuvent ils tournent en production sur le site web compagnion.</simpara>
<simpara>Le débutant devrait s&#8217;attendre à rencontrer les acteurs d&#8217;un système Java d&#8217;entreprise et à transformer un dépôt entièrement vide en une application complète, visible publiquement et déployée dans le cloud.  Les développeurs de toutes les couleurs peuvent trouver des approches intéressantes pour tester à partir de données existantes, envoyer des évènements au client, intérargir avec une grille de données distribuées, valider l&#8217;interface utilisateur et bien plus encore.</simpara>
<simpara>En résumé, nous voudrions rendre la complexité beaucoup moins complexe. Avec de la chance, cele vous apportera une meilleure productivité et plus de plaisir dans votre travail.</simpara>
<simpara>Du moins c&#8217;est ce que nous avons vécu alors que nous utilisions les techniques qui ont inspiré ce livre.</simpara>
</section>
<section id="_continuity">
<title>Continuity</title>
<simpara><emphasis>"If everyone is moving forward together, then success takes care of itself." - Henry Ford</emphasis></simpara>
<section id="_the_zen_of_prevention">
<title>The Zen of Prevention</title>
<simpara>At times it may feel that the universe mischievously conspires to destroy our work.  And to some extent this is true: nature doesn&#8217;t like order.  This entropy manifests itself in many ways; we open a network socket, a router may fail.  We write to a file, the disk could fill up.  We fail to check for valid inputs, our program could blow up unexpectedly.</simpara>
<simpara>Causes of potential failure are both infinite and inevitable.  As guardians of our own code quality, we&#8217;re armed with two battle tactics: Be <emphasis>reactive</emphasis>, or be <emphasis>proactive</emphasis>.</simpara>
<section id="_reactive_error_handling">
<title>Reactive Error Handling</title>
<simpara>Colloquially referred to as "firefighting", a reactive position calls us to action.  In most cases, an undesirable situation has already presented itself, and now we&#8217;re charged with fixing:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
The initial cause of the error, if under our control
</simpara>
</listitem>
<listitem>
<simpara>
The unprotected areas of code which allowed the cause to wreck greater havoc
</simpara>
</listitem>
<listitem>
<simpara>
Any resultant artifacts which persist after the error is encountered
</simpara>
</listitem>
</orderedlist>
<simpara>Anyone who&#8217;s rifled through a database&#8217;s binary log file to restore data to a consistent state can attest to the stressful waste of time incurred in handling emergency situations after a breach in expected execution. Dealing with issues as they arise also imposes a sense of immediacy; the activities of a normal workday may be suspended to address more pressing concerns.</simpara>
<simpara>Clearly, the reactive model is not our best option if it can be avoided.</simpara>
</section>
<section id="_proactive_quality_policies">
<title>Proactive Quality Policies</title>
<simpara>"Only YOU can prevent &#8230; fires" has been the plea of the United States Forest Service since 1947, underscoring the importance of limiting factors that contribute to disaster <emphasis>before</emphasis> they happen.</simpara>
<simpara>Related to the prevention of errors is the issue of <emphasis>containment</emphasis>.  In the case of failure we&#8217;d like to know as soon as possible and handle the problem prior to its leaking into other areas of the system where it might cause greater harm.  Consider this simple bit of code:</simpara>
<programlisting language="java" linenumbering="unnumbered">public String welcome(String name) {
  return "Hello, " + name;
}</programlisting>
<simpara>Assume a user were to accidentally pass <literal>null</literal> into the <literal>welcome(String)</literal> method above.  The <literal>String</literal> returned would be:</simpara>
<simpara><literal>Hello, null</literal></simpara>
<simpara>This is because the <ulink url="http://docs.oracle.com/javase/specs/jls/se7/html/"><emphasis>Java Language Specification Version 7</emphasis></ulink> states in <ulink url="http://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.18.1">15.18.1</ulink> that concatenation with a single <literal>String</literal> operand will result in String Conversion upon the other operand.  The <literal>null</literal> pointer is therefore represented as the <literal>String</literal> "null" according to the rules dictated by <ulink url="http://docs.oracle.com/javase/specs/jls/se7/html/jls-5.html#jls-5.1.11">5.1.11</ulink>.</simpara>
<simpara>Likely this isn&#8217;t the result we&#8217;d been expecting, but we&#8217;ve put ourselves in this position because we didn&#8217;t <emphasis>code defensively</emphasis>.  Enhancing the <literal>welcome(String)</literal> method to perform a <emphasis>precondition check</emphasis> would raise an <literal>Exception</literal> to the user and prohibit further normal execution flow:</simpara>
<programlisting language="java" linenumbering="unnumbered">public String welcome(String name) {
  if (name == null || name.isEmpty()) {
    throw new IllegalArgumentException("name must be specified");
  }
  return "Hello, " + name;
}</programlisting>
<simpara>This <emphasis>fail-fast</emphasis> policy is equally important at runtime as it is during development.  Knowing how to limit our exposure to error remains a topic of vast research and refinement.  Luckily, the study of <emphasis>Software Development Process</emphasis> provides us with a number of models upon which we may base our own practices.</simpara>
</section>
</section>
<section id="_software_development_processes">
<title>Software Development Processes</title>
<simpara><emphasis>Methodology.  Doctrine.  Paradigm.</emphasis>  Whatever we call it, our process (or absence of one!) is the script we follow on a day-to-day basis which guides our approach to building software.  Typically inspired by the central themes we believe contribute to quality and efficiency, a model for development workflow may be a powerful tool in keeping you and your team from heading down an unproductive path.  Many well-documented approaches exist, and knowing their motivations can help inform your own decisions in choosing a sensible model for your project.</simpara>
<section id="_serial_models">
<title>Serial Models</title>
<simpara>A <emphasis>serial</emphasis>, or <emphasis>sequential</emphasis>, process follows a linear path from project inception to completion.  As each stage in the development lifecycle comes to a close, the next one in turn is started.  Prior stages are typically not revisited, and this model is often visualized as a series of steps, like this:</simpara>
<itemizedlist>
<listitem>
<simpara>
INSERT IMAGE <emphasis role="strong">*</emphasis>
</simpara>
</listitem>
</itemizedlist>
<simpara>Development flows from one stage to the next, forming the basis for the nickname "Waterfall", often-associated with serial models.  Also called "Big Design Up Front", this process relies heavily upon a full understanding of all requirements from the project onset.  The general theory supporting Waterfall Design is roughly "measure twice, cut once"; by doing an exhaustive evaluation of all moving parts, the goal is to reduce wasted time by avoiding the need to go back and make corrections.  In our opinion, this tack is best applied for projects with a long development cycle targeting a single release.</simpara>
<simpara>While this might fit the retail software mold, the never-go-back mentality of a serial process makes it a particularly brittle approach to building adaptable code; the model is not designed to support changing requirements.  For that we might be better-served looking to a more random-access model where any development phase may be revisited (or many may be in-process at the same time!)</simpara>
</section>
<section id="_iterative_models">
<title>Iterative Models</title>
<simpara>In stark contrast to the linear workflow prescribed by the Waterfall Model, there exist a suite of well-known iterative designs built to encourage change and promote parallelism.  By decomposing a large problem into more manageable components, we grant ourselves the option to solve each piece independently.  Additionally, we might opt to take broad swipes on a first pass, further refining our solutions in repeated cycles; this is where "iterative" processes obtain their name.</simpara>
<section id="_extreme_programming">
<title>Extreme Programming</title>
<simpara>Also known simply as "XP", <emphasis>Extreme Programming</emphasis> is a discipline which introduces a feedback loop into each phase of the development process.  A practice which rose to popularity especially in the late 90s and early 2000s, XP lauds communication and other social aspects as centrally important themes.  Its workflow may look something like:</simpara>
<itemizedlist>
<listitem>
<simpara>
INSERT IMAGE <emphasis role="strong">*</emphasis>
</simpara>
</listitem>
</itemizedlist>
<simpara>While the full reasoning behind XP is detailed by Kent Beck&#8217;s <emphasis>Extreme Programming Explained: Embrace Change (Second Edition)</emphasis>, some of its primary tenants may be boiled down to:</simpara>
<itemizedlist>
<listitem>
<simpara>
Short development cycles
</simpara>
</listitem>
<listitem>
<simpara>
Daily, brief meetings
</simpara>
</listitem>
<listitem>
<simpara>
Pair Programming, Team Ownership and Accountability
</simpara>
</listitem>
<listitem>
<simpara>
Doing only what needs to be done now, deferring nonessential work until later
</simpara>
</listitem>
<listitem>
<simpara>
Garnering feedback from all stakeholders, not only programmers, early and often
</simpara>
</listitem>
<listitem>
<simpara>
Test-Driven Development
</simpara>
<itemizedlist>
<listitem>
<simpara>
The approach of first writing automated tests, then correcting/augmenting main code until they pass
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<simpara>In fact, XP along with other models has both inspired and acts as an implementation of a larger collection of iterative policies as outlined by the <ulink url="http://agilemanifesto.org/"><emphasis>Manifesto for Agile Software Development</emphasis></ulink>.</simpara>
</section>
</section>
</section>
<section id="_testing_emphasis_is_emphasis_development">
<title>Testing <emphasis>is</emphasis> Development</title>
<simpara><emphasis>"Move testing from the caboose to the engine." - Tim Ottinger, Senior Consultant, Industrial Logic</emphasis></simpara>
<simpara>No matter the development method your team prescribes, and no matter how rigidly you adhere to its principles, eventually you&#8217;re going to need to assert that your code works.  Of course you could handle this manually by deploying the application and letting a human user follow a scripted test plan, but wherever possible it&#8217;s much more efficient and fail-proof to automate the test execution. So you&#8217;re going to need to write some tests.</simpara>
<simpara>But it&#8217;s our opinion that testing is not simply about making sure your code works as expected.</simpara>
<simpara>When you write tests, you&#8217;re a <emphasis>user</emphasis> of your API.  You&#8217;ll see how intuitive it is to use, you&#8217;ll discover gaps in documentation.  You might discover that it&#8217;s too verbose or ugly, and most importantly: you can re-evaluate your design before it&#8217;s too late. You&#8217;re putting yourself in the shoes of your target audience.</simpara>
<simpara>What&#8217;s more, if you write tests alongside the development of your business logic, you might find your work to be more <emphasis>enjoyable</emphasis>.  You&#8217;ll know when a feature is completed; you&#8217;ll have the satisfaction of seeing concrete feedback in real-time.  Proponents of <emphasis>Test-Driven Development</emphasis> even make the case for writing tests <emphasis>before</emphasis> implementation.  In our experience, testing may be done alongside construction of the primary code such that the experience from one end of the tunnel can inform the other.</simpara>
<simpara>Automated testing can take many forms, and we&#8217;ll categorize a few for use throughout this text.</simpara>
</section>
<section id="_levels_of_testing">
<title>Levels of Testing</title>
<simpara>Proponents of test-oriented software development processes may qualify tests in one or more flavors:</simpara>
<itemizedlist>
<listitem>
<simpara>
Acceptance
</simpara>
<itemizedlist>
<listitem>
<simpara>
Asserts that code meets business requirements
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Black-Box
</simpara>
<itemizedlist>
<listitem>
<simpara>
Asserts the contract of an API is working without respect to its internals
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Compatibility
</simpara>
<itemizedlist>
<listitem>
<simpara>
Asserts that code plays nicely with one or more outside components; for instance a web application may need to display correctly on Internet Explorer, Chrome, Firefox, Safari, and mobile devices.
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Functional
</simpara>
<itemizedlist>
<listitem>
<simpara>
Asserts that code meets the technical requirements derived from business requirements; ie. that all <emphasis role="strong">functions</emphasis> are working as expected
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Load / Stress / Performance
</simpara>
<itemizedlist>
<listitem>
<simpara>
Asserts and measures how a system handles input under load, and how gracefully it degrades with increased traffic
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Regression
</simpara>
<itemizedlist>
<listitem>
<simpara>
Asserts that previously-identified errors have been corrected or that existing features remain to function
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Smoke
</simpara>
<itemizedlist>
<listitem>
<simpara>
A subset of a full test suite, intended to run quickly and provide feedback that the system is generally intact from a simplistic level
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
White-Box
</simpara>
<itemizedlist>
<listitem>
<simpara>
Asserts that an API is working as contracted, taking into concern implementation-specific data structures and constructs.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<simpara>A well-tested application may have tests covering many of the above areas, and we may further organize these types according to scope.</simpara>
<section id="_unit">
<title>Unit</title>
<simpara>The purpose of a unit test is to validate that a single functionality is operating as expected in isolation.  Unit tests are characterized as fast, simple, easy-to-run, and fine-grained.  They may dig into implementation details for use in _white-box testing.</simpara>
<simpara>For instance, every Java object inherits the method <literal>Object.hashCode()</literal> and the value equality test <literal>Object.equals(Object)</literal>.  By API contract, calls to <literal>hashCode</literal> of equal-by-value objects must return equal, that is:</simpara>
<programlisting language="java" linenumbering="unnumbered">/**
 * Test bullet 2 of the hashCode contract as defined by:
 * http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#hashCode()
*/
public void testHashCodeOfEqualObjects() {
  // Declare some vars that are equal-by-value
  MyObject a = new MyObject("a");
  MyObject b = new MyObject("a");

  // Now ensure hashCode is working for these objects as contracted
  assert a.equals(b) : "The objects should be equal by value";
  assert a.hashCode() == b.hashCode() : "Hash codes of equal objects not equal";
}</programlisting>
<simpara>The above test, implemented using the Java <literal>assert</literal> keyword, is a classic example of a unit test; it checks for the smallest possible <emphasis>invariant</emphasis> (in this case that the <literal>equals()</literal> and <literal>hashCode()</literal> implementations of <literal>MyObject</literal> are working with respect to one another).  Many experts will advise that a unit test contains only one assertion; in our experience this is a fantastic guideline but as the above example illustrates, use common sense.  If more than one assertion is required to conclude that all participants in an invariant are in expected form, then use what&#8217;s necessary.</simpara>
<simpara>In cases where a unit test may require inputs from unrelated components, the use of <emphasis>mock objects</emphasis> is a common solution.  Mocks supply an alternate implementation used in testing which may help the developer to:</simpara>
<itemizedlist>
<listitem>
<simpara>
Simulate an error condition
</simpara>
</listitem>
<listitem>
<simpara>
Avoid starting up an expensive process or code path
</simpara>
</listitem>
<listitem>
<simpara>
Avoid dependence upon a third-party system which might not be reliable (or even not available) for testing purposes
</simpara>
</listitem>
<listitem>
<simpara>
Avoid dependence upon a mechanism which supplies non-idempotent (non-repeatable) values.
</simpara>
<itemizedlist>
<listitem>
<simpara>
For instance a random-number generator or something that relies on the current time
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<simpara>While mocks absolutely have their place in the testing arsenal, in the context of Enterprise development it&#8217;s our opinion that their use is to be limited.  The Java Enterprise Edition is based on a <emphasis>POJO</emphasis> (Plain Old Java Object) component model which enables us to directly instantiate Servlets, EJBs, and CDI beans; this is great for validating business logic in simple calls.  However the true power of Java EE is in the <emphasis>loose coupling</emphasis> between components, and mocks do not account for the linkage between these pieces that&#8217;s provided by the container.  To fully test an application, you must test the whole runtime, not simply the code you&#8217;ve written on your own.  For that, we need a more comprehensive solution to validation than is allowed by Unit Tests.</simpara>
</section>
<section id="_integration">
<title>Integration</title>
<simpara>Imagine we&#8217;d like to build a pipe to carry water from a nearby reservoir to a treatment and purification facility.  The unit tests we&#8217;d described above would be responsible for ensuring that each section of the tube was free of leaks and generally of good quality.  But the whole is more than the sum of its parts: the opportunity for water escaping between the cracks still exists.</simpara>
<simpara>And so it is with software; we must check that our components play nicely with one another.  This is especially true for Java EE where <emphasis>dependency injection</emphasis> is a commonplace tool.  It&#8217;s great that one bean not be explicitly bound to another, but eventually we rely upon a container to do the wiring for us.  If our metadata or configuration is incorrect, our injection points may not be filled as we&#8217;re expecting.  This could result in a deployment-time exception or worse, making it imperative that we have test coverage for the interaction between components.</simpara>
<simpara>When we talk about <emphasis>integration testing</emphasis> in this book, it&#8217;s within the context of a <emphasis>container</emphasis>.  Historically, interaction with an application server has been notoriously difficult to test.  For many, Java EE has become a dirty term as a result.  It&#8217;s the goal of this text to clearly delineate techniques for building enterprise applications in a testable manner.  While many may view this discussion as related to integration testing, instead we feel that it&#8217;s more about <emphasis role="strong">development</emphasis> and integration testing is a valued part of that equation.</simpara>
<simpara>In that sense, testing <emphasis>is</emphasis> development.</simpara>
</section>
</section>
<section id="_foundation_test_frameworks">
<title>Foundation Test Frameworks</title>
<simpara>As you might imagine, <emphasis>container services</emphasis> really help us to cut down on the complexity in our application code.  Dependency Injection frees us from manual wiring while features like <emphasis>declarative security</emphasis> and <emphasis>transaction management</emphasis> keep us from weaving technical concerns into our business logic.  Unfortunately, nothing comes for free; the cost of enlisting an framework or application server&#8217;s help is that we&#8217;ve now added another integration point.  And every integration point must be validated by an integration test.</simpara>
<simpara>Java has built-in support for <literal>java.lang.Assertion</literal> error and the <literal>assert</literal> keyword, and these are fine tools when used in the right context.  Because assertions using <literal>assert</literal> are only analyzed in the presence of the <literal>-ea</literal> switch at launch of the Java runtime, you need not worry about the performance implications of running extra checks in a production environment with this support disabled.  For that reason, it makes sense to use <literal>assert</literal> for testing internal code, for instance:</simpara>
<programlisting language="java" linenumbering="unnumbered">private String welcome(String name) {
  assert name!=null &amp;&amp; !name.isEmpty() : "name must be specified";
  return "Hello, " + name;
}</programlisting>
<simpara>Because the visibility of this code is <literal>private</literal>, we do not need to worry about doing precondition checks on end-user input; the parameter <literal>username</literal> must be supplied by something <emphasis>we</emphasis> have written.  Therefore this need not be tested in production.</simpara>
<simpara>Of course, assertions may help us along the way, but they&#8217;re not <emphasis role="strong">tests</emphasis>.  Tests exercise a code path and validate one or more <emphasis>post-conditions</emphasis>.  For instance we might write the following client to validate that the public <literal>welcome(String)</literal> example from the <emphasis>Proactive Quality Policies</emphasis> section is working as we&#8217;d expect:</simpara>
<programlisting language="java" linenumbering="unnumbered">public class WelcomeJDKTest {

  /** WelcomeBean instance to be tested **/
  private WelcomeBean welcomer;

  private WelcomeJDKTest(WelcomeBean welcomer) {
    this.welcomer = welcomer;
  }

  public static void main(String... args) {

    /** Make a test client, then execute its tests **/
    WelcomeJDKTest tester = new WelcomeJDKTest(new WelcomeBean());
    tester.testWelcome();
    tester.testWelcomeRequiresInput();

  }

  private void testWelcome() {
    String name = "ALR";
    String expectedResult = "Hello, " + name;
    String receivedResult = welcomer.welcome(name);
    if(!expectedResult.equals(receivedResult)) {
      throw new AssertionError("Did not welcome " + name + " correctly");
    }
  }

  private void testWelcomeRequiresInput() {
    boolean gotExpectedException = false;
    try {
      welcomer.welcome(null);
    } catch (final IllegalArgumentException iae) {
      gotExpectedException = true;
    }
    if(!gotExpectedException) {
      throw new AssertionError("Should not accept null input");
    }
  }

}</programlisting>
<simpara>Not too terrible as far as code coverage goes; we&#8217;ve ensured that the <literal>welcome</literal> method functions as we&#8217;d expect, and we even check that it bans <literal>null</literal> input at the right place, before that null pointer has a chance to make things more complicated later.</simpara>
<simpara>But our signal-to-noise ratio is way off when we write our own <literal>main(String[])</literal>-based test clients.  Look at all the boilerplate involved just to get the execution running, as compared with the test code itself!  Just as we use frameworks and component models to cut the redundant, rote bits in our business logic, we can take advantage of some popular libraries to help us slim our tests.</simpara>
<section id="_junit">
<title>JUnit</title>
<simpara>The <ulink url="http://www.junit.org/">JUnit</ulink> Test Framework is one of the most widely-known testing frameworks for Java.  Initially ported from <ulink url="http://en.wikipedia.org/wiki/Kent_Beck">Kent Beck&#8217;s</ulink> work in testing the Smalltalk programming language, JUnit is the most-downloaded artifact in the <ulink url="http://search.maven.org/">Maven Central Repository</ulink> outside of libraries used to run Maven itself (as of August 2012).</simpara>
<simpara>Refactoring our <literal>WelcomeJDKTest</literal> above to use JUnit might look a little like this:</simpara>
<programlisting language="java" linenumbering="unnumbered">public class WelcomeJUnitTest {

    /** To be set by the {@link Before} lifecycle method **/
    private WelcomeBean welcomer;

    /** Called by JUnit before each {@link Test} method **/
    @Before
    public void makeWelcomer() {
        this.welcomer = new WelcomeBean();
    }

    @Test
    public void welcome() {
        final String name = "ALR";
        final String expectedResult = "Hello, " + name;
        final String receivedResult = welcomer.welcome(name);
        Assert.assertEquals("Did not welcome " + name + " correctly", expectedResult, receivedResult);
    }

    @Test
    public void welcomeRequiresInput() {
        boolean gotExpectedException = false;
        try {
            welcomer.welcome(null);
        } catch (final IllegalArgumentException iae) {
            gotExpectedException = true;
        }
        Assert.assertTrue("Should not accept null input", gotExpectedException);
    }
}</programlisting>
<simpara>The first benefit we get is that we don&#8217;t need a <literal>main(String[])</literal> method, and we don&#8217;t need to manually call upon our test methods.  Instead, JUnit will dutifully execute for us any lifecycle (ie. <literal>@Before</literal>) or test (annotated with <literal>@Test</literal>) methods and report the results back to its initial runner.  Secondly, we&#8217;re given access to the JUnit library, for instance a set of convenience methods in <literal>org.junit.Assert</literal>, to help us reduce the amount of code we&#8217;ll need to write assertions.</simpara>
<simpara>JUnit also has widespread IDE support, making test execution during development much easier.  For instance, consider the context menu available in Eclipse:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch01-continuity/runas_junit.png"/>
  </imageobject>
  <textobject><phrase>JUnit IDE Runner Integration</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>As opposed to our homebrewed <literal>main(String[])</literal> test client, JUnit supports reporting.  In the IDE this may appear graphically:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch01-continuity/junit_test_execution.png"/>
  </imageobject>
  <textobject><phrase>JUnit IDE Reporting Integration</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>During a more formal build process, output may be directed to an XML file for analysis by a build server.  This can be very helpful in tracking progress over time:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch01-continuity/ci_test_trend.png"/>
  </imageobject>
  <textobject><phrase>Continuous Integration Test Reporting</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Of course, JUnit is not the only kid on the block when it comes to test frameworks.</simpara>
</section>
<section id="_testng">
<title>TestNG</title>
<simpara>If JUnit sets the standard for simplicity in Java testing, <ulink url="http://testng.org/doc/index.html">TestNG</ulink> touts greater flexibility to the developer by offering an arguably greater featureset.  While the differences between the two frameworks are beyond the scope of this text, there&#8217;s quite a bit of overlap in concept.  Refactoring our test for TestNG should look familiar:</simpara>
<programlisting language="java" linenumbering="unnumbered">public class WelcomeTestNGTest {

    /** To be set by the {@link @BeforeTest} lifecycle method **/
    private WelcomeBean welcomer;

    /** Called by TestNG before each {@link Test} method **/
    @BeforeTest
    public void makeWelcomer() {
        this.welcomer = new WelcomeBean();
    }

    @Test
    public void welcome() {
        /// .. Omitting logic for brevity
        Assert.assertEquals(receivedResult, expectedResult, "Did not welcome " + name + " correctly");
    }

    @Test
    public void welcomeRequiresInput() {
        /// .. Omitting logic for brevity
        Assert.assertTrue(gotExpectedException, "Should not accept null input");
    }
}</programlisting>
<simpara>Some of the parameter orders and API names for the annotations have changed, but the concept remains: write less, and let the framework wire up the call stack.</simpara>
<simpara>IDE Integration, while not standard for Eclipse Juno, is <ulink url="http://testng.org/doc/download.html">simple enough to install</ulink> and provides a GUI runner as we&#8217;ve seen with JUnit:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch01-continuity/testng_test_execution.png"/>
  </imageobject>
  <textobject><phrase>TestNG IDE Runner Integration</phrase></textobject>
</inlinemediaobject></simpara>
</section>
</section>
<section id="_continuous_development">
<title>Continuous Development</title>
<simpara>Followers of Extreme Programming and Agile methodologies are likely to be familiar with <ulink url="http://martinfowler.com/articles/continuousIntegration.html">Continuous Integration</ulink>, a practice which advocates frequent patching of the upstream development branch in order to catch errors as they&#8217;re introduced.  Such an approach involves:</simpara>
<itemizedlist>
<listitem>
<simpara>
An authoritative source repository (which is <emphasis role="strong">not</emphasis> at odds with decentralized version control systems, as we&#8217;ll soon see)
</simpara>
</listitem>
<listitem>
<simpara>
A comprehensive test suite
</simpara>
</listitem>
<listitem>
<simpara>
An automated build system
</simpara>
</listitem>
<listitem>
<simpara>
Automated deployment
</simpara>
</listitem>
</itemizedlist>
<simpara>These general rules are applicable in most any modern language, are tool-agnostic, and are widely-accepted throughout the development community.</simpara>
<simpara>So why the <emphasis>Continuous Development</emphasis> title of this book?</simpara>
<simpara>In addition to the successful ideology and theory espoused by the Agile community, we&#8217;ll be looking at concrete tools and projects both within and extending the Java Enterprise Platform to best address the real-world concerns of an Enterprise Java Developer.</simpara>
<simpara>The authoritative Git repository containing the book and example application source for this text is hosted by our friends at <ulink url="http://www.github.com">GitHub</ulink> at <ulink url="https://github.com/arquillian/continuous-enterprise-development">https://github.com/arquillian/continuous-enterprise-development</ulink>.  The accompanying book site is located at <ulink url="http://continuousdev.org">http://continuousdev.org</ulink>, and the official Twitter channel is <ulink url="http://twitter.com/ContinuousDev">@ContinuousDev</ulink>.  The authors may be reached at <ulink url="mailto:authors@continuousdev.org">authors@continuousdev.org</ulink>.</simpara>
<simpara>All contents of the book&#8217;s repository are licensed under <ulink url="http://creativecommons.org/licenses/by-sa/2.0/"><emphasis>Creative Commons Attribution-ShareAlike 2.0 Generic</emphasis></ulink>, and we invite the community at large to contribute work including feature requests, typographical error corrections, and enhancements via our <ulink url="https://github.com/arquillian/continuous-enterprise-development/issues">GitHub Issue Tracker</ulink>.</simpara>
<simpara>The print release of the book and its example is set to be given the Git tag of <literal>1.0.0</literal> in the authoritative repository, and development will continue thereafter in the <literal>master</literal> branch to correct errata and add supplmentary material including new chapters and use cases.  The community is welcome to suggest or request topics for additional coverage.</simpara>
<simpara>The example application accompanying the use cases raised in this book is called GeekSeek, and is publicly-available at <ulink url="http://geekseek.continuousdev.org">http://geekseek.continuousdev.org</ulink>.  The source is located in this repository under <literal>code/application</literal>, and instructions for building, testing, and running locally are detailed in <ulink url="https://github.com/arquillian/continuous-enterprise-development/blob/master/Chapter04-RequirementsAndExampleApplication.asciidoc">Chapter 4</ulink>.  The build jobs for the application are kindly powered by <ulink url="http://www.cloudbees.com">CloudBees</ulink> at <ulink url="https://arquillian.ci.cloudbees.com/job/GeekSeek-wildfly/">https://arquillian.ci.cloudbees.com/job/GeekSeek-wildfly/</ulink> and <ulink url="https://arquillian.ci.cloudbees.com/job/GeekSeek-jbosseap/">https://arquillian.ci.cloudbees.com/job/GeekSeek-jbosseap/</ulink>.</simpara>
<simpara>We welcome your contributions and hope you find the material covered here to be of interest and benefit to your work and career in testable enterprise development.</simpara>
<simpara>The first step is to meet some of the key players who will become thematic in this text.</simpara>
</section>
</section>
<section id="_enabling_technologies">
<title>Enabling Technologies</title>
<simpara><emphasis>"I get by with a little help from my friends." - Paul McCartney and John Lennon</emphasis></simpara>
<simpara>There&#8217;s a common misconception that the goal of a standard specification is to address <emphasis>every</emphasis> problem.  This couldn&#8217;t be further from the truth; creating a standard is meant to address the 80% case in a manner that&#8217;s been proven through experience in the field.  The <ulink url="http://www.oracle.com/technetwork/java/javaee/downloads/index.html">Java Enterprise Edition</ulink> and its subsystems, governed by the <ulink url="http://www.jcp.org/en/home/index">Java Community Process</ulink>  (JCP), is no exception.</simpara>
<simpara>By its very makeup, the JCP is designed to strive for consensus among all participants in an Expert Group on a given technology.  Where corporate sponsors and individual contributors disagree or determine that a feature is not yet mature enough to be adequately standardized, latitude is given to specification implementors.  This helps to foster creativity and provides differentiation between vendors.  In fact, on a <ulink url="http://java.net/projects/javaee-spec/lists/jsr342-experts/archive/2012-08/message/16">discussion regarding the Java EE7 Roadmap</ulink>, Expert Group member David Blevins succinctly addressed the dynamic: "Vendors innovate, collectively we standardize."</simpara>
<simpara>While it&#8217;s not the goal of this book to provide exhaustive instruction on the complete featureset of Java EE, it is absolutely our intent to unify the development experience.  Helping us along the way are a set of enabling technologies intending to smooth the rough edges of the EE Platform and fill the gaps left open by its specifications.</simpara>
<simpara>The following open-source projects are all made freely-available for you to download, use, and modify (be sure to consult individual licensing terms).</simpara>
<section id="_bootstrapping">
<title>Bootstrapping</title>
<simpara>For all the documentation surrounding Java EE and its use, the seemingly simple act of getting started gets quickly muddled:</simpara>
<itemizedlist>
<listitem>
<simpara>
How am I going to build my sources into deployments?
</simpara>
</listitem>
<listitem>
<simpara>
How should I organize my codebase?
</simpara>
</listitem>
<listitem>
<simpara>
How can my team best collaborate in parallel on the codebase?
</simpara>
</listitem>
<listitem>
<simpara>
What about libraries my code uses?  How do I get those?
</simpara>
</listitem>
</itemizedlist>
<simpara>There are a number of valid answers to each of these questions, and the flexibility of choice can easily turn into a burden.  Because we&#8217;ll be exploring fully-functioning examples which are intended to be reproduced in your own environment, by necessity we&#8217;ve had to make some decisions in the interest of keeping focus on the code as opposed to our development tools.  The projects below, when combined, work very well together but are certainly not the only solutions to the bullets raised above.</simpara>
<simpara>One approach to undertaking a new project is to first lay out the scaffolding on your local file system.  This will create the structure for your source code, build descriptors, and other resources used by your project.  Often this process is fairly rote, involving commands to make new directories and text files in some sensible layout.  While there&#8217;s no formal rule dictating how your project tree is organized, some build systems employ a convention; others instead choose to allow you total control over your project&#8217;s build by encouraging you to script or otherwise instruct each build task.</simpara>
<simpara>Our examples will be built using a <emphasis>declarative build tool</emphasis> which has standard commands that do not change from project to project.</simpara>
<section id="_apache_maven">
<title>Apache Maven</title>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch02-enabling_technologies/maven.png"/>
  </imageobject>
  <textobject><phrase>Apache Maven</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Perhaps the most prominent figure in the Java automated build tool landscape, <ulink url="http://maven.apache.org/">Apache Maven</ulink> positions itself as a "software project management and comprehension tool".  For simplicity&#8217;s sake, we may view it as a build tool; it&#8217;s capable of compiling, testing, and assembling.</simpara>
<simpara>One very nice feature of Maven is that it strives for <emphasis>"convention over configuration"</emphasis>.  By following a set of recommended best practices, you&#8217;re likely to trim down on the amount of metadata you&#8217;d otherwise need to explicitly define.  Additionally, Maven actions (called <emphasis>goals</emphasis>) are bound to a documented <ulink url="http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html">lifecycle</ulink> which are common to all Maven-based projects.  For instance, in order to compile, test, and package your project, the command <literal>$&gt; mvn package</literal> applies.  This standardization alleviates us from having to declare or learn different build commands for each project.</simpara>
<simpara>At the core of the Maven engine is a sophisticated <emphasis>dependency management</emphasis> solution capable of resolving libraries by name from a <ulink url="http://search.maven.org/">Central Repository</ulink> (or additionally-configured repository) onto a user&#8217;s local system.  This feature allows us to skip the manual process of adding dependencies into our version control system, and allows us to instead fetch them on-demand as part of the build process.  As an added bonus, the requisite dependencies for all projects consuming ours are well-documented and automatically fetched for us.</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT IMAGE : Project A depends on B depends on C, gets all as requested from the Central Repo</emphasis></emphasis></simpara>
<simpara>Maven is not without its detractors, however.  It&#8217;s been criticized for a few points, among them:</simpara>
<itemizedlist>
<listitem>
<simpara>
Maven Plugins versions are not bound to Maven Core versions, making guaranteed reproducible builds between different environments difficult to guarantee.
</simpara>
</listitem>
<listitem>
<simpara>
Project Object Model (POM, ie. <literal>pom.xml</literal>) syntax, the metadata describing a project&#8217;s makeup, is verbose.
</simpara>
</listitem>
<listitem>
<simpara>
Transitive dependencies as a default trigger a lot of downloading on first build.  Without care, a project may inherit more dependencies than are necessary or desired.
</simpara>
</listitem>
<listitem>
<simpara>
Deviation from the defined Maven standard is often difficult to reconcile.
</simpara>
</listitem>
</itemizedlist>
<simpara>It <emphasis>is</emphasis> possible to use Maven-structured repositories from outside Maven.  In fact, standalone dependency manager <ulink url="http://ant.apache.org/ivy/">Apache Ivy</ulink> (often used in concert with task-based tool <ulink url="http://ant.apache.org/">Apache Ant</ulink>), does just that.  Groovy-based <ulink url="http://www.gradle.org/">Gradle</ulink> seeks to provide the flexibility of Ant with the dependency management of Maven.</simpara>
<simpara>That said, Maven continues to be a popular and widely-used tool in Java development, and will satisfy our requirements to build our examples.</simpara>
</section>
<section id="_jboss_forge">
<title>JBoss Forge</title>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch02-enabling_technologies/forge.png"/>
  </imageobject>
  <textobject><phrase>JBoss Forge</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>If you&#8217;ve spent any time developing Java EE-based projects (or any nontrivial application, for that matter!), you&#8217;ve likely invested a good amount of energy in creating the project layout, defining dependencies, and informing the build system of the relevant ClassPaths to be used in compilation and execution.  While Maven enables us to reduce that load as compared with undertaking project setup manually, there&#8217;s typically quite a bit of boilerplate involved in the <literal>pom.xml</literal> defining your requirements.</simpara>
<simpara><ulink url="http://forge.jboss.org/">JBoss Forge</ulink> offers "incremental project enhancement for Java EE".  Implemented as a command shell, Forge gives us the ability to alter project files and folders.  Some concrete tasks we might use Forge to handle are:</simpara>
<itemizedlist>
<listitem>
<simpara>
Adding <emphasis>Java Persistence API</emphasis> (JPA) entities and describing their model
</simpara>
</listitem>
<listitem>
<simpara>
Configuring Maven dependencies
</simpara>
</listitem>
<listitem>
<simpara>
Setting up project scaffolding
</simpara>
</listitem>
<listitem>
<simpara>
Generating a view layer, reversed-engineered from a domain model
</simpara>
</listitem>
<listitem>
<simpara>
Deploying to an application server
</simpara>
</listitem>
</itemizedlist>
<simpara>Because Forge is built atop a <emphasis>modular, <ulink url="http://forge.jboss.org/plugins.html">plugin</ulink>-based architecture</emphasis>, it&#8217;s extensible to additional tasks that may be specific to your application.</simpara>
<simpara>Overall, the goal of Forge is to ease project setup at all stages of development, so we&#8217;ll be employing it in this text to speed along the construction of our examples.</simpara>
</section>
</section>
<section id="_version_control">
<title>Version Control</title>
<simpara>From the moment we collaborate on a project with others or would like to inspect the evolution of our code over time, we need some form of <emphasis>version control</emphasis>.  Until recently, the most common paradigm for synchronizing access to a shared codebase was the <emphasis>client/server</emphasis> model wherein developers may keep a local working copy and check their changes into a centralized server.</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT IMAGE SHOWING CENTRALIZED VERSION CONTROL</emphasis></emphasis></simpara>
<simpara>Some systems utilize file-level locking to ensure that no conflicts arise during development; others allow concurrent access at the file granularity but cue the developer to resolve line-level conflicts upon committing changes upstream.</simpara>
<simpara>Likely the widest-deployed client/server version control system (VCS) from the 1990s through the 2000s has been <ulink url="http://savannah.nongnu.org/projects/cvs">Concurrent Versions Systems</ulink>, most often referred by its acronym <emphasis>CVS</emphasis>.  While CVS has enabled teams to freely work on all files in the tree through <emphasis>unreserved checkouts</emphasis>, its shortcomings including non-atomic commits and absent tracking for file renames prompted the development of <ulink url="http://subversion.apache.org/">Subversion</ulink> (SVN), hier apparent to CVS.  Boasting a wider featureset and greater stability as contrasted with CVS, SVN has enjoyed its reign from the mid- to late-2000s.</simpara>
<simpara>These days, the centralized model has been superseded by <emphasis>distributed version control systems</emphasis> (DVCS), which is differentiated by its ability to store the full repository including all history in any number of nodes.</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT IMAGE SHOWING DVCS</emphasis></emphasis></simpara>
<simpara>This layout creates a "pull model", where developers on a common project are given the authority over their own repository, free to incorporate changes from others (or not!).  At first, this can be a confusing topic to grasp for users vested in the centralized "push model", but its our opinion that the benefits of this design easily justify the initial confusion inherent when considering many full-fledged repositories representing the same project.</simpara>
<simpara>Some immediate gains to consider:</simpara>
<itemizedlist>
<listitem>
<simpara>
Repository operations such as committing and searching history are much faster
</simpara>
</listitem>
<listitem>
<simpara>
Network connectivity is not required to alter the respository&#8217;s state
</simpara>
</listitem>
<listitem>
<simpara>
Every repository is a full backup of the codebase&#8217;s history
</simpara>
</listitem>
</itemizedlist>
<simpara>This is because each user is typically working on a local repository, and synchronization with a remote repository is only necessary when pushing changes to be visible by others.</simpara>
<simpara>In this text, we&#8217;ll be using the open-source DVCS <emphasis>Git</emphasis>.</simpara>
<section id="_git">
<title>Git</title>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch02-enabling_technologies/git.png"/>
  </imageobject>
  <textobject><phrase>Git</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Originally developed to coordinate development of the Linux Kernel, Git is a DVCS whose usage has taken off in recent years, arguably due to the user-friendliness of the socially-aware hosting site <ulink url="http://www.github.com">GitHub</ulink>.  In fact, this book&#8217;s text and examples are <ulink url="https://github.com/arquillian/continuous-enterprise-development">hosted</ulink> on GitHub for all to participate.</simpara>
<simpara>From a high-level, we&#8217;ve chosen Git for our projects as it enables:</simpara>
<itemizedlist>
<listitem>
<simpara>
True feature (topic) development.  Branching is quick, easy, and cheap.  You may work on feature X in isolation with the ability to put your changes <emphasis>on top of</emphasis> development that may be occurring in the mainline branch.
</simpara>
</listitem>
<listitem>
<simpara>
Integration with 3rd-party systems built to respond to Git events.  For instance, we&#8217;ll be able to trigger builds and production deployments by pushing our local changes to a remote repository.
</simpara>
</listitem>
<listitem>
<simpara>
Rewriting of local history.  Often it&#8217;s handy to commit liberally, giving yourself many "save" points along the way.  However, before making these (sometimes breaking) changes visible to the rest of the world, it&#8217;s good practice to "squash" the mini-changes into a cohesive, singular commit.  This helps keep the version history sane and facilitates later auditing if a bug should arise.
</simpara>
</listitem>
</itemizedlist>
<simpara>Again, it is not our aim to fully delve into the mechanics of each tool we&#8217;ll be employing.  However, we will be issuing Git commands and explaining their use along the way.  A very good reference on the myriad Git subroutines can be found in the <ulink url="http://git-scm.com/book">Pro Git Book</ulink> by Scott Chacon, available for free in digital editions and in print via online retailers.</simpara>
</section>
</section>
<section id="_a_test_platform_for_java_ee">
<title>A Test Platform for Java EE</title>
<simpara>Java EE 5 introduced a <emphasis>POJO</emphasis> (Plain Old Java Object) programming model which freed developers from having to adhere to any particular class hierarchy for its business objects.  The introduction of <ulink url="http://jcp.org/en/jsr/detail?id=299">Contexts and Dependency Injection</ulink> (CDI) in Java EE 6 further pushed the notion of simple business objects by providing <emphasis>typesafe injection</emphasis>.</simpara>
<simpara>The benefit to objects that can be easily created using the <literal>new</literal> operator is the same as their drawback; when we manually instantiate objects for use in testing, we&#8217;re not dealing with the same enterprise components we have in the target runtime.  An EJB becomes such only in the context of an EJB container; a Servlet is a Servlet only when created by a Servlet Container.  Any time we circumvent the target runtime environment to handle object creation and wiring on our own, we&#8217;re using <emphasis>mock objects</emphasis>.</simpara>
<simpara>While many will advocate on the usefulness of mocks, by definition they provide an approximation of how your application will behave in a production environment.  Remember that you&#8217;re responsible for validating that the full bevy of code running on your servers is working as expected, including the bits you <emphasis>did not write</emphasis>.  There are many not-so-subtle errors that may arise while leveraging the full potential of the application server in production, and it&#8217;s best to be testing in an environment as close to the real thing as possible.</simpara>
<simpara>True Java EE testing in this sense is an area left largely unspecified by the EE Platform, and we&#8217;ll be examining some tools to help bridge this divide.</simpara>
<section id="_arquillian">
<title>Arquillian</title>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch02-enabling_technologies/arquillian.png"/>
  </imageobject>
  <textobject><phrase>Arquillian</phrase></textobject>
</inlinemediaobject></simpara>
<simpara><ulink url="http://arquillian.org">Arquillian</ulink> is an innovative and highly extensible testing platform for the JVM that enables developers to easily create automated integration, functional and acceptance tests for Java middleware.</simpara>
<simpara>Picking up where unit tests leave off, Arquillian handles all the plumbing of container management, deployment and framework initialization so you can focus on the business of writing test logic.  Instead of configuring a potentially-complex test harness, Arquillian abstracts out the target runtime by:</simpara>
<itemizedlist>
<listitem>
<simpara>
Managing the lifecycle of the container (or containers)
</simpara>
</listitem>
<listitem>
<simpara>
Bundling the test case, dependent classes and resources into a ShrinkWrap archive (or archives)
</simpara>
</listitem>
<listitem>
<simpara>
Deploying the archive (or archives) to the container (or containers)
</simpara>
</listitem>
<listitem>
<simpara>
Enriching the test case by providing dependency injection and other declarative services
</simpara>
</listitem>
<listitem>
<simpara>
Executing the tests inside (or against) the container
</simpara>
</listitem>
<listitem>
<simpara>
Capturing the results and returning them to the test runner for reporting
</simpara>
</listitem>
<listitem>
<simpara>
To avoid introducing unnecessary complexity into the developer’s build environment, Arquillian integrates seamlessly with familiar testing frameworks (e.g., JUnit 4, TestNG 5), allowing tests to be launched using existing IDE, Ant and Maven test plugins — without any add-ons.
</simpara>
</listitem>
</itemizedlist>
<simpara>The Arquillian project adheres to three core principles:</simpara>
<itemizedlist>
<listitem>
<simpara>
<emphasis role="strong">Tests should be portable to any supported container</emphasis>.  Keeping container-specific APIs out of the tests enables developers to verify application portability by running tests in a variety of containers. It also means that lightweight containers can be used as a substitute for full containers during development.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Tests should be executable from both the IDE and the build tool</emphasis>.  By leveraging the IDE, the developer can skip the build for a faster turnaround and has a familiar environment for debugging. These benefits shouldn’t sacrifice the ability to run the tests in continuous integration using a build tool.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">The platform should extend or integrate existing test frameworks</emphasis>.  An extensible architecture encourages reuse of existing software and fosters a unified Java testing ecosystem.  Regardless of how complex it becomes, executing an Arquillian test is as simple as selecting “Run As &gt; Test” in the IDE or executing the “test” goal from the build tool.
</simpara>
</listitem>
</itemizedlist>
<simpara><emphasis role="strong"><emphasis role="strong">NOTE: Get a better image for this</emphasis></emphasis>
<inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch02-enabling_technologies/shrinkwrap_runas_junit.png"/>
  </imageobject>
  <textobject><phrase>RunAs &gt; JUnit</phrase></textobject>
</inlinemediaobject></simpara>
</section>
<section id="_shrinkwrap">
<title>ShrinkWrap</title>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch02-enabling_technologies/shrinkwrap.png"/>
  </imageobject>
  <textobject><phrase>ShrinkWrap</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>From the onset, ShrinkWrap was born from a need to more easily test Java Enterprise deployments. Traditionally defined as flat-file archives adhering to the ZIP standard, these have necessitated the introduction of some build step to package up all application resources. And a build step takes time:</simpara>
<screen>$ mvn clean install
... terrifying output trace ...
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:13.492s
[INFO] ------------------------------------------------------------------------</screen>
<simpara>But as developers, we live in our coding environments. Switching out of that mindset to run a build is wasteful.  So we asked: "What if we could declare, in Java, an object to represent that archive?"  What resulted was a Java API analogue to the "jar" tool, a virtual filesystem with an intuitive syntax.</simpara>
<programlisting language="java" linenumbering="unnumbered">JavaArchive archive = ShrinkWrap.create(JavaArchive.class,"myarchive.jar")
   .addClasses(MyClass.class, MyOtherClass.class)
   .addResource("mystuff.properties");</programlisting>
<simpara>This enables us to take advantage of the IDE’s incremental compilation features, allowing us to skip the build.</simpara>
<itemizedlist>
<listitem>
<simpara>
NOTE: Get a better image for this
<inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch02-enabling_technologies/shrinkwrap_incremental_compilation.png"/>
  </imageobject>
  <textobject><phrase>ShrinkWrap Incremental Compilation</phrase></textobject>
</inlinemediaobject>
</simpara>
</listitem>
</itemizedlist>
<simpara>This piece fulfills the design goal of Arquillian to run tests based on full-fledged deployments directly from the IDE.</simpara>
<simpara>While ShrinkWrap is a standalone virtual filesystem, in our examples we&#8217;ll be primarily exercising it as the deployment mechanism for Arquillian.  Let&#8217;s take a moment to review its usage.</simpara>
<simpara>The first step is getting your hands on the ShrinkWrap binaries. The Core is composed of three pieces:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis>Name</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis>Maven Coordinates</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>API</simpara></entry>
<entry align="left" valign="top"><simpara>org.jboss.shrinkwrap:shrinkwrap-api</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>SPI</simpara></entry>
<entry align="left" valign="top"><simpara>org.jboss.shrinkwrap:shrinkwrap-spi</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Implementation</simpara></entry>
<entry align="left" valign="top"><simpara>org.jboss.shrinkwrap:shrinkwrap-impl-base</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Only the API should be available upon your compilation ClassPath, while the SPI and the Implementation modules are both required for the runtime. This is to enforce good separation between classes intended for direct use and the project’s internals.</simpara>
<simpara>In Maven, these may be brought in under the proper scopes easily by using the ShrinkWrap Dependency Chain POM, available in Maven Central:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;project xmlns="http://maven.apache.org/POM/4.0.0"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="
  http://maven.apache.org/POM/4.0.0
  http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
  &lt;!-- snip --&gt;

  &lt;dependency&gt;
    &lt;groupId&gt;org.jboss.shrinkwrap&lt;/groupId&gt;
    &lt;artifactId&gt;shrinkwrap-depchain&lt;/artifactId&gt;
    &lt;version&gt;${version.shrinkwrap}&lt;/version&gt;
    &lt;type&gt;pom&lt;/type&gt;
  &lt;/dependency&gt;

  &lt;!-- snip --&gt;
&lt;/project&gt;</programlisting>
<simpara>For projects outside use of the Maven repository system, the ShrinkWrap Distribution makes all modules available as a download, and you may set up the dependencies manually to suit your needs.</simpara>
<simpara><emphasis>Prerequisites</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>
JRE5+ Runtime
</simpara>
</listitem>
<listitem>
<simpara>
No additional dependencies
</simpara>
</listitem>
</itemizedlist>
<simpara>ShrinkWrap may run on any Java5 runtime or higher, but requires at least JDK6 for compilation.</simpara>
<simpara>The primary entry point to the ShrinkWrap library is the <literal>org.jboss.shrinkwrap.api.ShrinkWrap</literal> class.  From here you may call the <literal>create</literal> method to make a new <literal>Archive</literal>, the a generic view of the virtual filesystem which allows the addition of content called <literal>Asset</literal> s into a location called an <literal>ArchivePath</literal>.  The following table more easily shows ShrinkWrap nomenclature next to more common terms:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis>Archive Type</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis>Description</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.GenericArchive</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Simplest type of concrete user-view of an <literal>Archive</literal>; supports generic operations</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.spec.JavaArchive</literal></simpara></entry>
<entry align="left" valign="top"><simpara>JAR type; allows addition of <literal>Class</literal> es, <literal>Package</literal> s, and Manifest operations</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.spec.EnterpriseArchive</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Java EE EAR type; supports Manifest and related spec operations</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.spec.WebArchive</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Java EE WAR type; supports operations common to web application deployments</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.spec.ResourceAdaptorArchive</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Java EE RAR type; supports operations common to resource adaptor deployments</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>To create an <literal>Archive</literal>, simply choose your desired archive type and optionally supply a name to the static <literal>ShrinkWrap:create</literal> method:</simpara>
<programlisting language="java" linenumbering="unnumbered">GenericArchive myArchive = ShrinkWrap.create(GenericArchive.class,"myArchive.jar");</programlisting>
<simpara>That&#8217;s it!  You&#8217;ve got your first ShrinkWrap archive!</simpara>
<simpara>Of course, an object representing an empty archive is pretty useless.  So let&#8217;s have a look at adding in some content.  As we noted before, content is modeled by the <literal>Asset</literal> class, so let&#8217;s first take a look at some of the <literal>Asset</literal> implementations provided by ShrinkWrap:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis>Asset</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis>Represents</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.asset.ArchiveAsset</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Nested <literal>Archive</literal> content</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.asset.ByteArrayAsset</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>byte[]</literal> or <literal>InputStream</literal> content</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.asset.ClassAsset</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Java <literal>Class</literal> content</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.asset.ClassLoaderAsset</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A resource which can be loaded by an optionally-specified <literal>ClassLoader</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.asset.FileAsset</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>File</literal> content</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.asset.StringAsset</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>String</literal> content</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.asset.UrlAsset</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Content located at a given <literal>URL</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.asset.EmptyAsset</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Empty (0-byte) content</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Additionally, because <literal>Asset</literal> is an interface, you may provide your own implementation to supply any byte-based content that may be represented as an <literal>InputStream</literal> .  For instance, the snippet below shows how to present an Activation Framework <literal>DataSource</literal> as an <literal>Asset</literal> :</simpara>
<programlisting language="java" linenumbering="unnumbered">final DataSource dataSource = null; // Assume you have this
Asset asset = new Asset() {
  @Override
  public InputStream openStream() {
    try {
      return dataSource.getInputStream();
    } catch (final IOException e) {
      throw new RuntimeException(e);
    }
  }
};</programlisting>
<simpara>The <literal>Archive:add</literal> method allows us to pass in some <literal>Asset</literal> content and add it under an <literal>ArchivePath</literal>.</simpara>
<programlisting language="java" linenumbering="unnumbered">myArchive.add(myAsset,"path/to/content");
System.out.println(myArchive.toString(true));</programlisting>
<simpara>Passing a <literal>true</literal> verbosity flag into the <literal>toString</literal> method of <literal>Archive</literal> creates a recursive <literal>"ls -l"</literal> -style output:</simpara>
<screen>myArchive.jar:
/path/
/path/to/
/path/to/content</screen>
<simpara>The <literal>Archive</literal> views we covered before are also really helpful, depending upon the type of content you&#8217;re working with.  For instance, a standard JAR file typically contains <literal>.class</literal> files and other resources, so the <literal>JavaArchive</literal> type lets you add these.</simpara>
<simpara>ShrinkWrap supports a simple mechanism allowing you to switch "views" of your archive, and it&#8217;s provided by the <literal>as</literal> method of the <literal>org.jboss.shrinkwrap.api.Assignable</literal> interface; each view in turn extends <literal>Assignable</literal>. So in order to get your archive to use the <literal>JavaArchive</literal> view in order to easily add <literal>Class</literal> resources, you could simply:</simpara>
<programlisting language="java" linenumbering="unnumbered">myArchive.as(JavaArchive.class).addClasses(String.class, Integer.class);
System.out.println(myArchive.toString(true));</programlisting>
<screen>archive.jar:
/java/
/java/lang/
/java/lang/String.class
/java/lang/Integer.class</screen>
<simpara>Using this mechanism is central to keeping ShrinkWrap&#8217;s usage clean and intuitive, while providing for a versatility typically found in true multiple-inheritance languages.</simpara>
<simpara>While ShrinkWrap has its roots in Java EE and close ties to the Arquillian Testing Platform, it&#8217;s certainly not limited to these domains.  In fact, ShrinkWrap on its own intentionally scoped to go no further than act as a virtual filesystem for archives.  As such, it provides a simple mechanism for playing nicely with flat-file structures.</simpara>
<simpara>Borrowing from our example above, perhaps we&#8217;d like to use ShrinkWrap to package up all of the @.class@ files in the current package and output these as a standard JAR in ZIP format.  The code for that would actually be pretty simple:</simpara>
<programlisting language="java" linenumbering="unnumbered"> JavaArchive archive = ShrinkWrap.create(JavaArchive.class,
  "myPackage.jar").addPackage(this.getClass().getPackage());
  System.out.println(archive.toString(true));
  archive.as(ZipExporter.class).exportTo(
    new File("/home/alr/Desktop/myPackage.jar"), true);</programlisting>
<screen>myPackage.jar:
/org/
/org/alr/
/org/alr/test/
/org/alr/test/TestClass.class</screen>
<simpara>So let&#8217;s see what&#8217;s going on here.  First we create a <literal>JavaArchive</literal> and add all contents of the current <literal>Class</literal> 's <literal>Package</literal> . Then we dump the output to the console, just to see what&#8217;s included.  In the final line, we again use the <literal>Assignable</literal> facilities of the <literal>JavaArchive</literal> view to get us into a new view: one capable of exporting to ZIP format.  In this case we use the appropriately-named <literal>ZipExporter</literal>, allowing us to export to a <literal>File</literal>, <literal>OutputStream</literal>, or even get the contents as an <literal>InputStream</literal> so we can deal with the bytes ourselves.</simpara>
<simpara>There are 3 types of exporters which ship with ShrinkWrap:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis>Exporter</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis>Output Format</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.exporter.TarExporter</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TAR</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.exporter.TarGzExporter</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TAR.GZ</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.exporter.ZipExporter</literal></simpara></entry>
<entry align="left" valign="top"><simpara>ZIP</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Of course, we can also obtain a ShrinkWrap archive from a flat-file in a similar fashion by using one of the standard importers:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis>Importer</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis>Output Format</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.importer.TarImporter</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TAR</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.importer.TarGzImporter</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TAR.GZ</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.jboss.shrinkwrap.api.importer.ZipImporter</literal></simpara></entry>
<entry align="left" valign="top"><simpara>ZIP</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The code for running an import to roundtrip the previous example might look like this:</simpara>
<programlisting language="java" linenumbering="unnumbered"> JavaArchive roundtrip = ShrinkWrap
  .create(ZipImporter.class, "myPackageRoundtrip.jar")
  .importFrom(new File("/home/alr/Desktop/myPackage.jar"))
  .as(JavaArchive.class);</programlisting>
<simpara>Note how we can pass <literal>ZipImporter</literal> into the <literal>ShrinkWrap.create</literal> method, as it&#8217;s <literal>Assignable</literal> as well!  Beginning to notice a theme here?</simpara>
<simpara>This concludes our brief introduction into manipulating archive content with ShrinkWrap.</simpara>
</section>
<section id="_shrinkwrap_resolvers">
<title>ShrinkWrap Resolvers</title>
<simpara>While ShrinkWrap is ideally-suited to creating new archives containing byte-based resources, often our applications are composed from pre-built libraries into more complex deployments.  These may bundle other archives together, for instance in the following example <emphasis>Web application ARchive</emphasis> (WAR):</simpara>
<screen>$&gt; jar -tvf myApplication.war
     0 Tue Apr 23 17:01:08 MST 2013 META-INF/
   128 Tue Apr 23 17:01:06 MST 2013 META-INF/MANIFEST.MF
     0 Tue Apr 23 17:01:08 MST 2013 WEB-INF/
     0 Tue Apr 23 17:01:08 MST 2013 WEB-INF/classes/
     0 Tue Apr 23 17:01:08 MST 2013 WEB-INF/lib/
  3654 Tue Apr 23 16:59:44 MST 2013 WEB-INF/lib/hibernate.jar
  3800 Tue Apr 23 17:01:00 MST 2013 WEB-INF/lib/commons-io.jar
  4015 Tue Apr 23 17:00:44 MST 2013 WEB-INF/lib/myEjbModule.jar</screen>
<simpara>As we can see, under <literal>WEB-INF/lib</literal> there are a couple of thirdparty libraries used as dependencies by our own code, and an <emphasis>Enterprise JavaBeans</emphasis> (EJB) module that we&#8217;ve written for our application.  This packaging structure is consistent with the final deployments used by most WARs and <emphasis>Enterprise application ARchives</emphasis> (EARs).</simpara>
<simpara>Often we don&#8217;t control the construction of these libraries, and we certainly shouldn&#8217;t be in the business of re-assembling them (and hence further differentiating our tests from the our production runtime deployments).  With the advent of Maven and other build systems, typically thirdparty libraries and our own dependent modules are obtained from a backing software <emphasis>repository</emphasis>.  In this case we supply a series of coordinates which uniquely identifies an artifact in the repository, and resolve the target files from there.</simpara>
<simpara>That is precisely the aim of the ShrinkWrap Resolvers project; it is a Java API to obtain artifacts from a repository system.  Currently implemented are grammars and support for Maven-based repository structures (this is separate from the use of Maven as a project management system or build tool; it&#8217;s possible to use a Maven repository layout with other build systems).</simpara>
<simpara>ShrinkWrap Resolvers is comprised of the following modules:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis>Name</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis>Maven Coordinates</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>API</simpara></entry>
<entry align="left" valign="top"><simpara>org.jboss.shrinkwrap.resolver:shrinkwrap-resolver-api</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>SPI</simpara></entry>
<entry align="left" valign="top"><simpara>org.jboss.shrinkwrap.resolver:shrinkwrap-resolver-spi</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Maven API</simpara></entry>
<entry align="left" valign="top"><simpara>org.jboss.shrinkwrap.resolver:shrinkwrap-resolver-api-maven</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Maven SPI</simpara></entry>
<entry align="left" valign="top"><simpara>org.jboss.shrinkwrap.resolver:shrinkwrap-resolver-spi-maven</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Maven Implementation</simpara></entry>
<entry align="left" valign="top"><simpara>org.jboss.shrinkwrap.resolver:shrinkwrap-resolver-impl-maven</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Maven Implementation with Archive Integration</simpara></entry>
<entry align="left" valign="top"><simpara>org.jboss.shrinkwrap.resolver:shrinkwrap-resolver-impl-maven-archive</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The separation between the Maven and non-Maven modules is there to enforce modular design and separate out generic resolution from Maven-specific grammars, should the project support other mechanisms in the future.</simpara>
<section id="_adding_shrinkwrap_resolvers_to_your_project">
<title>Adding ShrinkWrap Resolvers to Your Project</title>
<simpara>Obtaining ShrinkWrap Resolvers for use in your system can be done in a single pass by declaring a dependency upon the <literal>depchain</literal> module in a Maven <emphasis>pom.xml</emphasis>:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;dependencies&gt;
    ...
    &lt;dependency&gt;
      &lt;groupId&gt;org.jboss.shrinkwrap.resolver&lt;/groupId&gt;
      &lt;artifactId&gt;shrinkwrap-resolver-depchain&lt;/artifactId&gt;
      &lt;version&gt;${version.shrinkwrap.resolvers}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
      &lt;type&gt;pom&lt;/type&gt;
    &lt;/dependency&gt;
    ...
&lt;/dependencies&gt;</programlisting>
<simpara>This will bring the APIs into the test classpath and the SPIs and Implementation modules into the runtime classpaths (which will not be transitively inherited, as per Maven rules in <literal>runtime</literal> scope).</simpara>
<simpara>Alternatively, you may have finer-grained control over using ShrinkWrap Resolvers by bringing in each module manually:</simpara>
<programlisting language="xml" linenumbering="unnumbered"> &lt;dependencies&gt;
    ...
    &lt;dependency&gt;
      &lt;groupId&gt;org.jboss.shrinkwrap.resolver&lt;/groupId&gt;
      &lt;artifactId&gt;shrinkwrap-resolver-api&lt;/artifactId&gt;
      &lt;version&gt;${version.shrinkwrap.resolvers}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.jboss.shrinkwrap.resolver&lt;/groupId&gt;
      &lt;artifactId&gt;shrinkwrap-resolver-spi&lt;/artifactId&gt;
      &lt;version&gt;${version.shrinkwrap.resolvers}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.jboss.shrinkwrap.resolver&lt;/groupId&gt;
      &lt;artifactId&gt;shrinkwrap-resolver-api-maven&lt;/artifactId&gt;
      &lt;version&gt;${version.shrinkwrap.resolvers}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.jboss.shrinkwrap.resolver&lt;/groupId&gt;
      &lt;artifactId&gt;shrinkwrap-resolver-spi-maven&lt;/artifactId&gt;
      &lt;version&gt;${version.shrinkwrap.resolvers}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.jboss.shrinkwrap.resolver&lt;/groupId&gt;
      &lt;artifactId&gt;shrinkwrap-resolver-impl-maven&lt;/artifactId&gt;
      &lt;version&gt;${version.shrinkwrap.resolvers}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.jboss.shrinkwrap.resolver&lt;/groupId&gt;
      &lt;artifactId&gt;shrinkwrap-resolver-impl-maven-archive&lt;/artifactId&gt;
      &lt;version&gt;${version.shrinkwrap.resolvers}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    ...
  &lt;/dependencies&gt;</programlisting>
<important>
<simpara>If you happen to use Arquillian BOM in <literal>&lt;dependencyManagement&gt;</literal>, it already contains a ShrinkWrap Resolvers version. You must import ShrinkWrap Resolvers BOMs preceding Arquillian BOM in order to get 2.0.0-x version. Adding a ShrinkWrap BOM is recommended in any case.</simpara>
<simpara>The ShrinkWrap Resolver BOM may be imported via following snippet:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;dependencyManagement&gt;
  &lt;dependencies&gt;
    ...
    &lt;!-- Override dependency resolver with latest version.
         This must go *BEFORE* the Arquillian BOM. --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.jboss.shrinkwrap.resolver&lt;/groupId&gt;
      &lt;artifactId&gt;shrinkwrap-resolver-bom&lt;/artifactId&gt;
      &lt;version&gt;${version.shrinkwrap.resolvers}&lt;/version&gt;
      &lt;scope&gt;import&lt;/scope&gt;
      &lt;type&gt;pom&lt;/type&gt;
    &lt;/dependency&gt;
    ...
  &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;</programlisting>
</important>
<simpara>The general entry point for resolution is the convenience <literal>org.jboss.shrinkwrap.resolver.api.maven.Maven</literal> class, which has static hooks to obtain a new <literal>org.jboss.shrinkwrap.resolver.api.maven.MavenResolverSystem</literal>.
Let&#8217;s cover some of the most popular use cases for ShrinkWrap Resolver.</simpara>
</section>
<section id="_resolution_of_artifacts_specified_by_maven_coordinates">
<title>Resolution of Artifacts Specified by Maven Coordinates</title>
<simpara>Maven coordinates, in their canonical form, are specified as following <literal>groupId:artifactId:[packagingType:[classifier]]:version</literal>. Often, those are referred as <literal>G</literal> (groupId), <literal>A</literal> (artifactId), <literal>P</literal> (packagingType), <literal>C</literal> (classifier) and <literal>V</literal> (version). If you omit <literal>P</literal> and <literal>C</literal>, they will get their default value, which is packaging of <literal>jar</literal> and an empty classifier. ShrinWrap Resolver additionally allows you to skip <literal>V</literal> in case it has version information available, that would be explained later on.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
The most simple use case is to resolve a file using coordinates. Here, the resolver locates an artifact defined by <literal>G:A:V</literal> and resolves it including all transitive dependencies. The result is formatted as array of type <literal>File</literal>.
</simpara>
<programlisting language="java" linenumbering="unnumbered">File[] = Maven.resolver().resolve("G:A:V").withTransitivity().asFile();</programlisting>
</listitem>
<listitem>
<simpara>
You might want to change default Maven behavior and resolve only artifact specified by <literal>G:A:V</literal>, avoiding its transitive dependencies. For this use case, ShrinkWrap Resolvers provides a shorthand for changing resolution strategy, called <literal>withoutTransitivity()</literal>. Additionally, you might want to return a single <literal>File</literal> instead of an array.
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().resolve("G:A:V").withoutTransitivity().asSingleFile();</programlisting>
</listitem>
<listitem>
<simpara>
Very often, you need to resolve more than one artifact. The method <literal>resolve(String&#8230;)</literal> allows you to specify many artifacts at the same time. The result of the call will be an array of <literal>File</literal> composed by artifacts defined by <literal>G1:A1:V1</literal> and <literal>G2:A2:V2</literal> including their transitive dependencies.
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().resolve("G1:A1:V1", "G2:A1:V1").withTransitivity().asFile();</programlisting>
</listitem>
<listitem>
<simpara>
Resolving a dependency with specific packaging type. Packaging type is specified by <literal>P</literal> in <literal>G:A:P:V</literal> coordinates description.
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().resolve("G:A:war:V").withTransitivity().asFile();</programlisting>
<simpara>Packaging can be of any type; the most common are listed in following table.</simpara>
<table
frame="all"
rowsep="1" colsep="1"
>
<title>Packaging types</title>
<tgroup cols="9">
<colspec colname="col_1" colwidth="11*"/>
<colspec colname="col_2" colwidth="11*"/>
<colspec colname="col_3" colwidth="11*"/>
<colspec colname="col_4" colwidth="11*"/>
<colspec colname="col_5" colwidth="11*"/>
<colspec colname="col_6" colwidth="11*"/>
<colspec colname="col_7" colwidth="11*"/>
<colspec colname="col_8" colwidth="11*"/>
<colspec colname="col_9" colwidth="11*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>jar</simpara></entry>
<entry align="left" valign="top"><simpara>war</simpara></entry>
<entry align="left" valign="top"><simpara>ear</simpara></entry>
<entry align="left" valign="top"><simpara>ejb</simpara></entry>
<entry align="left" valign="top"><simpara>rar</simpara></entry>
<entry align="left" valign="top"><simpara>par</simpara></entry>
<entry align="left" valign="top"><simpara>pom</simpara></entry>
<entry align="left" valign="top"><simpara>test-jar</simpara></entry>
<entry align="left" valign="top"><simpara>maven-plugin</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</listitem>
<listitem>
<simpara>
Resolving a dependency with specific classifier. With a classifier, such as <literal>tests</literal>, you need to include all <literal>G:A:P:C:V</literal> parts of coordinates string.
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().resolve("G:A:test-jar:tests:V").withTransitivity().asFile();</programlisting>
</listitem>
<listitem>
<simpara>
Returning resolved artifacts as different type than file. ShrinkWrap Resolvers provides shorthands for returning an <literal>InputStream</literal> instead of <literal>File</literal>. Additionally, with <literal>shrinkwrap-resolver-maven-impl-archive</literal> on the runtime classpath, you may additionally return results as ShrinkWrap archives, such as <literal>JavaArchive</literal>, <literal>WebArchive</literal> or <literal>EnterpriseArchive</literal>.
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().resolve("G:A:V").withTransitivity().as(File.class);
Maven.resolver().resolve("G:A:V").withTransitivity().as(InputStream.class);
Maven.resolver().resolve("G:A:V").withTransitivity().as(JavaArchive.class);
Maven.resolver().resolve("G:A:war:V").withoutTransitivity().asSingle(WebArchive.class);</programlisting>
<note>
<simpara>It&#8217;s the responsibility of caller to close the returned <literal>InputStream</literal>.</simpara>
</note>
</listitem>
<listitem>
<simpara>
Working with artifact metadata. Sometimes, you are more interested in metadata, such as dependencies of a given artifacts instead of artifact itself. ShrinkWrap Resolvers provides an API for such use cases:
</simpara>
<programlisting language="java" linenumbering="unnumbered">MavenResolvedArtifact artifact = Maven.resolver().resolve("G:A:war:V")
  .withoutTransitivity().asSingle(MavenResolvedArtifact.class);

MavenCoordinate coordinates = artifact.getCoordinate();
MavenArtifactInfo[] dependencies = artifact.getDependencies();
String version = artifact.getResolvedVersion();
ScopeType scope = artifact.getScope();</programlisting>
<simpara>You can still retrieve resolved artifact from <literal>MavenResolvedArtifact</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">File file = artifact.asFile();</programlisting>
</listitem>
<listitem>
<simpara>
Excluding a dependency of the artifact you want to resolve. In case you need to resolve an artifact while avoiding some of its dependencies, you can follow concept of <literal>&lt;exclusions&gt;</literal> known for Maven. The following shows how to exclude <literal>G:B</literal> while resolving <literal>G:A:V</literal>.
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver()
  .addDependencies(
    MavenDependencies.createDependency("G:A:V", ScopeType.COMPILE, false,
      MavenDependencies.createExclusion("G:B"))).resolve().withTransitivity().asFile();</programlisting>
</listitem>
<listitem>
<simpara>
Using a strategy to control what will be resolved. In special cases, excluding a single dependency is not the behaviour you want to achieve. For instance, you want to resolve all test scoped dependencies of an artifact, you want to completely avoid some dependency while resolving multiple artifacts or maybe you&#8217;re interested in optional dependencies. For those cases, ShrinkWrap Resolvers allows you to specify a <literal>MavenResolutionStrategy</literal>. For instance, you can exclude <literal>G:B</literal> from <literal>G:A:V</literal> (e.g. the same as previous examples) via following snippet:
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().resolve("G:A:V").using(
  new RejectDependenciesStrategy(false, "G:B")).asFile();</programlisting>
<note>
<simpara>Methods <literal>withTransitivity()</literal> and <literal>withoutTransitivity()</literal> are just a convenience methods to avoid you writing down strategy names. The first one calls <literal>TransitiveStrategy</literal> while the latter calls <literal>NotTransitiveStrategy</literal>.</simpara>
</note>
<simpara>Strategies are composed of an array of <literal>MavenResolutionFilter</literal> instances and <literal>TransitiveExclusionPolicy</literal> instance. While defining the first allows you to transform dependency graph of resolved artifacts, the latter allows you to change default behavior when resolving transitive dependencies. By default, Maven does not resolve any dependencies in <emphasis>provided</emphasis> and <emphasis>test</emphasis> scope and it also skips <emphasis>optional</emphasis> dependencies. ShrinkWrap resolver behaves the same way by default, but allows you to change that behaviour. This comes handy especially if when you want to for instance resolve all provided dependencies of <literal>G:A:V</literal>. For your convenience, ShrinkWrap Resolvers ships with strategies described in following table.</simpara>
<table
frame="all"
rowsep="1" colsep="1"
>
<title>Strategies available in ShrinkWrap Resolver</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="75*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>AcceptAllStrategy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Accepts all dependencies of artifacts. Equals <literal>TransitiveStrategy</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>AcceptScopesStrategy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Accepts only dependencies that have defined scope type.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>CombinedStrategy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>This allows you to combine multiple strategies together. The behaviour defined as logical AND between combined strategies.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>NonTransitiveStrategy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Rejects all dependencies that were not directly specified for resolution. This means that all transitive dependencies of artifacts for resolution are rejected.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>RejectDependenciesStrategy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Rejects dependencies defined by <literal>G:A</literal> (version is not important for comparison, so it can be omitted altogether). By default, it is transitive: <literal>RejectDependenciesStrategy("G:A", "G:B")</literal> means that all dependencies that origin at <literal>G:A</literal> or <literal>G:B</literal> are removed as well. If you want to change that behavior to reject defined dependencies but to keep their descendants, instantiate strategy as following: <literal>RejectDependenciesStrategy(false, "G:A", "G:B")</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>TransitiveStrategy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Acceps all dependencies of artifacts. Equals <literal>AcceptAllStrategy</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</listitem>
<listitem>
<simpara>
Control sources of resolution. ShrinkWrap Resolvers allows you to specify where do you want to resolve artifacts from. By default, it uses classpath (also known as Maven Reactor) and Maven Central repository, however you can programmatically alter the behavior.
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().resolve("G:A:V").withClassPathResolution(false)
  .withTransitivity().asFile();
Maven.resolver().resolve("G:A:V").withMavenCentralRepo(false)
  .withTransitivity().asFile();
Maven.resolver().offline().resolve("G:A:V")
  .withTransitivity().asFile();</programlisting>
<simpara>While classpath resolution is handy for testing SNAPSHOT artifacts that are not yet installed in any of the Maven repository, making ShrinkWrap Resolvers offline avoids accessing any repositories but local cache.</simpara>
</listitem>
<listitem>
<simpara>
While controlling classpath resolution and Maven Central comes handy, sometimes you might want to specify completely different <emphasis>settings.xml</emphasis> file than default for your test execution. This can be done via following API calls:
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.configureResolver().fromFile("/path/to/settings.xml")
  .resolve("G:A:V").withTransitivity().asFile();

Maven.configureResolver().fromClassloaderResource("path/to/settings.xml")
  .resolve("G:A:V").withTransitivity().asFile();</programlisting>
<warning>
<simpara>ShrinkWrap Resolvers will not consume settings.xml specified on command line (<literal>-s settings.xml</literal>) or in the IDE. It reads settings.xml files at their standard locations, which are <literal>~/.m2/settings.xml</literal> and <literal>$M2_HOME/conf/settings.xml</literal> unless overridden in the API or via a System Property.</simpara>
</warning>
</listitem>
</orderedlist>
</section>
<section id="_resolution_of_artifacts_defined_in_pom_files">
<title>Resolution of Artifacts Defined in POM Files</title>
<simpara>While previous calls allow you to manually define what you want to resolve, in Maven projects, you have very likely specified this information already in your <emphasis>pom.xml</emphasis> file. ShrinkWrap Resolver allows you to follow <emphasis>DRY</emphasis> principles and it is able to load metadata included there.</simpara>
<simpara>ShrinkWrap Resolvers constructs so called effective POM model (simplified, that is your <emphasis>pom.xml</emphasis> file plus parent hierarchy and Super POM, Maven default POM file). In order to construct the model, it uses all local repository, classpath repository and remote repositories. Once the model is loaded, you can use the metadata in there to be automatically added to artifacts to be resolved.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
Resolving an artifact with version defined in effective POM. In case, you want to resolve <literal>G:A:V</literal>, you can simply specify <literal>G:A</literal> instead. For artifacts with non JAR packaging type or classifier, you must use alternative syntax with question mark <emphasis><literal>?</literal></emphasis>, such as <literal>G:A:P:?</literal> or <literal>G:A:P:C:?</literal>.
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().loadPomFromFile("/path/to/pom.xml")
  .resolve("G:A").withTransitivity().asFile();

Maven.resolver().loadPomFromClassLoaderResource("/path/to/pom.xml")
  .resolve("G:A:P:?").withTransitivity().asFile();</programlisting>
</listitem>
<listitem>
<simpara>
Resolving artifacts defined in effective POM. ShrinkWrap Resolvers allows you to artifacts defined with specific scope into list of artifacts to be resolved. This way, you don&#8217;t need to alter your tests if you change dependencies of your application. You can either use <literal>importDependencies(ScopeType&#8230;)</literal> or convenience methods, that cover the most frequent usages (<literal>importRuntimeDependencies()</literal>, <literal>importTestDependencies()</literal> and <literal>importRuntimeAndTestDependencies()</literal>:
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().loadPomFromFile("/path/to/pom.xml")
  .importDependencies(ScopeType.TEST, ScopeType.PROVIDED)
  .resolve().withTransitivity().asFile();

Maven.resolver().loadPomFromFile("/path/to/pom.xml").importRuntimeDependencies()
  .resolve().withTransitivity().asFile();</programlisting>
<tip>
<simpara>"Runtime" in convenience methods means all the Maven scopes that are used in application runtime, which are <literal>compile</literal>, <literal>runtime</literal>, <literal>import</literal> and <literal>system</literal>. If you need to select according to Maven scopes, go for <literal>importDependencies(ScopeType&#8230;)</literal> instead.</simpara>
</tip>
</listitem>
<listitem>
<simpara>
Specifying plugins to be activated. By default, ShrinkWrap Resolvers activates profiles based on property value, file presence, active by default profiles, operating system and JDK. However, you can force profiles in same way as you would do via <literal>-P</literal> in Maven.
</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.resolver().loadPomFromFile(
  "/path/to/pom.xml", "activate-profile-1", "!disable-profile-2")
  .importRuntimeAndTestDependencies().resolve().withTransitivity().asFile();</programlisting>
</listitem>
</orderedlist>
</section>
<section id="_system_properties">
<title>System Properties</title>
<simpara>ShrinkWrap Resolvers allows you to override any programmatic configuration via System Properties.</simpara>
<table
frame="all"
rowsep="1" colsep="1"
>
<title>System Properties altering behavior of ShrinkWrap Resolvers</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="66*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>org.apache.maven.user.settings</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Path to user  <emphasis>settings.xml</emphasis> file. In case both settings are provided, they are merged, user one has the priority.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.apache.maven.global-settings</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Path to global <emphasis>settings.xml</emphasis> file. In case both settings are provided, they are merged, user one has the priority.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.apache.maven.security-settings</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Path to <emphasis>settings-security.xml</emphasis>, that contains encrypted master password for password protected Maven repositories.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>org.apache.maven.offline</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Flag there to work in offline mode.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>maven.repo.local</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Path to local repository with cached artifacts. Overrides value defined in any of the <emphasis>settings.xml</emphasis> files.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section id="_experimental_features">
<title>Experimental features</title>
<warning>
<simpara>The following features are in their early development stages. However, they should work for the most common use cases. Feel free to report a bug in <ulink url="https://issues.jboss.org/browse/SHRINKRES">SHRINKRES</ulink> project if that is not your case.</simpara>
</warning>
</section>
<section id="_shrinkwrap_resolver_maven_plugin">
<title>ShrinkWrap Resolver Maven Plugin</title>
<simpara>The ShrinkWrap Resolver Maven plugin allows you to propagate settings specified on the command line into test execution. Settings comprises of: paths to the <emphasis>pom.xml</emphasis> file and <emphasis>settings.xml</emphasis> files, activated/disabled profiles, offline flag and path to local repository. No support for IDE exists at this moment.</simpara>
<simpara>In order to activate the plugin, you need to add following snippet into <literal>&lt;build&gt;</literal> section of your <emphasis>pom.xml</emphasis> file.</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;plugin&gt;
  &lt;groupId&gt;org.jboss.shrinkwrap.resolver&lt;/groupId&gt;
  &lt;artifactId&gt;shrinkwrap-resolver-maven-plugin&lt;/artifactId&gt;
  &lt;version&gt;${version.shrinkwrap.resolvers}&lt;/version&gt;
  &lt;executions&gt;
    &lt;execution&gt;
      &lt;goals&gt;
        &lt;goal&gt;propagate-execution-context&lt;/goal&gt;
      &lt;/goals&gt;
    &lt;/execution&gt;
  &lt;/executions&gt;
&lt;/plugin&gt;</programlisting>
<simpara>Then, in your test you can do the following:</simpara>
<programlisting language="java" linenumbering="unnumbered">Maven.configureResolverViaPlugin().resolve("G:A").withTransitivity().asFile();</programlisting>
</section>
<section id="_maven_importer">
<title>Maven Importer</title>
<simpara>The <literal>MavenImporter</literal> is the most advanced feature of ShrinkWrap Resolvers. Instead of the user being responsible for specifying how testing archive should look like, it reuses information defined in your <emphasis>pom.xml</emphasis> in order to construct the archive. So, no matter how your project looks like, you can get a full archive, as you would deploy it into the application server within a single like of code.</simpara>
<simpara>MavenImporter is able to compile sources, construct <emphasis>MANIFEST.MF</emphasis>, fetch the dependencies and construct archive as Maven would do. It does not required any data to be prepared by Maven, however it can profit from those if they exist.</simpara>
<programlisting language="java" linenumbering="unnumbered">ShrinkWrap.create(MavenImporter.class)
  .loadPomFromFile("/path/to/pom.xml").importBuildOutput().as(WebArchive.class);

ShrinkWrap.create(MavenImporter.class)
  .loadPomFromFile("/path/to/pom.xml", "activate-profile-1", "!disable-profile-2")
  .importBuildOutput().as(WebArchive.class);

ShrinkWrap.create(MavenImporter.class).configureFromFile("/path/to/settings.xml")
  .loadPomFromFile("/path/to/pom.xml").importBuildOutput().as(JavaArchive.class);</programlisting>
<important>
<simpara><literal>MavenImporter</literal> does not currently support other packagings but JAR and WAR. Also, it does not honor many of Maven plugins, currently it supports their limited subset.</simpara>
<simpara>Additionally, using different JDK for running tests and compiling sources is not supported, although it should work if you are for instance compiling sources targeting JDK6 while being bootstrapped on JDK7.</simpara>
</important>
<simpara>By enabling resolution in a friendly, intuitive API, ShrinkWrap Resolvers arms ShrinkWrap archives with a powerful mechanism to create deployment units which are applicable in real-world scenarios that demand libraries and modules not owned by the current project.</simpara>
</section>
</section>
</section>
<section id="_runtime">
<title>Runtime</title>
<simpara>Being simply a component model, Java EE needs a concrete implementation to provide the runtime services to our applications.</simpara>
<section id="_wildfly">
<title>WildFly</title>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch02-enabling_technologies/wildfly.png"/>
  </imageobject>
  <textobject><phrase>WildFly</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>The latest community edition of the application server offered by JBoss has recently been renamed to <ulink url="http://wildfly.org/"><emphasis>WildFly</emphasis></ulink>, and this will be the default target runtime for our examples.  Written from the ground up, WildFly (previously-known as <emphasis>JBoss Application Server 7</emphasis>) was designed with the following goals at the core:</simpara>
<itemizedlist>
<listitem>
<simpara>
<emphasis role="strong">Speed</emphasis>.  Startup, deployment, and request processing demands leverage a concurrent state machine and constant-time ClassLoading.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Efficiency</emphasis>.  Memory usage is kept to a minimum.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Modularity</emphasis>.  Application libraries and server libraries are isolated from one another to avoid runtime conflicts
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Administration</emphasis>.  Centralized settings via Web Interface, HTTP, Java, and Command-Line APIs
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Compliance</emphasis>.  <ulink url="http://fedoraproject.org/wiki/Features/JBossAS7#Strict_Compliance">Java EE6 Full Profile Certification</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Testable</emphasis>.  Uses Arquillian and ShrinkWrap in its own internal test suite
</simpara>
</listitem>
</itemizedlist>
<simpara>Because a quick feedback loop is important in testing during development, the speed afforded by WildFly makes it a compelling candidate for our target runtime:</simpara>
<screen>19:16:06,662 INFO  [org.jboss.as] (Controller Boot Thread)
 JBAS015874: WildFly 8.0.0.Alpha2 "WildFly" started in 2702ms -
 Started 153 of 189 services (56 services are lazy, passive or on-demand)</screen>
<simpara>The online User Guide for WildFly is located at <ulink url="https://docs.jboss.org/author/display/WFLY8/Documentation">https://docs.jboss.org/author/display/WFLY8/Documentation</ulink>.</simpara>
</section>
<section id="_openshift">
<title>OpenShift</title>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch02-enabling_technologies/openshift.png"/>
  </imageobject>
  <textobject><phrase>OpenShift</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>While getting our applications running on our own machine is a great step in developing, the beauty of the internet is that we can expose our content and services to the world at large.  Until very recently, Java EE hosting typically involved a dedicated and expensive server colocated in a data center.  With the rapid advent of virtualization and the Cloud, we&#8217;re now able to gain public access much more easily, and at far reduced cost.</simpara>
<simpara><ulink url="http://www.openshift.com"><emphasis>OpenShift</emphasis></ulink> is Red Hat&#8217;s free Platform as a Service (PaaS) for applications.  While it supports a variety of frameworks bundled as "cartridges", we&#8217;ll be using OpenShift&#8217;s built-in JBossAS7 support.  With just a little bit of initial setup, pushing changes from our local Git repository to the OpenShift remote will trigger a build and deployment of our application for all to see.  We&#8217;ll be relieved of the responsibility to obtain a server, install JBossAS, configure the networking and firewalls, or manually deploy new versions.</simpara>
</section>
</section>
<section id="_on_to_the_code">
<title>On to the Code</title>
<simpara>Now that we&#8217;ve familiarized ourselves with the technologies we&#8217;ll be using throughout the exercises, let&#8217;s dig in and create a new Java EE application, making it public to the world.</simpara>
</section>
</section>
<section id="_scratch_to_production">
<title>Scratch to Production</title>
<simpara><emphasis>"The way to get started is to quit talking and begin doing." - Walt Disney</emphasis></simpara>
<simpara>Enterprise Java has long suffered the (possibly correct) critique that it&#8217;s difficult to bootstrap a new project.  Couple the lack of definitive jumpstart documentation with vendor-specific techniques for application deployment, throw a mess of 3rd-party dependencies into the mix, and we&#8217;ve got a prime recipe yielding barriers to entry for programmers new to web development in Java.</simpara>
<simpara>Of course, this all runs contrary to the mission of Java EE: to make our experience with enterprise features <emphasis>easier</emphasis>.  So while the programming model has certainly evolved past the days of confusingly verbose and explicitly-required metadata, the warts which lead to frustrating stack traces and unexpected deployment behaviors unfortunately persist.</simpara>
<simpara>Some of this is by design.  The Specifications which comprise the Java EE Platform intentionally leave room for vendors to implement features like server startup and deployment at their discretion <footnote><simpara>While there is some limited facility to, for instance, create an EJB container in a running JVM and bring EJB deployments on the classpath into service, a full-scale deployment is still typically achieved in a vendor-specific manner</simpara></footnote>.</simpara>
<simpara>In the interest of providing a uniformly-workable solution to the reader, this text will routinely opt for vendor-specific approaches in favor of generic guidelines.  By the end of this chapter, you should be comfortable creating a new Java EE Web Application and pushing it live to production using a few tools and services offered by the JBoss Community.</simpara>
<section id="_the_development_environment">
<title>The Development Environment</title>
<simpara>While all projects used here are ultimately standalone and require no plugins or special environments aside from a Java runtime, we&#8217;re going to make our lives easier by taking advantage of the integration facilities provided by JBoss Developer Studio (JBDS).</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch03-scratch_to_production/jbds.png"/>
  </imageobject>
  <textobject><phrase>JBoss Developer Studio</phrase></textobject>
</inlinemediaobject><emphasis>(TODO: Get an updated approved image)</emphasis></simpara>
<simpara>The JBDS plugins atop the Eclipse Integrated Development Environment (IDE) will unify our development experience and allow us to stay inside one window.  Installation is via an executable JAR available from the <ulink url="https://devstudio.jboss.com/earlyaccess/builds/stable/6.0.0.GA/jbdevstudio-product-universal-6.0.0.GA-v20121206-1855-B186.jar">JBDS Site</ulink> <emphasis>TODO Examine link and ensure it&#8217;s up-to-date before final publication</emphasis>.</simpara>
<simpara>To kick off the installation process, either double-click the icon (if your environment has the ".jar" extension correctly associated as a Java executable) or launch the installer from the command line via the Java runtime:</simpara>
<screen>$&gt; java -jar jbdevstudio-product-universal-6.0.0.GA-v20121206-1855-B186.jar</screen>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch03-scratch_to_production/jbds_install.png"/>
  </imageobject>
  <textobject><phrase>JBoss Developer Studio Installation</phrase></textobject>
</inlinemediaobject><emphasis>(TODO: Ensure version is correct)</emphasis></simpara>
<simpara>Following the graphical wizard will install the JDBS (and all requisite plugins we&#8217;ll be using) IDE onto your local machine.</simpara>
</section>
<section id="_a_new_project">
<title>A New Project</title>
<simpara>The previous chapter introduced us to JBoss Forge, a tool that aims to make project creation and enhancement more declarative and less manual.  As we&#8217;re starting fresh now, it makes sense to use Forge to create our project layout.  This will ultimately give us a functional skeleton from database to view layer which we can use either as a learning tool or a quick shortcut to writing some real code.</simpara>
<simpara>Forge&#8217;s user interface is a shell, so it can be installed manually and used from the terminal like any other command-line application.  However, JBDS removes the need for us to do this setup.  Selecting <literal>Window &gt; Show View &gt; Other&#8230;</literal> will give us immediate access to the Forge Console:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch03-scratch_to_production/window_forge_console.png"/>
  </imageobject>
  <textobject><phrase>Forge Console View Selection</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>With our new <emphasis>Forge Console</emphasis> view, we&#8217;re now free to start up the Forge runtime, which came embedded with the JBDS installation.  Pressing the green "Play" button will give us access to the Forge shell.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch03-scratch_to_production/start_forge.png"/>
  </imageobject>
  <textobject><phrase>Start Forge</phrase></textobject>
</inlinemediaobject></simpara>
<screen>    _____
   |  ___|__  _ __ __ _  ___
   | |_ / _ \| `__/ _` |/ _ \  \\
   |  _| (_) | | | (_| |  __/  //
   |_|  \___/|_|  \__, |\___|
                   |___/

JBoss Forge, version [ 1.0.6.Final ] - JBoss, by Red Hat, Inc. [ http://jboss.org/forge ]
[no project] pwd $</screen>
<simpara>JBDS integration with Forge is especially useful in this console as the IDE will automatically refresh any changes we make in Forge with our project view and open text editors.</simpara>
<simpara>As a decent shell, Forge support tab-complete of commands and known parameters; if you get stuck, feel free to use the <literal>TAB</literal> key to see what&#8217;s available.</simpara>
<simpara>To ease up on our configuration options, let&#8217;s first start off by instructing Forge to accept defaults:</simpara>
<screen>$&gt; set ACCEPT_DEFAULTS true;</screen>
<simpara>And now let&#8217;s create the filesystem layout and <literal>pom.xml</literal> for our new Maven-based Java EE project.  We&#8217;ll be creating a simple application which will allow users to leave comments, so we&#8217;ll name the application, "feedback":</simpara>
<screen>$&gt; new-project --named feedback --topLevelPackage org.cedj.ch03.feedback --projectFolder feedback;</screen>
<simpara>Once we hit enter, we&#8217;ll see that Forge has dutifully created our new project&#8217;s layout:</simpara>
<screen>***SUCCESS*** Created project [feedback] in new working directory [./feedback]
Wrote ./feedback
Wrote ./feedback/pom.xml
Wrote ./feedback/src/main/java
Wrote ./feedback/src/test/java
Wrote ./feedback/src/main/resources
Wrote ./feedback/src/test/resources
Wrote ./feedback/src/main/java/org/cedj/feedback
Wrote ./presentations/feedback/src/main/resources/META-INF/forge.xml</screen>
<simpara>Additionally, our project has appeared in the Project View:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch03-scratch_to_production/project_created.png"/>
  </imageobject>
  <textobject><phrase>Project Created</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Users of <ulink url="http://maven.apache.org/guides/introduction/introduction-to-archetypes.html">Maven Archetypes</ulink> may be familiar with this type of technique to create a new project, but as Forge is an <emphasis>incremental</emphasis> tool, it&#8217;s capable of reading a project&#8217;s state and adding behaviors after creation.</simpara>
<simpara>Let&#8217;s add support for Java Persistence (JPA) to our project, a task that typically would involve some searching for the correct dependencies for the spec APIs (as well as those for any vendor-specific extensions).  Forge is helpful here as well, via its <literal>persistence</literal> plugin:</simpara>
<screen>$&gt; persistence setup --provider HIBERNATE --container JBOSS_AS7;</screen>
<simpara>In this case we&#8217;ve chosen <ulink url="http://www.hibernate.org/">Hibernate</ulink> as our persistence provider, and have targeted JBoss AS7 as our container.  Forge will equip our POM with the proper dependencies and supply us with a default <literal>persistence.xml</literal> preconfigured to work with the AS7 runtime.  Remember, for a list of supported options, look to <literal>TAB</literal> completion.</simpara>
<screen>***SUCCESS*** Installed [forge.spec.jpa] successfully.
***INFO*** Setting transaction-type="JTA"
***INFO*** Using example data source [java:jboss/datasources/ExampleDS]
***SUCCESS*** Persistence (JPA) is installed.
Wrote ./feedback/src/main/resources/META-INF/persistence.xml
Wrote ./feedback/pom.xml</screen>
<simpara>A peek into the generated <literal>persistence.xml</literal> will show us a decent default configuration:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;
&lt;persistence xmlns="http://java.sun.com/xml/ns/persistence" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="2.0" xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"&gt;
  &lt;persistence-unit name="forge-default" transaction-type="JTA"&gt;
    &lt;description&gt;Forge Persistence Unit&lt;/description&gt;
    &lt;provider&gt;org.hibernate.ejb.HibernatePersistence&lt;/provider&gt;
    &lt;jta-data-source&gt;java:jboss/datasources/ExampleDS&lt;/jta-data-source&gt;
    &lt;exclude-unlisted-classes&gt;false&lt;/exclude-unlisted-classes&gt;
    &lt;properties&gt;
      &lt;property name="hibernate.hbm2ddl.auto" value="create-drop"/&gt;
      &lt;property name="hibernate.show_sql" value="true"/&gt;
      &lt;property name="hibernate.format_sql" value="true"/&gt;
      &lt;property name="hibernate.transaction.flush_before_completion" value="true"/&gt;
    &lt;/properties&gt;
  &lt;/persistence-unit&gt;
&lt;/persistence&gt;</programlisting>
<simpara>Let&#8217;s make one tweak; the property <literal>hibernate.hbm2ddl.auto</literal> is set to automatically drop the database tables such that they won&#8217;t be able to be reused across deployments.  While this might be handy in development to ensure you&#8217;re always coding from a clean slate, we&#8217;d actually like to use some real persistence later on, so let&#8217;s change that property to a value of <literal>update</literal>.</simpara>
<simpara>Java EE6 introduced the <ulink url="http://jcp.org/en/jsr/detail?id=303">Bean Validation</ulink> Specification which allows for validation constraints at the database, application, and view layers all with a single declaration.  Let&#8217;s enable BV for our project, similar to how we put in place support for persistence:</simpara>
<screen>$&gt; validation setup --provider HIBERNATE_VALIDATOR</screen>
<simpara>Once again we&#8217;re given the appropriate dependencies in our POM, as well as a valid <literal>validation.xml</literal> configuration file such that we don&#8217;t have to apply any boilerplate XML on our own.</simpara>
<screen>***SUCCESS*** Installed [forge.spec.validation] successfully.
Wrote ./feedback/src/main/resources/META-INF/validation.xml
Wrote ./feedback/pom.xml</screen>
<simpara>The generated <literal>validation.xml</literal> should be fine for our uses without any modification.</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;
&lt;validation-config xmlns="http://jboss.org/xml/ns/javax/validation/configuration" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt;
  &lt;default-provider&gt;org.hibernate.validator.HibernateValidator&lt;/default-provider&gt;
  &lt;message-interpolator&gt;org.hibernate.validator.messageinterpolation.ResourceBundleMessageInterpolator&lt;/message-interpolator&gt;
  &lt;traversable-resolver&gt;org.hibernate.validator.engine.resolver.DefaultTraversableResolver&lt;/traversable-resolver&gt;
  &lt;constraint-validator-factory&gt;org.hibernate.validator.engine.ConstraintValidatorFactoryImpl&lt;/constraint-validator-factory&gt;
&lt;/validation-config&gt;</programlisting>
<simpara>Now we&#8217;re all set to add some entities to our project.  For the uninitiated, this will be our interface to accessing persistent (ie. database-backed) data as an object.  For now we&#8217;ll just create one simple bean to represent a database table, and we&#8217;ll call it "FeedbackEntry".</simpara>
<screen>$&gt; entity --named FeedbackEntry;</screen>
<simpara>Forge will create a new Java class for us, adding the proper <literal>@Entity</literal> annotation, an ID field to represent our primary key, a version field for optimistic locking, and stubbed out methods for value-based <literal>equals(Object)</literal> and <literal>hashCode()</literal>.</simpara>
<programlisting language="java" linenumbering="unnumbered">package org.cedj.feedback.model;

import javax.persistence.Entity;
import java.io.Serializable;
import javax.persistence.Id;
import javax.persistence.GeneratedValue;
import javax.persistence.GenerationType;
import javax.persistence.Column;
import javax.persistence.Version;
import java.lang.Override;

@Entity
public class FeedbackEntry implements Serializable
{

   @Id
   private @GeneratedValue(strategy = GenerationType.AUTO)
   @Column(name = "id", updatable = false, nullable = false)
   Long id = null;
   @Version
   private @Column(name = "version")
   int version = 0;

   public Long getId()
   {
      return this.id;
   }

   public void setId(final Long id)
   {
      this.id = id;
   }

   public int getVersion()
   {
      return this.version;
   }

   public void setVersion(final int version)
   {
      this.version = version;
   }

   public String toString()
   {
      String result = "";
      if (id != null)
         result += id;
      return result;
   }

   @Override
   public boolean equals(Object that)
   {
      if (this == that)
      {
         return true;
      }
      if (that == null)
      {
         return false;
      }
      if (getClass() != that.getClass())
      {
         return false;
      }
      if (id != null)
      {
         return id.equals(((FeedbackEntry) that).id);
      }
      return super.equals(that);
   }

   @Override
   public int hashCode()
   {
      if (id != null)
      {
         return id.hashCode();
      }
      return super.hashCode();
   }
}</programlisting>
<simpara>Our <literal>FeedbackEntry</literal> entity should be capable of recording feedback for some user with a Twitter ID, so let&#8217;s add fields to represent that data (as well as some validation constraints dictating that these may not be <literal>null</literal>).</simpara>
<screen>field string --named twitterHandle;
constraint NotNull --onProperty twitterHandle;
field string --named feedback;
constraint NotNull --onProperty feedback;</screen>
<simpara>It&#8217;s worth noting now that our Forge prompt reads that the current location is <emphasis>inside</emphasis> our Entity, as that&#8217;s where we&#8217;re currently working.  Forge&#8217;s <literal>ls</literal> command is handy for seeing the current state of our Entity as we build.</simpara>
<screen>[feedback] FeedbackEntry.java $ ls

[fields]
private::Long::id;
private::String::feedback;
private::String::twitterHandle;
private::int::version;

[methods]
public::equals(Object that)::boolean
public::getFeedback()::String
public::getId()::Long
public::getTwitterHandle()::String
public::getVersion()::int
public::hashCode()::int
public::setFeedback(final String feedback)::void
public::setId(final Long id)::void
public::setTwitterHandle(final String twitterHandle)::void
public::setVersion(final int version)::void
public::toString()::String</screen>
<simpara>With our sole Entity in place, it&#8217;s time to let Forge generate a UI layer for us as a starting point for the view in our web application.  The "<literal>scaffolding</literal>" command makes short work of this.</simpara>
<screen>$&gt; scaffold setup
***SUCCESS*** Installed [forge.maven.WebResourceFacet] successfully.
***SUCCESS*** Installed [forge.spec.ejb] successfully.
***SUCCESS*** Installed [forge.spec.cdi] successfully.
***SUCCESS*** Installed [forge.spec.servlet] successfully.
***SUCCESS*** Installed [forge.spec.jsf.api] successfully.
***SUCCESS*** Installed [faces] successfully.
Wrote ./feedback/src/main/webapp
Wrote ./feedback/pom.xml
Wrote ./feedback/src/main/webapp/WEB-INF/beans.xml
Wrote ./feedback/src/main/webapp/WEB-INF/faces-config.xml
Wrote ./feedback/src/main/webapp/favicon.ico
Wrote ./feedback/src/main/webapp/resources/scaffold/paginator.xhtml
Wrote ./feedback/src/main/webapp/resources/scaffold/pageTemplate.xhtml
Wrote ./feedback/src/main/webapp/index.html
Wrote ./feedback/src/main/webapp/index.xhtml
Wrote ./feedback/src/main/webapp/error.xhtml
Wrote ./feedback/src/main/webapp/resources/add.png
Wrote ./feedback/src/main/webapp/resources/bootstrap.css
Wrote ./feedback/src/main/webapp/resources/false.png
Wrote ./feedback/src/main/webapp/resources/favicon.ico
Wrote ./feedback/src/main/webapp/resources/forge-logo.png
Wrote ./feedback/src/main/webapp/resources/forge-style.css
Wrote ./feedback/src/main/webapp/resources/remove.png
Wrote ./feedback/src/main/webapp/resources/search.png
Wrote ./feedback/src/main/webapp/resources/true.png
Wrote ./feedback/src/main/webapp/WEB-INF/web.xml</screen>
<simpara>As shown by the somewhat lengthy output, we&#8217;re now equipped with a <literal>src/main/webapp</literal> folder laid out with a nice starting point from which we can build our own UI.  With just one more command, we can generate a CRUD (Create, Read, Update, Delete) interface to our entities:</simpara>
<screen>$&gt; scaffold from-entity org.cedj.feedback.model.*;
***INFO*** Using currently installed scaffold [faces]
***SUCCESS*** Generated UI for [org.cedj.feedback.model.FeedbackEntry]
Wrote ./feedback/src/main/java/org/cedj/feedback/view/FeedbackEntryBean.java
Wrote ./feedback/src/main/webapp/feedbackEntry/create.xhtml
Wrote ./feedback/src/main/webapp/feedbackEntry/view.xhtml
Wrote ./feedback/src/main/webapp/feedbackEntry/search.xhtml
Wrote ./feedback/src/main/webapp/resources/scaffold/pageTemplate.xhtml
Wrote ./feedback/src/main/java/org/cedj/feedback/view/ViewUtils.java
Wrote ./feedback/src/main/webapp/WEB-INF/classes/META-INF/forge.taglib.xml
Wrote ./feedback/src/main/java/org/cedj/feedback/model/FeedbackEntry.java</screen>
<simpara>And that&#8217;s enough for now; we&#8217;ve created the skeleton for a fully-functional application.  Of course, the thematic element of this book is <emphasis>testable development</emphasis>, so it&#8217;s best we throw in the facility to run some integration tests on our little application.</simpara>
</section>
<section id="_writing_our_first_integration_test_with_arquillian">
<title>Writing Our First Integration Test with Arquillian</title>
<simpara>We&#8217;ve mentioned before that Forge is based on a plugin architecture; all commands we&#8217;ve used thus far are actually plugins called by the Forge runtime when we request them in the console.  Up to this point, we&#8217;ve used support that comes standard with the Forge distribution.  Now we&#8217;d like to add some tests, and we&#8217;ll use the Arquillian Test Platform as both the programming model and the JUnit test runner.  First order of business is to install the Arquillian plugin into our Forge runtime, and this is done by way of the <literal>forge install-plugin</literal> command.</simpara>
<screen>$&gt; forge install-plugin arquillian
Connecting to remote repository [https://raw.github.com/forge/plugin-repository/master/repository.yaml]... connected!
***INFO*** Preparing to install plugin: arquillian
***INFO*** Checking out plugin source files to [/tmp/forgetemp1365281623326595751/repo] via 'git'
***INFO*** Switching to branch/tag [refs/heads/1.0.2.Final]
***INFO*** Invoking build with underlying build system.
...
***INFO*** Installing plugin artifact.
***SUCCESS*** Installed from [https://github.com/forge/plugin-arquillian.git] successfully.</screen>
<simpara>This instructs Forge to connect to its plugin repository, grab the latest version of the requested plugin, build it from source, and install the binaries into the current runtime.  As Forge is built on a modular ClassLoading architecture, we&#8217;re able to load in plugins without the need to restart the process or concern ourselves with conflicting dependencies.</simpara>
<simpara>With the Arquillian plugin installed, we now have access to the <literal>arquillian</literal> command.  Let&#8217;s instruct Forge to equip our POM with the dependencies needed to run Arquillian tests on the JBoss AS7 container.</simpara>
<screen>$&gt; arquillian setup --container JBOSS_AS_REMOTE_7.X;</screen>
<simpara>You&#8217;ll be prompted for the versions of Arquillian, JUnit, and JBoss AS7 that you&#8217;d like to use, and the available options will expand over time as new versions are released.  These instructions have been tested with:</simpara>
<screen>[org.jboss.arquillian:arquillian-bom:pom::1.0.3.Final]
[junit:junit:::4.11]
[org.jboss.as:jboss-as-arquillian-container-remote:::7.1.1.Final]</screen>
<simpara>With the POM config changes out of the way, let&#8217;s ask Forge to now create for us a jumping-off point from which we&#8217;ll write our test.</simpara>
<screen>$&gt; arquillian create-test --class org.cedj.feedback.model.FeedbackEntry.java
Picked up type &lt;JavaResource&gt;: org.cedj.feedback.model.FeedbackEntryTest
Wrote ./feedback/src/test/java/org/cedj/feedback/model/FeedbackEntryTest.java</screen>
<simpara>The newly-created <literal>FeedbackEntryTest</literal> is technically an Arquillian test, but it really doesn&#8217;t do too much for us.  After all, we can automate quite a bit, but in the end it&#8217;s up to us to write our own business and test logic.  So let&#8217;s replace the contents of this class with:</simpara>
<programlisting language="java" linenumbering="unnumbered">package org.cedj.feedback.model;

import java.io.File;
import javax.persistence.EntityManager;
import javax.persistence.PersistenceContext;
import org.jboss.arquillian.container.test.api.Deployment;
import org.jboss.arquillian.junit.Arquillian;
import org.jboss.shrinkwrap.api.ShrinkWrap;
import org.jboss.shrinkwrap.api.spec.WebArchive;
import org.junit.Assert;
import org.junit.Test;
import org.junit.runner.RunWith;

@RunWith(Arquillian.class)
public class FeedbackEntryTest {
    @PersistenceContext
    private EntityManager em;

    @Deployment
    public static WebArchive createDeployment() {
        return ShrinkWrap.createFromZipFile(WebArchive.class, new File(
                "target/feedback.war"));
    }

    @Test
    public void canFindFeedbackByUser() {
        final FeedbackEntry feedback = em.createQuery(
                "from " + FeedbackEntry.class.getSimpleName()
                        + " where twitterHandle='@ALRubinger'",
                FeedbackEntry.class).getSingleResult();
        Assert.assertNotNull(feedback);
    }

    @Test
    public void testIsDeployed() {
        Assert.assertNotNull(em);
    }
}</programlisting>
<simpara>Before going forward, let&#8217;s break down the anatomy of this test.</simpara>
<simpara>First, we&#8217;ll note that there are no references in the <literal>import</literal> statements to any particular application server or target container.  This is because Arquillian is designed to decouple the programming model of the test from the target runtime; any container which can handle the capabilities demanded by the test will work.  This keeps the portability goals of Java EE intact, moving the mechanics of startup and deployment to configuration elements.  In this case, the Arquillian runner will note that the JBossAS7 container adaptor is available on the <literal>classpath</literal> as it&#8217;s been defined in the POM when we ran the <literal>setup</literal> command for the Arquillian Forge plugin.</simpara>
<simpara>The next point of interest is the class-level annotation:</simpara>
<programlisting language="java" linenumbering="unnumbered">@RunWith(Arquillian.class)</programlisting>
<simpara><literal>@RunWith</literal> is a standard JUnit construct which directs control to a specified test runner.  This is Arquillian&#8217;s entry point; from here Arquillian can receive lifecycle events from JUnit and perform its own handling.  The benefit to this design decision is that Arquillian requires no special plugins or configuration on the part of the user.  Anything which is capable of launching a JUnit test - be it a Maven build, an Ant task, a manual command, or an IDE - can take advantage of Arquillian without any additional handling.  For instance, JBDS and Eclipse can launch a full-scale integration test with Arquillian by right-clicking on the class and selecting "<literal>Run As &gt; JUnit Test</literal>".</simpara>
<simpara>Next up is the class declaration:</simpara>
<programlisting language="java" linenumbering="unnumbered">public class FeedbackEntryTest {...}</programlisting>
<simpara>The important bit here is what&#8217;s <emphasis>not</emphasis> required.  Because of the Arquillian JUnit Test Runner, you&#8217;re free to use whatever class hierarchy you&#8217;d like, and there&#8217;s no need to extend a base support class.  This keeps Arquillian tests in line with the POJO programming model originally introduced in Java EE5.</simpara>
<simpara>Another feature of Arquillian is its ability to provide services like injection to the test.  Here we&#8217;re going to interact with persistent storage via the JPA <literal>EntityManager</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">    @PersistenceContext
    private EntityManager em;</programlisting>
<simpara>The <literal>EntityManager</literal> is typically used by server-side business components like EJBs or CDI beans, but because this test is going to run <emphasis>inside</emphasis> the container as part of a deployment, we&#8217;ll be able to interact with it directly.</simpara>
<simpara><emphasis>TODO: Insert image of the Arquillian lifecycle with regards to in-container testing</emphasis></simpara>
<simpara>Because Arquillian aims to follow the standards set forth by Java EE, instead of requiring the user to do a lookup or manual creation of the <literal>EntityManager</literal>, we&#8217;ll be able to receive an instance by requesting injection via use of the <literal>@PersistenceContext</literal> annotation.</simpara>
<simpara>The final important fixture of the Arquillian test anatomy is the <literal>@Deployment</literal> method:</simpara>
<programlisting language="java" linenumbering="unnumbered">  @Deployment
    public static WebArchive createDeployment() {
        return ShrinkWrap.createFromZipFile(WebArchive.class, new File(
                "target/feedback.war"));
    }</programlisting>
<simpara>Because Java EE application servers work off deployments like <emphasis>Web Archives (WARs)</emphasis>, <emphasis>Java Archives (JARs)</emphasis>, or <emphasis>Enterprise Archives (EARs)</emphasis>, we need to instruct Arquillian with the artifact to be deployed.  This method must be <literal>static</literal> and return any ShrinkWrap <literal>Archive</literal> type; for this first exercise we&#8217;ll simply grab the output of the current project&#8217;s build <literal>feedback.war</literal>, but as we&#8217;ll soon see in later examples, we don&#8217;t need to rely on flat files at all!  This will free us to skip the build entirely inbetween code changes and test runs, instead letting us rely ShrinkWrap&#8217;s packaging of <literal>.class</literal> files created from the IDE&#8217;s incremental complication features.</simpara>
<simpara>The rest of the file is all test logic!  Remember, the focus of the Arquillian programming model is to allow you to write less boilerplate and setup, and focus on the bits of code that only you as the developer can write.  It&#8217;s not your job to deal with bootstrapping an application server or calling upon vendor-specific deployment hooks; Arquillian will handle all of that for us behind the scenes.</simpara>
</section>
<section id="_running_the_application_locally">
<title>Running the Application Locally</title>
<simpara>Time to see our generated application in action.  First we should run the build to package our flat-file deployable <literal>feedback.war</literal> for manual deployment into JBoss AS7.  We can trigger Maven from the Forge console:</simpara>
<screen>$&gt; build --notest --profile JBOSS_AS_REMOTE_7.X;</screen>
<simpara>After a series of informative build output messages from Maven, you should see <literal>BUILD SUCCESS</literal>, indicating that the WAR has been properly built from sources.</simpara>
<simpara>The missing bit is that we need a server into which we can deploy our webapp!  JBossAS7 has a simple installation process (simply download and unzip onto the filesystem), but again Forge can help automate this for us so we don&#8217;t need to locate the JBossAS binaries.  For this we&#8217;ll turn to the Forge JBossAS7 Plugin, which is installed similarly to the Arquillian plugin we put in place in the last section.</simpara>
<screen>$&gt; forge install-plugin jboss-as-7</screen>
<simpara>Once installation is complete, we may use the newly-acquired <literal>as7</literal> command to set up our server.</simpara>
<screen>$&gt; as7 setup</screen>
<simpara>You&#8217;ll be prompted for your <literal>$JAVA_HOME</literal> location and JBossAS7 version; be sure to align the versions with the Arquillian Container Adaptor Version we&#8217;d chosen before.  Again, in this example we recommend <literal>7.1.1.Final</literal>.  Forge will additionally ask for the location to a JBossAS7 installation on the filesystem, but simply hitting <literal>ENTER</literal> will download the server for us into the <literal>target</literal> directory of our project.</simpara>
<simpara>Now it&#8217;s time to fire up the server.  First <literal>cd</literal> into the root of your project in the Forge shell, then execute:</simpara>
<screen>$&gt; as7 start --jboss-home target/jboss-as-dist/jboss-as-7.1.1.Final/</screen>
<simpara>If you&#8217;ve opted for a different version of JBossAS7, you may have to make substitutions to point <literal>JBOSS_HOME</literal> correctly.  Assuming all goes to plan, you should see the JBossAS7 startup sequence in the Forge shell, followed by:</simpara>
<screen>***INFO*** JBoss AS 7.1.3.Final has successfully started.</screen>
<simpara>With the server up, let&#8217;s deploy our application:</simpara>
<screen>$&gt; as7 deploy</screen>
<simpara>Again, after a series of JBossAS7 deployment messages, you should see:</simpara>
<screen>The deployment operation (FORCE_DEPLOY) was successful.</screen>
<simpara>We&#8217;re up and running!  Point your browser of choice to the root of the application at <literal>http://localhost:8080/feedback</literal>, and you should see the home screen of the UI that Forge has generated for us.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch03-scratch_to_production/feedback_home.png"/>
  </imageobject>
  <textobject><phrase>Feedback Application Home</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Selecting the "Feedback Entry" button will grant us access to the CRUD editor for this entity.  From here we can create a new row in the database table.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch03-scratch_to_production/new_feedback_entry.png"/>
  </imageobject>
  <textobject><phrase>New Feedback Entry</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>While CRUD applications are little more than a UI frontend to an Entity, the benefit here is in having a fully-functioning application to use as a base from which to start.  For newcomers to Java EE, this is especially useful as a learning tool.</simpara>
<simpara>With our new entry now persisted into the database, let&#8217;s undeploy the application in preparation to perform our first integration test run with Arquillian.</simpara>
<screen>$&gt; as7 undeploy
...
The deployment operation (UNDEPLOY_IGNORE_MISSING) was successful.</screen>
</section>
<section id="_running_the_arquillian_integration_test">
<title>Running the Arquillian Integration Test</title>
<simpara>At this point, we still have a running JBoss AS7 server and have undeployed the "feedback" application.  Because we&#8217;d chosen the <literal>JBOSS_AS_REMOTE_7.X</literal> option as part of the Forge Arquillian Plugin <literal>setup</literal> command above, our POM is equipped with a profile which enables a dependency on the JBoss AS7 Arquillian Container:</simpara>
<screen>    &lt;profile&gt;
      &lt;id&gt;JBOSS_AS_REMOTE_7.X&lt;/id&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.jboss.as&lt;/groupId&gt;
          &lt;artifactId&gt;jboss-as-arquillian-container-remote&lt;/artifactId&gt;
          &lt;version&gt;7.1.1.Final&lt;/version&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;</screen>
<simpara>Let&#8217;s inform JBDS that we should consider the metadata considered in this profile; this will impact our compilation and JUnit runtime +classpath+s.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch03-scratch_to_production/select_maven_profiles.png"/>
  </imageobject>
  <textobject><phrase>Select Maven Profile</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Now the Arquillian test launcher will know to pick up the proper adaptor to a remote JVM instance of JBoss AS7 when running tests; it will connect to the currently-running instance, deploy the defined <literal>@Deployment</literal>, execute the tests, and undeploy to clean up.  If we&#8217;d like to allow Arquillian to automatically control the server start/stop lifecycle alongside each test suite, we could alternatively use the <literal>JBOSS_AS_REMOTE_7.X</literal> setup option which defines <literal>org.jboss.as:jboss-as-arquillian-container-managed</literal> as a dependency in a POM profile.</simpara>
<simpara>With JBDS now configured with the proper <literal>classpath</literal> for test execution, all that&#8217;s left to do is launch the test.  A simple right-click on the test class in the Project Explorer yields the option <literal>Run As &gt; JUnit Test</literal>.  The IDE&#8217;s JUnit launcher will create a new process, fire up JUnit, and yield control to Arquillian.  We&#8217;ll receive results just as we&#8217;d expect from any other JUnit test.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch03-scratch_to_production/passing_test.png"/>
  </imageobject>
  <textobject><phrase>Passing the Tests</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>With assurance that our application has some minimal level of tested functionality, let&#8217;s take a risk and move this off the isolation of our local machine and into the public realm, accessible from the world.</simpara>
</section>
</section>
<section id="_requirements_and_the_example_application">
<title>Requirements and the Example Application</title>
<simpara><emphasis>"Whatever pursuit you undertake, the requirements should start with a love of what it is that you are pursuing." - Bill Toomey</emphasis></simpara>
<simpara>While the previous chapter provides decent proof that it&#8217;s possible to jumpstart development on a greenfield Java EE project without too much hassle, we all recognize how this may be a far cry from how applications are built in the real world.  The benefits of quickly going from a blank canvas to a deployed, functioning application are largely educational or handy in rapid prototyping, but in the majority of cases we&#8217;re likely looking to:</simpara>
<itemizedlist>
<listitem>
<simpara>
Have greater control over the architectural design of our program
</simpara>
</listitem>
<listitem>
<simpara>
Augment an existing application with new features
</simpara>
</listitem>
<listitem>
<simpara>
Integrate one or more systems
</simpara>
</listitem>
<listitem>
<simpara>
Increase modularity during development
</simpara>
</listitem>
</itemizedlist>
<simpara>In short, the preceding chapter introduced us to some potentially new technologies and is capable of getting us up and running, but the end result is a toy that would need a lot more work before it became a viable product.</simpara>
<simpara>This book will aim to address some of the common issues encountered during enterprise development.  Our primary goal is education, and that will inform some of the design choices we make in building our application; for instance we may expose more technologies than necessary to fulfill our objectives.  But just as a guide on design patterns doesn&#8217;t advocate usage of every technique at the same time, neither should these examples.  It&#8217;s your responsibility as developer to choose appropriate tools for the job, and we&#8217;ll aspire to help you make informed decisions.</simpara>
<section id="_introducing_geekseek">
<title>Introducing GeekSeek</title>
<simpara>Our example application will be a software conference tracker, roughly modeled after the excellent <ulink url="http://lanyrd.com/">Lanyrd</ulink> service.  Its purpose will be to expose information to aid conference-goers in planning their experience around technical sessions and related activities.  The goal is to provide a single example with all layers working in concert to showcase how various technologies interact, and each use case detailed in the book will dig into various slices of the application.  We&#8217;ve lovingly named this example: <emphasis>GeekSeek</emphasis>.</simpara>
<simpara>Reading this book should not be a passive endeavor; we&#8217;ve designed the example application to be an executable proof of the approaches we&#8217;ll use to satisfy our broad uses cases.  Readers will likely get the greatest benefit by pulling down the GeekSeek source, building, testing, and running the application locally.</simpara>
<simpara>The live "production" GeekSeek site is hosted at <ulink url="http://geekseek.continuousdev.org">http://geekseek.continuousdev.org</ulink>; let&#8217;s first have a look at the requirements comprising this application.</simpara>
<section id="_feature_set">
<title>Feature Set</title>
<simpara>We&#8217;ll start by outlining in broad strokes the features provided by GeekSeek.  This will provide a high-level view of the actions users may take, and from these we can start to drill down into more technical requirements.</simpara>
<itemizedlist>
<listitem>
<simpara>
Account-Centric Actions
</simpara>
<itemizedlist>
<listitem>
<simpara>
Users may sign up by associating the site with their <ulink url="http://www.twitter.com">Twitter</ulink> account
</simpara>
</listitem>
<listitem>
<simpara>
Users may track others whom they follow on Twitter
</simpara>
</listitem>
<listitem>
<simpara>
Users may see others whom may be interested in their activity (their Twitter followers).
</simpara>
</listitem>
<listitem>
<simpara>
Users may get updates on the activity of their followee&#8217;s followees (transitively, the people followed by the people you follow).
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Directory View
</simpara>
<itemizedlist>
<listitem>
<simpara>
Users may display upcoming and prior Conferences in the system
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Conferences and Sessions
</simpara>
<itemizedlist>
<listitem>
<simpara>
Users may add Conference and Session data, additionally associating them with a Venue and Room.
</simpara>
</listitem>
<listitem>
<simpara>
Users may define who is speaking at or attending a Session
</simpara>
</listitem>
<listitem>
<simpara>
Users may add arbitrary Attachments (media) information to a Conference, Session, Venue or Room
</simpara>
</listitem>
<listitem>
<simpara>
Users may track Conferences and Sessions to receive alerts for updates and changes
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Search
</simpara>
<itemizedlist>
<listitem>
<simpara>
Search for a Conference, Session, or User by some criteria
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>
<section id="_conceptual_data_model">
<title>Conceptual Data Model</title>
<simpara>As we&#8217;re still in the process of defining what our application does and the types of data it&#8217;ll be dealing with, this is not the place to delve into database design just yet.  This is the stage where we describe our <emphasis>conceptual data model</emphasis>;  first we need to understand:</simpara>
<itemizedlist>
<listitem>
<simpara>
What kind of data is to be represented?
</simpara>
</listitem>
<listitem>
<simpara>
Who are the major players (entities), and what are their fields?
</simpara>
</listitem>
</itemizedlist>
<simpara>Here we speak at a very coarse level of granularity, and we seek to define from a business perspective the <emphasis>nouns</emphasis> of our application.  In our case, we have:</simpara>
<section id="_user">
<title>User</title>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Name</simpara></entry>
<entry align="left" valign="top"><simpara>Type</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Twitter ID</simpara></entry>
<entry align="left" valign="top"><simpara>String, unique among all users</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Bio</simpara></entry>
<entry align="left" valign="top"><simpara>String</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_conference">
<title>Conference</title>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Name</simpara></entry>
<entry align="left" valign="top"><simpara>String</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Tagline</simpara></entry>
<entry align="left" valign="top"><simpara>String</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Start</simpara></entry>
<entry align="left" valign="top"><simpara>Date/Time</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>End</simpara></entry>
<entry align="left" valign="top"><simpara>Date/Time</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_session">
<title>Session</title>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Title</simpara></entry>
<entry align="left" valign="top"><simpara>String</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Outline</simpara></entry>
<entry align="left" valign="top"><simpara>String</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Start</simpara></entry>
<entry align="left" valign="top"><simpara>Date/Time</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>End</simpara></entry>
<entry align="left" valign="top"><simpara>Date/Time</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_attachment">
<title>Attachment</title>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Content</simpara></entry>
<entry align="left" valign="top"><simpara>Binary</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Type</simpara></entry>
<entry align="left" valign="top"><simpara>Media Type (ie. JPEG, PDF, etc)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_venue">
<title>Venue</title>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Name</simpara></entry>
<entry align="left" valign="top"><simpara>String</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Location</simpara></entry>
<entry align="left" valign="top"><simpara>Place</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_room">
<title>Room</title>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Name</simpara></entry>
<entry align="left" valign="top"><simpara>String</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Location</simpara></entry>
<entry align="left" valign="top"><simpara>Place</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Once we&#8217;ve got a solid understanding of the kinds of data we&#8217;ll be addressing, we may go a bit further and see how these nouns might play out in the context of our proposed featureset.</simpara>
</section>
</section>
<section id="_logical_data_model">
<title>Logical Data Model</title>
<simpara>We&#8217;ve taken the first step in describing our data types by acknowledging the information we&#8217;ll need to capture.  Now we need to take into account some additional concerns:</simpara>
<itemizedlist>
<listitem>
<simpara>
What are the relationships inherent between entities?
</simpara>
</listitem>
<listitem>
<simpara>
How much data are we expecting in each entity?
</simpara>
</listitem>
<listitem>
<simpara>
What features will be demanded of our entities?
</simpara>
</listitem>
</itemizedlist>
<simpara>It&#8217;s questions like these which will help us to arrive at a <emphasis>logical data model</emphasis>, a representation of our data that isn&#8217;t yet tied to any specific storage mechanism but still addresses the questions above.  Decisions at this step are instrumental in our later choices which will have heavy impact in areas like efficiency and performance.</simpara>
<simpara>This is because database systems have varying strengths when we couple data representation with the requests we may make.  Actions like searching and sorting can take milliseconds or days, depending only upon the backing data structures and implementation used!  Therefore it&#8217;s very important for us to define the relationships required between our data, and recognize cases where we could have potentially large result sets; it&#8217;s here that we&#8217;ll need to design efficiently.</simpara>
<section id="_relationships">
<title>Relationships</title>
<simpara><emphasis>Relationships</emphasis> are the bonds that tie our entities together, and come in three flavors of <emphasis>cardinality</emphasis>:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">Cardinality</entry>
<entry align="left" valign="top">Name</entry>
<entry align="left" valign="top">Example</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>1:1</simpara></entry>
<entry align="left" valign="top"><simpara>One-to-one</simpara></entry>
<entry align="left" valign="top"><simpara>I have one nose; my nose belongs to only me</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1:N</simpara></entry>
<entry align="left" valign="top"><simpara>One-to-many</simpara></entry>
<entry align="left" valign="top"><simpara>I have many fingers; my fingers belong to only me</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>N:N</simpara></entry>
<entry align="left" valign="top"><simpara>Many-to-many</simpara></entry>
<entry align="left" valign="top"><simpara>I have many friends; my friends also have many other friends besides me</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>So in the case of the entities for our application as defined by our desired featureset, we can draw the following relationships:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<thead>
<row>
<entry align="left" valign="top">#</entry>
<entry align="left" valign="top">Entity 1</entry>
<entry align="left" valign="top">Entity 2</entry>
<entry align="left" valign="top">Cardinality</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>Conference</simpara></entry>
<entry align="left" valign="top"><simpara>Session</simpara></entry>
<entry align="left" valign="top"><simpara>1:N</simpara></entry>
<entry align="left" valign="top"><simpara>A conference may have many sessions</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>Session</simpara></entry>
<entry align="left" valign="top"><simpara>Room</simpara></entry>
<entry align="left" valign="top"><simpara>N:N</simpara></entry>
<entry align="left" valign="top"><simpara>A session may take place in many rooms (spanned together)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>3</simpara></entry>
<entry align="left" valign="top"><simpara>Venue</simpara></entry>
<entry align="left" valign="top"><simpara>Room</simpara></entry>
<entry align="left" valign="top"><simpara>1:N</simpara></entry>
<entry align="left" valign="top"><simpara>A venue may have many rooms; a room exists only in one venue</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>4</simpara></entry>
<entry align="left" valign="top"><simpara>Conference</simpara></entry>
<entry align="left" valign="top"><simpara>Venue</simpara></entry>
<entry align="left" valign="top"><simpara>1:N</simpara></entry>
<entry align="left" valign="top"><simpara>A conference may take place in many venues</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>5</simpara></entry>
<entry align="left" valign="top"><simpara>Conference</simpara></entry>
<entry align="left" valign="top"><simpara>Attachment</simpara></entry>
<entry align="left" valign="top"><simpara>1:N</simpara></entry>
<entry align="left" valign="top"><simpara>A conference may have many attachments</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>6</simpara></entry>
<entry align="left" valign="top"><simpara>Session</simpara></entry>
<entry align="left" valign="top"><simpara>Attachment</simpara></entry>
<entry align="left" valign="top"><simpara>1:N</simpara></entry>
<entry align="left" valign="top"><simpara>A session may have many attachments</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>7</simpara></entry>
<entry align="left" valign="top"><simpara>Venue</simpara></entry>
<entry align="left" valign="top"><simpara>Attachment</simpara></entry>
<entry align="left" valign="top"><simpara>1:N</simpara></entry>
<entry align="left" valign="top"><simpara>A venue may have many attachments</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>8</simpara></entry>
<entry align="left" valign="top"><simpara>Room</simpara></entry>
<entry align="left" valign="top"><simpara>Attachment</simpara></entry>
<entry align="left" valign="top"><simpara>1:N</simpara></entry>
<entry align="left" valign="top"><simpara>A room may have many attachments</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>9</simpara></entry>
<entry align="left" valign="top"><simpara>User</simpara></entry>
<entry align="left" valign="top"><simpara>User</simpara></entry>
<entry align="left" valign="top"><simpara>N:N</simpara></entry>
<entry align="left" valign="top"><simpara>A user may follow many other users on Twitter, and may also have many followers.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>In graphical terms, this may look a little like:</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT IMAGES HERE OF THE RELATIONSHIP MODEL BETWEEN ENTITIES (Fig 04-01)</emphasis></emphasis></simpara>
</section>
<section id="_intended_use">
<title>Intended Use</title>
<simpara>When considering the efficiency of operations like database lookups, we should attempt to strike a balance between premature optimization and planning for performance.  For instance, it really wouldn&#8217;t matter how complex the relationships between these entities are if we were only expecting a small, finite number of records; these would likely be cached at some level and held in memory, avoiding the need for lengthy tasks like full table scans.  At the other end of the spectrum, it&#8217;d be an oversight to recognize that we&#8217;re expecting lots of data in a <emphasis>normalized</emphasis> form, and anticipate that querying against this model has time complexity of linear (<emphasis>O(n)</emphasis>), geometric (<emphasis>O(n<superscript>2</superscript>)</emphasis>) or worse.</simpara>
<simpara>Unfortunately, a pick peek at our data types and featureset shows that given enough time and interest in the application, we could reasonably expect entries for each of our main data types to grow, unbounded.</simpara>
<simpara>Of particular note is the many-to-many relationship among users.  Because a user may have both many followers and may follow many people, we have two unidirectional relationships; a follower of mine is not necessarily someone I follow.  This is in contrast to a mutual "friend" model employed by, say, the <ulink url="http://www.facebook.com">Facebook</ulink> social networking site.</simpara>
<simpara>In effect this relationship has a graph structure:</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT MORE DETAILED IMAGE OF USER RELATIONSHIPS, (Fig 04-02)</emphasis></emphasis></simpara>
<simpara>While there are any number of ways we might store and model this structure, it&#8217;s worth noting that requesting transient relationships can be a problem with geometric time complexity.  That is: we&#8217;d need one query to find all of a user&#8217;s followers.  Then, <emphasis role="strong">for each</emphasis> of the results in that set, we&#8217;d need another query to find <emphasis role="strong">their</emphasis> followers.  With each level we drill in to find followers, the problem gets prohibitively complex and unsolvable when organized in standard tables and rows.</simpara>
<simpara>Because the relationship is naturally a graph, it will likely make sense to store our relationship data in this fashion.  That way, instead of querying standard records, we can walk the graph (simply obtaining a value from a pointer is an operation with constant time complexity, and thus will perform many factors better when we compound the process in a loop).</simpara>
<simpara>Another interesting area revolves around the system&#8217;s attachments.  An attachment can be associated with a conference, session, venue, or room, and ultimately consists of some arbitrary series of bytes.  This amounts to a natural "key/value" store really, where we can add a bunch of content, associate some metadata with it, and draw a relationship to its "owner".  Again, we might tackle this in a standard table representation, but perhaps the problem domain suggests a native solution more in tune with the key/value model.</simpara>
<simpara>Now that we&#8217;ve developed a better understanding of our data, what requests we&#8217;ll make of it, and how much we might have, we can move on to designing some user-based and technical use cases to drive the construction of our application.</simpara>
</section>
</section>
<section id="_obtaining_building_testing_and_running_geekseek">
<title>Obtaining, Building, Testing, and Running GeekSeek</title>
<simpara>We&#8217;d mentioned earlier that we&#8217;d be using the distributed version control system <emphasis>Git</emphasis> to store the source for this book and its examples, and our friends at <ulink url="http://www.github.com">GitHub</ulink> kindly host our <emphasis>authoritative repository</emphasis> at <ulink url="https://github.com/arquillian/continuous-enterprise-development">https://github.com/arquillian/continuous-enterprise-development</ulink>.  Unlike centralized version control systems, Git stores the full repository history in each clone; when you "fork" or "copy" our repo, you&#8217;ll get the entire history with every commit made since the book&#8217;s inception.  The <emphasis>authoritative repository</emphasis> refers to the one we elect to act as the <emphasis>upstream</emphasis>; changes that are approved to make it into new releases go here.</simpara>
<section id="_obtaining_the_source">
<title>Obtaining the Source</title>
<simpara>The first step towards obtaining the source is to sign up for a GitHub account.  While it&#8217;s absolutely possible to clone the authoritative repo locally, without an account either here or at some other writable host you won&#8217;t have an avenue to push changes of your own or contribute ideas.  As signing up for an account is free for our uses and has become commonplace espeically in open-source development, it&#8217;s the avenue we&#8217;ll advise.</simpara>
<simpara>Signup is fairly simple and the process starts at <ulink url="https://github.com">https://github.com</ulink></simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch04-requirements_example_app/github_signup.png"/>
  </imageobject>
  <textobject><phrase>GitHub Signup</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Once logged in, we&#8217;ll <emphasis>fork</emphasis> the authoritative repo into your own publicly-viewable repository.  This is done by visiting the book&#8217;s repo and pressing the "Fork" button:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch04-requirements_example_app/fork.png"/>
  </imageobject>
  <textobject><phrase>Forking a GitHub Repository</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>With the fork in your account, now you&#8217;ll be able to <emphasis>clone</emphasis> this repository locally.  And because you have your own fork on GitHub, you&#8217;ll be able to <emphasis>push</emphasis> the <emphasis>commits</emphasis> you make locally to your own fork, where you have write access.  This provides two important benefits; first, it serves as a backup in case of disk failure, loss of machine, or a synchronization point if you develop on many machines.  Second, it allows others to see the changes you&#8217;ve made an optionally bring them in for their own use.</simpara>
<simpara>Before bringing in your fork of the repository locally, we&#8217;ll need to have a Git client installed.  This is a command-line tool available on many platforms, but there are also GUI wrappers, for instance included in many IDEs like Eclipse or IntelliJ IDEA.  We&#8217;ll offer instructions based on the command-line.</simpara>
<simpara>Installation is platform-specific, but in flavors of Linux, this is easily enough achived via your package manager of choice:</simpara>
<screen>$&gt; sudo apt-get install -y git</screen>
<simpara><literal>apt-get</literal> is the default for Debian-based distributions including Ubuntu and Linux Mint; for others (including RHEL and Fedora), <literal>yum</literal> may be more appropriate:</simpara>
<screen>$&gt; sudo yum install -y git</screen>
<simpara>The Git Client for Windows can be obtained as an executable installer at <ulink url="http://git-scm.com/download/win">http://git-scm.com/download/win</ulink>.  Similarly, the client for Mac is available at <ulink url="http://git-scm.com/download/mac">http://git-scm.com/download/mac</ulink>.</simpara>
<simpara>You may verify your installation at the command prompt by executing:</simpara>
<screen>$&gt; git --version
git version 1.8.1.2</screen>
<simpara>With your Git client installed locally, now you&#8217;re free to pull down the book&#8217;s repository from your public fork on GitHub to your local machine.  This is done by first finding the URI to your repository on your GitHub repo&#8217;s home page:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch04-requirements_example_app/clone.png"/>
  </imageobject>
  <textobject><phrase>GitHub URI to Clone</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Then simply move to a directory in which you&#8217;d like to place your local clone, and issue the <literal>git clone</literal> command, passing in the URI to your GitHub repository.  For instance:</simpara>
<screen>$&gt; git clone git@github.com:ALRubinger/continuous-enterprise-development.git
Cloning into 'continuous-enterprise-development'...
remote: Counting objects: 2661, done.
remote: Compressing objects: 100% (1170/1170), done.
remote: Total 2661 (delta 534), reused 2574 (delta 459)
Receiving objects: 100% (2661/2661), 1.19 MiB | 1.24 MiB/s, done.
Resolving deltas: 100% (534/534), done.</screen>
<simpara>The above will create a new directory called <literal>continuous-enterprise-development</literal>, under which you&#8217;ll be able to see the book&#8217;s source in the root and all supporting code under the <literal>code</literal> directory.  The <emphasis>GeekSeek</emphasis> application root is housed under <literal>code/application</literal>.</simpara>
<screen>$&gt; ls -l
total 492
-rw-r--r-- 1 alr alr   468 Jul  6 17:18 book.asciidoc
-rw-r--r-- 1 alr alr  3227 Jun 26 03:20 Chapter00-Prelude.asciidoc
-rw-r--r-- 1 alr alr 23634 Jun 28 18:03 Chapter01-Continuity.asciidoc
-rw-r--r-- 1 alr alr 40527 Jun 28 18:03 Chapter02-EnablingTechnologies.asciidoc
-rw-r--r-- 1 alr alr 29803 Jun 28 18:03 Chapter03-ScratchToProduction.asciidoc
-rw-r--r-- 1 alr alr 20772 Jul  7 17:29 Chapter04-RequirementsAndExampleApplication.asciidoc
-rw-r--r-- 1 alr alr 61834 Jul  7 17:29 Chapter04-RequirementsAndExampleApplication.html
-rw-r--r-- 1 alr alr 32765 Jun 28 18:03 Chapter05-JavaPersistenceAndRelationalData.asciidoc
 ...etc
drwxr-xr-x 8 alr alr  4096 Jul  6 20:24 code
drwxr-xr-x 6 alr alr  4096 Jun 26 03:20 images
-rw-r--r-- 1 alr alr  2733 Jul  7 16:19 README.asciidoc</screen>
<simpara>This will pull the current upstream version of the application into your local disk.  If, for instance, you&#8217;d like to work against one of the authoritative repository&#8217;s tags, you may:</simpara>
<itemizedlist>
<listitem>
<simpara>
Create a <literal>remote</literal> reference to the authoritative repo: <literal>git remote add upstream <ulink url="https://github.com/arquillian/continuous-enterprise-development.git">https://github.com/arquillian/continuous-enterprise-development.git</ulink></literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>fetch</literal> all the tags from the remote repo: <literal>git fetch -t upstream</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>checkout</literal> the tag as a local branch: <literal>git checkout -b remotes/upstream/1.0.0</literal> (For instance checks out tag <literal>1.0.0</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
Work on your new branch, based off the tag you&#8217;ve specified: <literal>git branch</literal>
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_building_and_testing_geekseek">
<title>Building and Testing GeekSeek</title>
<simpara>We&#8217;ll be using the Maven software management tool to handle our build, test, and packaging needs.  The Java 7 JDK is a prerequisite we&#8217;ll assume is installed on your system, referenced by the environment variable <literal>JAVA_HOME</literal>, and the executables in <literal>$JAVA_HOME/bin</literal> available on the system <literal>PATH</literal>; Maven may be simply downloaded and extracted on your drive to <emphasis>MAVEN_HOME</emphasis> from <ulink url="http://maven.apache.org/download.cgi">http://maven.apache.org/download.cgi</ulink>.  Ensure that <emphasis>MAVEN_HOME/bin</emphasis> is on your <literal>PATH</literal>, and you&#8217;ll be good to go:</simpara>
<screen>$&gt; mvn -version
Apache Maven 3.0.5 (r01de14724cdef164cd33c7c8c2fe155faf9602da; 2013-02-19 08:51:28-0500)
Maven home: /home/alr/opt/apache/maven/apache-maven-3.0.5
Java version: 1.7.0_25, vendor: Oracle Corporation
Java home: /home/alr/opt/oracle/java/jdk1.7.0_25/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "3.8.0-19-generic", arch: "amd64", family: "unix"</screen>
<simpara>Building and testing GeekSeek is done by invoking the <literal>package</literal> phase of Maven on the <literal>pom.xml</literal> file located in <literal>code/application</literal>:</simpara>
<screen>application $&gt; mvn package
  ...lots of output
[INFO] BUILD SUCCESS</screen>
<simpara>The first run is likely to take some time as Maven will resolve all dependencies of the project (including the application servers in which it will run), and download them onto your local disk.  Subsequent runs will not require this initial "downloading the internet" step and will execute much faster.</simpara>
<simpara>The <literal>test</literal> phase will instruct Maven to fire up the application servers and run all tests to ensure that everything is working as expected.  If you&#8217;d like to save some time and simply fetch the dependencies, build the sources, and package the application, execute <literal>mvn package -DskipTests=true</literal>.  For a full list of the Maven lifecycles, consult:  <ulink url="http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html">http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html</ulink>.</simpara>
<simpara>Packaging the full application will result in a WAR (Web Archive) file located at <literal>application/target/geekseek-(version).war</literal>.  It&#8217;s this file which may be deployed into an application server to run GeekSeek locally; by default we&#8217;ll be using <emphasis>WildFly</emphasis> from the JBoss Community.</simpara>
</section>
<section id="_running_geekseek">
<title>Running GeekSeek</title>
<simpara>While we&#8217;ve configured the build to obtain and use WildFly for use in testing GeekSeek automatically as part of the build, you may prefer to have an installation on your local disk to use manually.  This is useful for testing with remote containers (as covered later in the "Assembly and Deployment" Chapter) as well as poking around the running application locally.</simpara>
<simpara>WildFly is available for free download at <ulink url="http://www.wildfly.org/download/">http://www.wildfly.org/download/</ulink>, and should be extracted to a location we&#8217;ll call <emphasis>JBOSS_HOME</emphasis>.  By executing <literal>JBOSS_HOME/bin/standalone.sh</literal>, the server will start:</simpara>
<screen>wildfly-8.0.0.Alpha2 $&gt; JBOSS_HOME=`pwd`
wildfly-8.0.0.Alpha2 $&gt; cd bin/
bin $&gt; ./standalone.sh
=========================================================================
  JBoss Bootstrap Environment
  JBOSS_HOME: /home/alr/business/oreilly/git/continuous-enterprise-development/code/application/target/wildfly-8.0.0.Alpha2
  JAVA: /home/alr/opt/oracle/java/jdk7/bin/java
  JAVA_OPTS:  -server -XX:+UseCompressedOops -Xms64m -Xmx512m -XX:MaxPermSize=256m -Djava.net.preferIPv4Stack=true -Djboss.modules.system.pkgs=org.jboss.byteman -Djava.awt.headless=true

=========================================================================

18:08:42,477 INFO  [org.jboss.modules] (main) JBoss Modules version 1.2.2.Final
18:08:43,290 INFO  [org.jboss.msc] (main) JBoss MSC version 1.2.0.Beta1
   ...trimm output
JBAS015874: WildFly 8.0.0.Alpha2 "WildFly" started in 8624ms - Started 153 of 189 services (56 services are lazy, passive or on-demand)</screen>
<simpara>Copying the <literal>application/target/geekseek-(version).war</literal> file into <literal>$JBOSS_HOME/standalone/deployments</literal> will trigger deployment of the GeekSeek application:</simpara>
<screen>$&gt; cp code/application/application/target/geekseek-1.0.0-alpha-1-SNAPSHOT.war code/application/target/wildfly-8.0.0.Alpha2/standalone/deployments/ -v
‘code/application/application/target/geekseek-1.0.0-alpha-1-SNAPSHOT.war’ -&gt; ‘code/application/target/wildfly-8.0.0.Alpha2/standalone/deployments/geekseek-1.0.0-alpha-1-SNAPSHOT.war’</screen>
<simpara>This will trigger something similar to the following on the server console:</simpara>
<screen>18:11:46,839 INFO  [org.jboss.as.server] (DeploymentScanner-threads - 2) JBAS018559: Deployed "geekseek-1.0.0-alpha-1-SNAPSHOT.war" (runtime-name : "geekseek-1.0.0-alpha-1-SNAPSHOT.war")</screen>
<simpara>Once deployed, you&#8217;ll be able to launch your web browser of choice, point it to <literal>http://localhost:8080/geekseek-(version)</literal> (for instance <literal>http://localhost:8080/geekseek-1.0.0</literal>), and add explore the screens powering the featureset we&#8217;ve covered above.</simpara>
</section>
</section>
</section>
<section id="_use_cases_and_chapter_guide">
<title>Use Cases and Chapter Guide</title>
<simpara>Each chapter from here on out will address a set of related technical and user-centric use cases.  They&#8217;ll be organized as follows:</simpara>
<section id="_chapter_5_java_persistence_and_relational_data">
<title>Chapter 5 - Java Persistence and Relational Data</title>
<simpara>Our feature set above demands a variety of operations that depend upon persistent data; information that must be saved longer than a user&#8217;s session or even the application&#8217;s startup/shutdown lifecycle.  It&#8217;s likely we won&#8217;t be able to hold all of our data in memory either, so we&#8217;ll need to tackle issues like serialization and concurrent, multi-user access.</simpara>
<simpara>As our logical data analysis has exposed, we have plenty of data types that might work well arranged in a table/row/column structure provided by the <emphasis>relational</emphasis> model, and that&#8217;s exactly what we&#8217;ll cover in Chapter 5.</simpara>
<simpara>We&#8217;ll also give a brief overview of mapping from a relational database to an object model that&#8217;s more familiar and friendly using the <emphasis>Java Persistence API</emphasis> and transactional support via <emphasis>Enterprise JavaBeans</emphasis>, and we&#8217;ll be sure to test that our domain layer is properly tested against known data sets using the handy <emphasis>Arquillian Persistence Extension</emphasis>.</simpara>
</section>
<section id="_chapter_6_nosql_data_grids_and_graph_databases">
<title>Chapter 6 - NoSQL: Data Grids and Graph Databases</title>
<simpara>While it enjoys popularity as the most widely-deployed database management system flavor, the relational model is not the only representation we have at our disposal.  In recent years a paradigm shift has been prevalent in the persistence space.</simpara>
<simpara>NoSQL is a blanket term which has varied definitions, but generally refers to any number of database systems which do not employ the relational model.  Popular implementations include a document store (ie. <ulink url="http://www.mongodb.org/">MongoDB</ulink>), a key/value store (ie. <ulink url="http://www.jboss.org/infinispan/">Infinispan</ulink>), or a graph database (ie. <ulink url="http://www.neo4j.org/">Neo4j</ulink>).</simpara>
<simpara>We&#8217;ve noted above that our user relationship model is a natural graph and that our attachments might be well-served from a key/value store, so Chapter 6 will take a look at implementing persistent storage through these mechanisms.</simpara>
</section>
<section id="_chapter_7_business_logic_and_the_services_layer">
<title>Chapter 7 - Business Logic and the Services Layer</title>
<simpara>With our persistence layers covered, we need to expose some way of allowing users to interact with the data and carry out the business logic demanded by our requirements.  Java EE recommends encapsulating business logic in components such as <emphasis>Enterprise JavaBeans (EJBs)</emphasis> or <emphasis>Contexts and Dependency Injection (CDI)</emphasis> beans; we&#8217;ll be using primarily EJBs.</simpara>
<simpara>EJBs and CDI beans are very handy for either direct calling or via a <emphasis>remote procedure call</emphasis> (RPC) style, but they don&#8217;t do much to inform us as users about the possible state transitions and available operations as we navigate the application.</simpara>
<simpara>Our use case will explore the testable development of an SMTP service and interacting with an external, asynchronous, non-transactional resource.</simpara>
</section>
<section id="_chapter_8_rest_and_addressable_services">
<title>Chapter 8 - REST and Addressable Services</title>
<simpara>REST (<emphasis>Re</emphasis> presentational <emphasis>S</emphasis> tate <emphasis>T</emphasis> ransfer) is an architecture of patterns that reveal services as resources in a fashion consistent with the guiding concepts behind the web itself.  Chapter 7 will introduce the exposition of enterprise services using REST guidelines, and will be implemented with Java EE&#8217;s JAX-RS framework.  Additionally, we&#8217;ll test our endpoints using <emphasis>Arquillian Warp</emphasis> and the <ulink url="http://code.google.com/p/rest-assured/">REST-assured</ulink> project.</simpara>
</section>
<section id="_chapter_8_user_interfaces">
<title>Chapter 8 - User Interfaces</title>
<simpara>With our services made available via an addressable resource due to our REST layer, we can begin to create a client of our application which allows users to interact.  This will compose our user interface.</simpara>
<section id="_javascript_rest_client">
<title>JavaScript / REST client</title>
</section>
<section id="_angular_js">
<title>Angular.js ?</title>
</section>
</section>
<section id="_chapter_9_transactions">
<title>Chapter 9 - Transactions</title>
<section id="_tx_testing_plan">
<title>Tx Testing Plan</title>
</section>
</section>
<section id="_chapter_10_security">
<title>Chapter 10 - Security</title>
<simpara>Our feature set requirements clearly couple user registration with an existing Twitter account, so we&#8217;ll need plenty of implementation and testing to ensure that the integrity of our users is not compromised.</simpara>
<simpara>Chapter 10 will involve OAuth authentication using security and identify management from the <ulink url="http://www.jboss.org/picketlink">PicketLink</ulink> project.  We&#8217;ll again look to REST-assured to help us with our client testing strategy.</simpara>
</section>
<section id="_chapter_11_assembly_and_deployment">
<title>Chapter 11 - Assembly and Deployment</title>
<simpara>Once we&#8217;ve abided by proper modular design principles, it&#8217;s time to bring everything together and do some full-scale integration testing upon the final deployable archive.  Chapter 11 will combine our application and set up some test configurations to flex all layers of GeekSeek working in tandem.</simpara>
</section>
<section id="_chapter_12_efficiency_and_quality_during_development">
<title>Chapter 12 - Efficiency and Quality During Development</title>
<simpara>Orthogonal to the task of creating our example application, there are a series of techniques we may employ to help us to code more quickly and confidently.  These include:</simpara>
<itemizedlist>
<listitem>
<simpara>
The use of "remote" containers during the development lifecycle
</simpara>
</listitem>
<listitem>
<simpara>
Hot-swapping new code into a deployed container with <ulink url="http://zeroturnaround.com/software/jrebel/">JRebel</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Analyzing code coverage and <emphasis>Arquillian Jacoco</emphasis>
</simpara>
</listitem>
<listitem>
<simpara>
Static analysis
</simpara>
</listitem>
</itemizedlist>
<simpara><emphasis role="strong"><emphasis role="strong">TODO This is still incomplete and undefined</emphasis></emphasis></simpara>
</section>
<section id="_chapter_13_arquillian_extensibility">
<title>Chapter 13 - Arquillian Extensibility</title>
<simpara>Throughout the text we&#8217;ll be covering a series of "Containers" and "Extensions" to Arquillian; these extend the core behaviors allowing us to hook into 3rd-party tools or execute some custom logic during test execution.</simpara>
<simpara>However, the Arquillian Community can&#8217;t possibly foresee all testing use cases, and new integration points are emerging all of the time.  For this reason, we provide the Arquillian <emphasis>Service Provider Interface</emphasis> (SPI), a set of hooks which allow you as a user of Arquillian to extend its behavior.</simpara>
<simpara>Chapter 13 will cover the SPI and explain the construction of your own Arquillian extension points.</simpara>
<simpara>With our birds-eye view of the GeekSeek example application complete, it&#8217;s time to dig into some code.</simpara>
</section>
</section>
</section>
<section id="_java_persistence_and_relational_data">
<title>Java Persistence and Relational Data</title>
<simpara><emphasis>"Energy and persistence conquer all things." - Benjamin Franklin</emphasis></simpara>
<simpara>If we really boil down the primary objective of most applications to bare metal, we&#8217;ll find that nearly everything we do involves an interaction with <emphasis>data</emphasis>.  We supply it when we make a new online order.  We pull it out when we research on a Wiki.  We update it when we change our credit card&#8217;s billing address.</simpara>
<simpara>The information contained in a system at any point in time comprises the <emphasis>state</emphasis> of the application, and state comes in a variety of <emphasis>scopes</emphasis>, including:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Request</simpara></entry>
<entry align="left" valign="top"><simpara>Limited access within one request/response cycle</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Session</simpara></entry>
<entry align="left" valign="top"><simpara>Limited access within one user session</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Conversation/Sequence/Transaction</simpara></entry>
<entry align="left" valign="top"><simpara>Limited access to a sequence of events (treated as one unit) within one user session</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Application</simpara></entry>
<entry align="left" valign="top"><simpara>Shared throughout the application</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Environment</simpara></entry>
<entry align="left" valign="top"><simpara>Shared throughout the host environment</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Depending upon your view or framework of choice, there may be other ways to slice visibility, but the above table outlines some of the most commonly-used paradigms.</simpara>
<simpara>As is thematic throughout the study of computer science, the rule of thumb is to limit ourselves to the smallest scope required.  Fine-grained access to data helps to ensure that we don&#8217;t leak out state where it can cause security issues or difficult-to-debug behaviors.  Can you imagine what it&#8217;d be like if one user&#8217;s access to his online bank account were to be replicated to all active sessions?</simpara>
<simpara>In addition to the notion of scopes, which limit data&#8217;s visibility, we also have the concept of <emphasis>persistence</emphasis>.  Persistence is a property which dictates whether or not state will survive outside of its confining scope.  For instance: we may allow a user to log in and change her online profile, but if we don&#8217;t synchronize these updates with some sort of persistent storage, they&#8217;ll be lost as soon as her user session which defines the scope of this data is closed.</simpara>
<simpara>Perhaps the simplest way to handle persistent storage is to directly serialize information to the file system.  At first glance, this looks like a nice approach; we open up a file, write whatever we want in there, and close it up.  Later we go in and read as needed.  Easy!</simpara>
<simpara>Until we start to think through how this is going to play out in practice.  Our applications are multi-user; they support any number of operations going on in parallel.  How are we to ensure that we don&#8217;t have two writes happening on the same file at once?  We could put a read/write lock in place to ensure that only one write happens at a time, but then we could potentially queue up lots of write requests while work is being done.  And what about auditing our changes, or ensuring that the integrity of our data model is preserved in case of an error?  Very quickly we&#8217;ll discover that the task of persisting our data is a first-class problem in and of itself, and one that probably doesn&#8217;t belong on our desks as application developers.</simpara>
<simpara>It&#8217;d be much better to delegate the task of persistent storage to another component equipped to handle this efficiently and securely.  Luckily, we&#8217;ll have our pick of any number of Database Management Systems (DBMS) which do just that.</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT IMAGE OF APPLICATION &gt; DBMS MODEL</emphasis></emphasis></simpara>
<simpara>The role of a DBMS is very generally to store and provide access to data.  They come in a variety of flavors which are differentiated in terms of how they internally organize information:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Relational (RDBMS)</simpara></entry>
<entry align="left" valign="top"><simpara>Like data is grouped into tables where columns represent data types and rows represent records.  Most often employs a protocol language called <emphasis>Structured Query Language</emphasis> (SQL) for interaction.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Graph</simpara></entry>
<entry align="left" valign="top"><simpara>Stores objects with relationships in a graph structure; ideal for traversing nodes.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Key/Value</simpara></entry>
<entry align="left" valign="top"><simpara>Nested Map or document-oriented structure, becoming very popular in recent years.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>This chapter will focus on today&#8217;s most commonly-used relational model (NoSQL will be covered next in Chapter 6).</simpara>
<section id="_the_relational_database_model">
<title>The Relational Database Model</title>
<simpara>To best understand the relational model, let&#8217;s highlight how it differs from the object model with which we&#8217;re already familiar.  For this example we&#8217;ll seek to describe a family.</simpara>
<simpara>Each member of the family may be represented by a <literal>Person</literal> object:</simpara>
<programlisting language="java" linenumbering="unnumbered">public class Person {

    // Instance members
    private Long id;
    private String name;
    private Boolean male;
    private Person father;
    private Person mother;
    private List&lt;Person&gt; children;

    // Accessors / Mutators
    public Long getId() {
        return id;
    }
    public void setId(final Long id) {
        this.id = id;
    }
    /* Other properties ommitted for brevity... */
}</programlisting>
<simpara>Simple enough; this value object which explicitly declares the relationship between a parent and child is sufficient for us to further infer siblings, grandparents, cousins, aunts, uncles, and so on.  If we populate a few of these objects and wire them together, we&#8217;ll end up with a <emphasis>graph</emphasis> representing our family:</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT IMAGE OF FAMILY, MODELED AS A GRAPH</emphasis></emphasis></simpara>
<simpara>Now, let&#8217;s take a look at how that same information might be represented in a relational database.  Much like a spreadsheet, classes from our object model are instead organized into tables:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Data Type</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">Field Name</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>UNSIGNED INTEGER</literal> (<emphasis>PK</emphasis>)</simpara></entry>
<entry align="left" valign="top"><simpara>id</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>VARCHAR(255)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>name</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>BIT(1)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>male</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>UNSIGNED INTEGER</literal></simpara></entry>
<entry align="left" valign="top"><simpara>father</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>UNSIGNED INTEGER</literal></simpara></entry>
<entry align="left" valign="top"><simpara>mother</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Already we see there are some differences here.  The <literal>id</literal>, <literal>name</literal>, and <literal>male</literal> fields are as we might expect; simple data types where a Java <literal>Long</literal> is now represented as a database <literal>UNSIGNED INTEGER</literal>, a Java <literal>String</literal> maps to a <literal>VARCHAR(255)</literal> (variable-length character String with maximum length of 255), and a Java <literal>Boolean</literal> becomes a <literal>BIT</literal> type.  But instead of a direct reference to the <literal>mother</literal> or <literal>father</literal>, instead we see the data type there is <literal>UNSIGNED INTEGER</literal>.  Why?</simpara>
<simpara>This is the defining characteristic of <emphasis>relational</emphasis> in RDBMS.  These fields are in fact pointers to the <emphasis>primary key</emphasis>, or identifying <literal>id</literal> field of another record.  As such, they are called <emphasis>foreign keys</emphasis>.  So our data may look something like this:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>id</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>male</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>father</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>mother</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>Paternal Grandpa</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>Paternal Grandma</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>3</simpara></entry>
<entry align="left" valign="top"><simpara>Dad</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>4</simpara></entry>
<entry align="left" valign="top"><simpara>Mom</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>5</simpara></entry>
<entry align="left" valign="top"><simpara>Brother</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>3</simpara></entry>
<entry align="left" valign="top"><simpara>4</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>6</simpara></entry>
<entry align="left" valign="top"><simpara>Sister</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
<entry align="left" valign="top"><simpara>3</simpara></entry>
<entry align="left" valign="top"><simpara>4</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Note especially that there is no direct data reference to the children of a person in the relational model.  That&#8217;s because this is the "many" side of a "one to many" relationship; one person may have many children and many children may have one father and one mother.  So therefore, to find the children of a given person, we&#8217;d ask the database something like:</simpara>
<simpara><emphasis>"Please give me all the records where the <emphasis>mother</emphasis> field is my ID if I&#8217;m not a male, and where the <emphasis>father</emphasis> field is my ID if I am a male."</emphasis></simpara>
<simpara>Of course, the English language might be a bit more confusing than we&#8217;d like, so luckily we&#8217;d execute a query in SQL to handle this for us.</simpara>
<simpara>So instead of the graph relationship we have with an object model, the relational model gives us something a little like this:</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT PICTURE OF RELATIONAL LAYOUT</emphasis></emphasis></simpara>
</section>
<section id="_the_java_persistence_api">
<title>The Java Persistence API</title>
<simpara>It&#8217;s nice that a DBMS allows us to relieve ourselves of the details involving persistence, but there are a few issues that introducing this separate data layer presents.</simpara>
<itemizedlist>
<listitem>
<simpara>
Though SQL is an ANSI Standard, its use is not truly portable between RDBMS vendors.  In truth each database product has its own dialect and extensions.
</simpara>
</listitem>
<listitem>
<simpara>
The details of interacting with a database are vendor-dependent, though there are connection-only abstractions (drivers) in Java (for instance Java Database Connectivity (JDBC)).
</simpara>
</listitem>
<listitem>
<simpara>
The relational model used by the database doesn&#8217;t map on its own to the object model we use in Java; this is called the <emphasis>object/relational impedance mismatch</emphasis>
</simpara>
</listitem>
</itemizedlist>
<simpara>To address each of these problems, Java EE6 provides a specification called the <emphasis>Java Persistence API</emphasis> (JPA), defined by <ulink url="http://jcp.org/en/jsr/detail?id=317">JSR 317</ulink>.  JPA is comprised of both an <ulink url="http://docs.oracle.com/javaee/6/api/javax/persistence/package-summary.html">API</ulink> for defining and interacting with entity objects and an SQL-like query language called <emphasis>Java Persistence Query Language</emphasis> (JPQL) for portable interaction with a variety of database implementations.  Because JPA is itself a spec, there are a variety of open-source compliant implementations available, including <ulink url="http://hibernate.org/">Hibernate</ulink>, <ulink url="http://www.eclipse.org/eclipselink/">EclipseLink</ulink>, and <ulink url="http://openjpa.apache.org/">OpenJPA</ulink>.</simpara>
<simpara>So now our tiered data architecture may look something like this:</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT IMAGE OF APPLICATION ENABLED w/ JPA TALKING TO JDBC, GOING TO DB</emphasis></emphasis></simpara>
<simpara>Though a full overview of this technology stack is beyond the scope of this book, we&#8217;ll be sure to point you to enough resources and explain the basics of interacting with data via JPA that you&#8217;ll be able to understand our application and test examples.</simpara>
<section id="_pojo_entities">
<title>POJO Entities</title>
<simpara>Again, as Java developers we&#8217;re used to interacting with objects and the classes that define them.  Therefore, JPA allows us to design our object model as we wish, and by sprinkling on some additional metadata (typically in the form of annotations, though XML may also be applied), we can tell our JPA provider enough for it to take care of the <emphasis>object/relational mapping</emphasis> for us.  For instance, applying the <literal>javax.persistence.Entity</literal> annotation atop a value object like our <literal>Person</literal> class above is enough to denote a JPA entity.  The data type mapping is largely inferred from our source Java types (though this may be overridden), and we define relationship fields using the <literal>@javax.persistence.OneToOne</literal>, <literal>@javax.persistence.OneToMany</literal>, and <literal>@javax.persistence.ManyToMany</literal> annotations.  We&#8217;ll see examples of this later in our application.</simpara>
<simpara>The important thing to keep in mind is the concept of <emphasis>managed entities</emphasis>.  Because JPA exposes a POJO (plain old Java object) programming model, consider the actions that this code might do upon an entity class <literal>Person</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">Person person = new Person();
person.setName("Dick Hoyt");</programlisting>
<simpara>OK, so very clearly we&#8217;ve created a new <literal>Person</literal> instance and set his name.  The beauty of the POJO programming model is also its drawback; this is just a regular object.  Without some additional magic, there&#8217;s no link to the persistence layer.  This coupling is done transparently to us, and the machine providing the voodoo is the JPA <literal>EntityManager</literal>.</simpara>
<simpara>The <ulink url="http://docs.oracle.com/javaee/6/api/javax/persistence/EntityManager.html"><literal>javax.persistence.EntityManager</literal></ulink> is our hook to a defined <emphasis>persistence unit</emphasis>, our abstraction above the database.  By associating POJO entities with the <literal>EntityManager</literal>, they become monitored for changes such that any state differences which take place in the object will be reflected in persistent storage.  An object under such supervision is called <emphasis>managed</emphasis>.  Perhaps this is best illustrated by some examples:</simpara>
<programlisting language="java" linenumbering="unnumbered">Person person = entityManager.find(Person.class, 1L); // Look up "Person" with Primary Key of 1
System.out.println("Got " + person); // This "person" instance is managed
person.setName("New Name"); // By changing the name of the person,
                            // the database will be updated when
                            // the EntityManager is flushed (likely when the current
                            // transaction commits)</programlisting>
<simpara>Above we perform a lookup of the entity by its primary key, modify its properties just as we would any other object, then let the <literal>EntityManager</literal> worry about synchronizing the state changes with the underlying database.  Alternatively, we could manually attach and detach the POJO from being <emphasis>managed</emphasis>:</simpara>
<programlisting language="java" linenumbering="unnumbered">Person person = new Person();
person.setId(1L); // Just a POJO
managedPerson = entityManager.merge(person); // Sync the state with the existing persistence context
managedPerson.setName("New Name"); // Make a change which be eventually become propagated to the DB
entityManager.detach(managedPerson); // Make "managedPerson" unmanaged
managedPerson.setName("Just a POJO");  // This state change will *not* be
                                       // propagated to the DB, as we're now unmanaged</programlisting>
</section>
</section>
<section id="_the_example_application">
<title>The Example Application</title>
<simpara>This is the first chapter we&#8217;ll be dealing with the companion Example Application for the book; its purpose is to highlight all layers working in concert to fulfill the <emphasis>user requirements</emphasis> dictated by each chapter.  From here out, we&#8217;ll be pointing to selections from the example application in order to showcase how we wire together the domain, application, view, and test layers in a cohesive, usable project.</simpara>
<simpara>The application&#8217;s sources may be built via Apache Maven, and are located under the <literal>code/application</literal> folder of the <ulink url="https://github.com/arquillian/continuous-enterprise-development/">Project Root in SCM</ulink>.  As we go along, we&#8217;ll note each file so that you may draw references between the text and the deployable example.  We&#8217;re firm believers that you best learn by doing (or at least exploring real code), so we invite you to dig in and run the examples as we go along.</simpara>
<simpara>Our application will be a simple conference tracker similar in functions to those provided by <ulink url="http://lanyrd.com/">Lanyrd</ulink>.  We&#8217;ll make it possible to track software conferences, their sessions and related entities, and in every chapter we&#8217;ll lay out a new set of user requirements which we&#8217;ll seek to satisfy using Java EE standards and extensions.  Testing is a first-class citizen in verifying that our development is done correctly, so for instance in this chapter we&#8217;ll be focusing on interactions with persistent data.</simpara>
</section>
<section id="_requirements_gathering_and_definition">
<title>Requirements Gathering and Definition</title>
<simpara>Before we can hope to arrive at any solutions, it&#8217;s important to clearly identify the problem domain.  Each chapter will first outline the goals we&#8217;re looking to address.</simpara>
<section id="_user_perspective">
<title>User Perspective</title>
<simpara>Our users are going to have to perform a series of <emphasis>CRUD</emphasis> (Create, Read, Update, Delete) operations upon the entities which drive our application&#8217;s data.  As such, we&#8217;ve defined a set of user-centric requirements:</simpara>
<screen>As a User, I should be able to:
...add a Conference.
...add a Session.
...view a Conference.
...view a Session.
...change a Conference.
...change a Session.
...remove a Conference.
...remove a Session.</screen>
<simpara>Quite simple (and maybe even redundant!) when put in these terms, especially for this persistence example.  However, it&#8217;s wise to get into the habit of thinking about features from a user perspective; this technique will come in quite handy later on when in more complex cases it&#8217;ll be easy to get mired in the implementation specifics of providing a feature, and we don&#8217;t want to lose track of the <emphasis>real</emphasis> goal we&#8217;re aiming to deliver.</simpara>
<simpara>To state even more generally:</simpara>
<screen>As a User, I should be able to Create, Read, Update, and Delete Conference and Session types.</screen>
<simpara>Of course, we have some other requirements which do not pertain to the user perspective.</simpara>
</section>
<section id="_technical_concerns">
<title>Technical Concerns</title>
<simpara>As noted in the introduction, the issue of data persistence is not trivial.  We must ensure that our solution will address:</simpara>
<itemizedlist>
<listitem>
<simpara>
Concurrent access
</simpara>
</listitem>
<listitem>
<simpara>
Multi-user access
</simpara>
</listitem>
<listitem>
<simpara>
Fault-tolerance
</simpara>
</listitem>
</itemizedlist>
<simpara>These constraints upon the environment will help to inform our implementation choices.  Again, explicitly stating these issues may seem obvious, but our experience teaches that sometimes we get so comfortable with an implementation choice that we may not first stop to think if it&#8217;s even appropriate!  For instance, a news or blogging site which has a high read to write ratio may not even need to worry about concurrency if the application can support stale data safely.  In that case, we might not even need transactions, and bypassing that implementation choice can lead to great gains in performance.</simpara>
<simpara>In our Example Application, however, we&#8217;ll want to ensure that users are seeing up-to-date information that&#8217;s consistent, and that implies a properly synchronized data source guarded by transactions.</simpara>
</section>
</section>
<section id="_implementation_technologies">
<title>Implementation Technologies</title>
<simpara>Given our user and technical concerns, the Java EE stack using JPA described above will do a satisfactory job towards meeting our requirements.  And there&#8217;s an added benefit: by using frameworks designed to relieve the application developer of complicated programming, we&#8217;ll end up writing a lot less code.  This will help us to reduce the <emphasis>conceptual weight</emphasis> of our code and ease maintenance over the long run.  The slices of Java EE that we&#8217;ll use specifically include:</simpara>
<itemizedlist>
<listitem>
<simpara>
Java Transaction API (JTA)
</simpara>
</listitem>
<listitem>
<simpara>
Enterprise JavaBeans (EJB, <ulink url="http://jcp.org/aboutJava/communityprocess/final/jsr318/">JSR 318</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
JPA
</simpara>
</listitem>
</itemizedlist>
<simpara>Transactions are a wide subject that merits its own book when dealing with the mechanics of implementing a viable transactional engine.  For us as users, however, the rules are remarkably simple.  We&#8217;ll imagine a transaction is a set of code that runs within a block.  The instructions that are executed within this block must adhere to the <emphasis>ACID</emphasis> properties: Atomicity, Consistency, Isolation, and Durability.</simpara>
<itemizedlist>
<listitem>
<simpara>
Atomicity - The instructions in the block act as one unit; they either succeed (<emphasis>commit</emphasis>) or fail (<emphasis>rollback</emphasis>) together
</simpara>
</listitem>
<listitem>
<simpara>
Consistency - All resources associated with the transaction (in this case, our database), will always be in a legal, viable state.  For instance, a foreign key field will always point to a valid primary key.  These rules are typically enforced by the transactional resource (again, our database).
</simpara>
</listitem>
<listitem>
<simpara>
Isolation - Actions taken upon transactional resources within a Tx block will <emphasis>not</emphasis> be seen outside the scope of the current transaction until and unless the transaction has successfully committed.
</simpara>
</listitem>
<listitem>
<simpara>
Durability - Once committed, the state of a transactional resource will not revert back or lose data.
</simpara>
</listitem>
</itemizedlist>
<simpara>Enterprise JavaBeans, or EJBs, enjoy close integration with JTA, so we won&#8217;t have to touch much of the transactional engine directly.  By managing our JPA entities through an <literal>EntityManager</literal> which is encapsulated inside a transactional EJB, we&#8217;ll get the benefits of transaction demarcation and management for free.  The overall architecture might be more easily described by this graphic:</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">INSERT IMAGE OF ENTITIES MANAGED BY AN EM INSIDE AN EJB IN A TX CONTEXT</emphasis></emphasis></simpara>
<simpara>Persistence is a case that&#8217;s well-understood by and lives at the heart of most Java EE applications, and these standards have been built specifically with our kind of use case in mind.  What&#8217;s left for us is to sanely tie the pieces together, but not before we consider that the runtime is not the only thing with which we should be concerned.</simpara>
</section>
<section id="_requirement_test_scenarios">
<title>Requirement Test Scenarios</title>
<simpara>Of course the runtime will be the user-facing code of our application.  However, the theme of this book is in <emphasis>testable development</emphasis>, and we&#8217;ll be focusing on proof through automated test.  To that end, every user and technical requirement we identify will be matched to an test which will ensure that functions are producing the correct results during the development cycle.  A nice rule of thumb is to abide by the motto: "If it&#8217;s not tested, it doesn&#8217;t exist."</simpara>
<simpara>In this case, we need to create coverage to ensure that we may:</simpara>
<itemizedlist>
<listitem>
<simpara>
Perform CRUD operations on the Conference and Session entities
</simpara>
<itemizedlist>
<listitem>
<simpara>
Execute operations against known data sets and validate the results
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Exercise our Transaction handling:
</simpara>
<itemizedlist>
<listitem>
<simpara>
Commits should result in entity object state flushed to persistent storage
</simpara>
</listitem>
<listitem>
<simpara>
Rollbacks (when a commit fails) result in no changes to persistent storage
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>
<section id="_test_setup">
<title>Test Setup</title>
<simpara>Our tests will be taking advantage of the <ulink url="https://docs.jboss.org/author/display/ARQ/Persistence"><emphasis>Arquillian Persistence Extension</emphasis></ulink>, which is created to aid in writing tests where the persistence layer is involved.  It supports the following features:</simpara>
<itemizedlist>
<listitem>
<simpara>
Wrapping each test in the separated transaction.
</simpara>
</listitem>
<listitem>
<simpara>
Seeding database using:
</simpara>
<itemizedlist>
<listitem>
<simpara>
DBUnit with XML, XLS, YAML and JSON supported as data sets format.
</simpara>
</listitem>
<listitem>
<simpara>
Custom SQL scripts.
</simpara>
</listitem>
<listitem>
<simpara>
Comparing database state at the end of the test using given data sets (with column exclusion).
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<simpara>Creating ad-hoc object graphs in the test code is often too verbose and makes it harder to read the tests themselves.  The Arquillian Persistence Extension provides alternatives to set database fixtures to be used for the given test.</simpara>
<simpara>Adding transactional support to these tests is fairly straightforward.  If that&#8217;s only what you need simply put a <literal>@Transactional</literal> annotation either on the test which you want be wrapped in transaction or on the test class (which will result in all tests running in their own transactions).  The following modes are supported:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>COMMIT</literal>: Each test will be finished with commit operation. This is default behavior.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>ROLLBACK</literal>: At the end of the test execution rollback will be performed.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>DISABLED</literal>: If you have enabled transactional support at the test class level, marking given test with this mode will simply run it without the transaction.
</simpara>
</listitem>
</itemizedlist>
<simpara>We&#8217;ll start by defining the Arquillian Persistence Extension in the <literal>dependencyManagement</literal> section of our parent POM:</simpara>
<simpara><literal>code/application/pom.xml</literal>:</simpara>
<screen>  &lt;properties&gt;
    &lt;version.arquillian_persistence&gt;1.0.0.Alpha6&lt;/version.arquillian_persistence&gt;
    ...
  &lt;/properties&gt;

  ...

  &lt;dependencyManagement&gt;
    &lt;dependencies&gt;
      &lt;dependency&gt;
        &lt;groupId&gt;org.jboss.arquillian.extension&lt;/groupId&gt;
        &lt;artifactId&gt;arquillian-persistence-impl&lt;/artifactId&gt;
        &lt;version&gt;${version.arquillian_persistence}&lt;/version&gt;
        &lt;scope&gt;test&lt;/scope&gt;
      &lt;/dependency&gt;
      ...
    &lt;/dependencies&gt;
  &lt;/dependencyManagement&gt;</screen>
<simpara>And we&#8217;ll also enable this in the <literal>dependencies</literal> section of the POMs of the projects in which we&#8217;ll be using the extension:</simpara>
<simpara><literal>code/application/domain/pom.xml</literal>:</simpara>
<screen>  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.jboss.arquillian.extension&lt;/groupId&gt;
      &lt;artifactId&gt;arquillian-persistence-impl&lt;/artifactId&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    ...
  &lt;/dependencies&gt;</screen>
<simpara>Database configuration for tests powered by the Persistence Extension is done via the same mechanism as is used for the runtime: the <literal>persistence.xml</literal> configuration file.</simpara>
<simpara><emphasis role="strong"><emphasis role="strong">UPDATE THIS TO REFLECT WHAT WE&#8217;LL USE WHEN THE APP IS DONE</emphasis></emphasis>
<literal>code/application/domain/core/src/test/java/org/cedj/app/domain/CoreDeployments.java</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">public static PersistenceDescriptor persistence() {
        return Descriptors.create(PersistenceDescriptor.class).createPersistenceUnit().name("test")
            .getOrCreateProperties().createProperty().name("hibernate.hbm2ddl.auto").value("create-drop").up()
            .createProperty().name("hibernate.show_sql").value("true").up().up()
            .jtaDataSource("java:jboss/datasources/ExampleDS").up();
    }</programlisting>
</section>
<section id="_runtime_components">
<title>Runtime Components</title>
<simpara>With our understanding of how we&#8217;ll go about testing our entities, let&#8217;s delve into the runtime code.  We&#8217;ll start with a look at the entity definitions themselves.</simpara>
<section id="_entity_objects">
<title>Entity Objects</title>
<simpara>We&#8217;re primarily concerned with the introduction of our <literal>Conference</literal> and <literal>Session</literal> entities; a <literal>Conference</literal> may have many <literal>Session+s associated with it.  So +Conference</literal> looks a bit like this:</simpara>
<simpara><literal>code/application/domain/conference/src/main/java/org/cedj/app/domain/conference/model/Conference.java</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">package org.cedj.app.domain.conference.model;

import java.io.Serializable;
import java.util.Collections;
import java.util.HashSet;
import java.util.Set;
import java.util.UUID;

import javax.persistence.CascadeType;
import javax.persistence.Embedded;
import javax.persistence.Entity;
import javax.persistence.FetchType;
import javax.persistence.Id;
import javax.persistence.OneToMany;
import javax.validation.Valid;
import javax.validation.constraints.NotNull;

import org.cedj.app.domain.model.Identifiable;

@Entity
public class Conference implements Identifiable, Serializable {

    private static final long serialVersionUID = 1L;

    @Id
    private String id;

    @NotNull
    private String name;

    private String tagLine;

    @Embedded
    @Valid
    @NotNull
    private Duration duration;

    @OneToMany(fetch = FetchType.EAGER, orphanRemoval = true, mappedBy = "conference", cascade = CascadeType.ALL)
    @Valid
    private Set&lt;Session&gt; sessions;

    public Conference() {
        this.id = UUID.randomUUID().toString();
    }

    public String getId() {
        return id;
    }

    public String getName() {
        return name;
    }

    public Conference setName(String name) {
        this.name = name;
        return this;
    }

    public String getTagLine() {
        return tagLine;
    }

    public Conference setTagLine(String tagLine) {
        this.tagLine = tagLine;
        return this;
    }

    public Conference setDuration(Duration duration) {
        this.duration = duration;
        return this;
    }

    public Duration getDuration() {
        return duration;
    }

    public Set&lt;Session&gt; getSessions() {
        if (sessions == null) {
            this.sessions = new HashSet&lt;Session&gt;();
        }
        return Collections.unmodifiableSet(sessions);
    }

    public Conference addSession(Session session) {
        if (sessions == null) {
            this.sessions = new HashSet&lt;Session&gt;();
        }
        if (!sessions.contains(session)) {
            sessions.add(session);
            session.setConference(this);
        }
        return this;
    }

    public void removeSession(Session session) {
        if (sessions.remove(session)) {
            session.setConference(null);
        }
    }
}</programlisting>
<simpara>You&#8217;ll notice a few interesting bits in play here.</simpara>
<simpara>The <literal>Id</literal> annotation denotes our primary key.</simpara>
<simpara>The <literal>javax.validation.*</literal> annotations allow us to impose validation constraints to ensure the data supplied to these methods is in the correct and expected form.</simpara>
<simpara>Also, <literal>Conference</literal> has a relationship with <literal>Session</literal> as denoted by the <literal>@OneToMany</literal> annotation.  This is a bi-directional relationship; we perform the object association in both the <literal>Conference</literal> and <literal>Session</literal> classes.  Here&#8217;s the definition of <literal>Session</literal>:</simpara>
<simpara><literal>code/application/domain/conference/src/main/java/org/cedj/app/domain/conference/model/Session.java</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">package org.cedj.app.domain.conference.model;

import java.io.Serializable;
import java.util.UUID;

import javax.persistence.Embedded;
import javax.persistence.Entity;
import javax.persistence.Id;
import javax.persistence.Lob;
import javax.persistence.ManyToOne;
import javax.validation.Valid;
import javax.validation.constraints.NotNull;

@Entity
public class Session implements Serializable {

    private static final long serialVersionUID = 1L;

    @Id
    private String id;

    @Embedded
    @NotNull
    @Valid
    private Duration duration;

    @NotNull
    private String title;

    @Lob
    private String outline;

    @ManyToOne
    private Conference conference;

    public Session() {
        this.id = UUID.randomUUID().toString();
    }

    public String getId() {
        return id;
    }

    public Duration getDuration() {
        return duration;
    }

    public void setDuration(Duration duration) {
        this.duration = duration;
    }

    public String getTitle() {
        return title;
    }

    public void setTitle(String title) {
        this.title = title;
    }

    public String getOutline() {
        return outline;
    }

    public void setOutline(String outline) {
        this.outline = outline;
    }

    void setConference(Conference conference) {
        this.conference = conference;
    }
}</programlisting>
<simpara>At this end of the relationship between <literal>Session</literal> and <literal>Conference</literal>, you&#8217;ll see that a <literal>Session</literal> is associated with a <literal>Conference</literal> via the <literal>ManyToOne</literal> annotation.</simpara>
<simpara>Finally, we make use of the <literal>Embedded</literal> annotation to note that we&#8217;d like to store a field as a complex object, in this case, the <literal>Duration</literal>:</simpara>
<simpara><literal>code/application/domain/conference/src/main/java/org/cedj/app/domain/conference/model/Duration.java</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">package org.cedj.app.domain.conference.model;

import java.util.Date;

import javax.validation.constraints.NotNull;

public class Duration {

    @NotNull
    private Date start;

    @NotNull
    private Date end;

    // hidden constructor for Persistence
    Duration() {
    }

    public Duration(Date start, Date end) {
        if (start == null) {
            throw new IllegalArgumentException("Start must be provided");
        }
        if (end == null) {
            throw new IllegalArgumentException("End must be provided");
        }
        if (end.before(start)) {
            throw new IllegalArgumentException("End cannot be before Start");
        }
        this.start = start;
        this.end = end;
    }

    public Date getEnd() {
        return (Date) end.clone();
    }

    public Date getStart() {
        return (Date) start.clone();
    }

    public Integer getNumberOfDays() {
        return -1;
    }

    public Integer getNumberOfHours() {
        return -1;
    }
}</programlisting>
</section>
<section id="_repository_ejbs">
<title>Repository EJBs</title>
<simpara>The "Repository" EJBs are where we&#8217;ll define the actions that may be taken by the user with respect to our entities.  Strictly speaking, they define the verbs: "Create" and "Read".</simpara>
<simpara>We can place most of the logic supporting these operations in an abstract, genericized base class:</simpara>
<simpara><literal>code/application/domain/core/src/main/java/org/cedj/app/domain/Repository.java</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">package org.cedj.app.domain;

import javax.ejb.TransactionAttribute;
import javax.ejb.TransactionAttributeType;
import javax.persistence.EntityManager;
import javax.persistence.PersistenceContext;

import org.cedj.app.domain.model.Identifiable;

@TransactionAttribute(TransactionAttributeType.REQUIRES_NEW)
public class Repository&lt;T extends Identifiable&gt; {

    @PersistenceContext
    private EntityManager manager;

    private Class&lt;T&gt; type;

    public Repository(Class&lt;T&gt; type) {
        this.type = type;
    }

    public T store(T entity) {
        T merged = merge(entity);
        manager.persist(merged);
        return merged;
    }

    public T get(String id) {
        return manager.find(type, id);
    }

    public void remove(T entity) {
        manager.remove(merge(entity));
    }

    private T merge(T entity) {
        return manager.merge(entity);
    }

    protected EntityManager getManager() {
        return manager;
    }
}</programlisting>
<simpara>Despite the small amount of code here, there&#8217;s a lot of utility going on.</simpara>
<simpara>The <literal>TransactionAttribute</literal> annotation and its <literal>REQUIRES_NEW</literal> value on the class level notes that every method invocation upon one of the business methods exposed by the EJB will run in its own transaction.  That means that if a transaction does not exist one will be created.  If there&#8217;s currently a transaction in flight, it will be <emphasis>suspended</emphasis> (ie. dis-associated with the running <literal>Thread</literal>) and a new one put in place.  The suspended transaction will resume when the business method invocation exits.</simpara>
<simpara>An instance member of this class is our <literal>EntityManager</literal>, which will be used to carry out the public business methods <literal>store</literal> (Create) and <literal>get</literal> (Read).  Update is handled by simply reading in an entity, then making any changes to that object&#8217;s state.  The application server will propagate these state changes to persistent storage when the transaction commits (ie. a transactional business method invocation completes successfully).</simpara>
<simpara>We can now extend this behavior with a concrete class and supply the requisite EJB annotations easily:</simpara>
<simpara><literal>code/application/domain/conference/src/main/java/org/cedj/app/domain/conference/ConferenceRepository.java</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">package org.cedj.app.domain.conference;

import javax.ejb.Stateless;

import org.cedj.app.domain.Repository;
import org.cedj.app.domain.conference.model.Conference;

@Stateless
public class ConferenceRepository extends Repository&lt;Conference&gt; {

    public ConferenceRepository() {
        super(Conference.class);
    }
}</programlisting>
<simpara>The <literal>Stateless</literal> annotation defines this class as an EJB, a Stateless Session Bean, meaning that the application server may create and destroy instances at will, and a client should not count on ever receiving any particular instance.</simpara>
</section>
<section id="_from_here_out_just_update_w_new_test_code">
<title>FROM HERE OUT, JUST UPDATE W/ NEW TEST CODE</title>
<section id="_store">
<title>Store</title>
<itemizedlist>
<listitem>
<simpara>
Setup dataset
</simpara>
</listitem>
<listitem>
<simpara>
Setup expected output
</simpara>
</listitem>
<listitem>
<simpara>
Create Conference Domain Model
</simpara>
</listitem>
<listitem>
<simpara>
Create Conference Repository <emphasis>create</emphasis>
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_update">
<title>Update</title>
<itemizedlist>
<listitem>
<simpara>
Setup dataset
</simpara>
</listitem>
<listitem>
<simpara>
Setup expected output
</simpara>
</listitem>
<listitem>
<simpara>
Create Conference Repository <emphasis>update</emphasis>
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_remove">
<title>Remove</title>
<itemizedlist>
<listitem>
<simpara>
Setup dataset
</simpara>
</listitem>
<listitem>
<simpara>
Setup expected output
</simpara>
</listitem>
<listitem>
<simpara>
Create Conference Repository <emphasis>delete</emphasis>
</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section id="_domain_user">
<title>Domain User</title>
<itemizedlist>
<listitem>
<simpara>
Not explained, only code
</simpara>
</listitem>
<listitem>
<simpara>
See Conference
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_domain_venue">
<title>Domain Venue</title>
<itemizedlist>
<listitem>
<simpara>
Not explained, only code.
</simpara>
</listitem>
<listitem>
<simpara>
See Conference
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_domain_attachment">
<title>Domain Attachment</title>
<itemizedlist>
<listitem>
<simpara>
Not explained, only code.
</simpara>
</listitem>
<listitem>
<simpara>
See Conference
</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section id="_business_logic_and_the_services_layer">
<title>Business Logic and the Services Layer</title>
<simpara><emphasis>"The best way to find yourself is to lose yourself in the service of others." - Mahatma Gandhi</emphasis></simpara>
<simpara>The code we’ve developed and tested up to this point has dealt with data: organizing, accessing, mutating, and transforming it into formats more comfortable to us as application developers. We’ve mentioned that these are the nouns of our GeekSeek project; now it’s time to put these to some good use and take <emphasis>action</emphasis>.</simpara>
<simpara><emphasis>Business logic</emphasis> governs the behaviors which power our applications. As compared with more generic (and <emphasis>cross-cutting</emphasis>) concerns which may be abstracted - security, transactions, object-relational mapping, resource management - business logic lies at the heart of our projects. It is unique to our needs, and no one else can write it for us.</simpara>
<simpara>That said, the cross cutting concerns mentioned above (and many more!) are all commonly-demanded by our business needs. For instance, imagine we have a series of services, each of which needing to be accessed by and authenticated and authorized user, and in the context of a transaction. If we were diligently applying proper modularization and encapsulation, we might implement separate functions for the transactional and security enforcement, then call these from our services:</simpara>
<simpara><emphasis role="strong">INSERT IMAGE SHOWING MANY SERVICES CALLING A AT THE HEAD AND FOOT A COMMON TX AND SECURITY FUNCTION (Fig 07-01)</emphasis></simpara>
<simpara>A glaring problem with this approach is that while we’ve nicely extracted out the logic for our security and transactions for reuse, we must still manually <emphasis>invoke</emphasis> them, sprinkling these method calls at the head and foot of every function requiring their use. Additionally, we may have to pass around contextual objects which know about the state of the current user or transactional registration (though in practice, these are commonly associated with a <literal>Thread</literal>, thus able to fly under the visible API radar in an obfuscated context).</simpara>
<simpara>Things get more complicated when we introduce <emphasis>dependent</emphasis> services. A <literal>UserRegistration</literal> function may in turn call many finer-grained services like <literal>SendEmail</literal>, <literal>PutUserInDatabase</literal>, and <literal>GenerateHashOfPassword</literal>. This composition is desirable because it separates concerns, but we’re left with the problem of <emphasis>looking up</emphasis> or locating each of this disparate services from <literal>UserRegistration</literal>. Ultimately this adds to the "plumbing" code which provides no benefit to us aside from hooking our cleanly-decoupled modules together. While this has historically been addressed by employing a technique known as the <emphasis>Service Locator Pattern</emphasis>, for reasons we’ll soon see, this is a largely outdated and inferior approach.</simpara>
<simpara>A more subtle, yet very important, issue that arises with pure <emphasis>POJO</emphasis> (Plain Old Java Object) programming in a multi-user environment is one of <emphasis>shared state</emphasis>. Consider the following code:</simpara>
<programlisting language="java" linenumbering="unnumbered">public class UserService {

  /** Cached flag denoting if our current user has logged in **/
  private boolean isLoggedIn;

  public boolean authenticate(final String userName,
    final String password){

    // First check if we're already logged in
    if(isLoggedIn){
      return true;
    }

    // Else hash the password, check against the hash
    // in the database, and return true if and
    // only if they match
    /** Omitted for brevity **/

  }
}</programlisting>
<simpara>This <literal>UserService</literal> is clearly meant to be associated with a current user session, and thus has what we call <emphasis>conversational scope</emphasis> confined to that session. When writing manual POJO services, the onus is upon us as developers to ensure that this is enforced; imagine if UserB were to come along and receive the object that UserA had already set <literal>isLoggedIn</literal> to <literal>true</literal>? Scope confinement is vitally important to the integrity of our system, and we have to be very careful when rolling our own solutions.</simpara>
<simpara>In this chapter we&#8217;ll be examining each of these complications and a proposed solution when tackling the testable development of a common, and seemingly innocuous, business requirement: sending email from a Java EE-based application.</simpara>
<section id="_use_case_send_email_on_new_user_signup">
<title>Use Case: Send Email On New User Signup</title>
<simpara>Web-based applications offer few avenues to push information to their users once offline; perhaps the most prevalent is through the use of email.  We see this in a variety of user stories: "Confirm Email Address", "Reset Password", and "Welcome New User" are all subject lines we&#8217;ve grown to expect from the sites we use.  It&#8217;s fitting, then, that we devise a simple strategy to send email from our application which may be easily reused by the more coarsely-grained operations.</simpara>
<simpara>Our GeekSeek application will therefore introduce the requirement: "Send an Email to the new User upon successful Signup"</simpara>
<simpara>At first blush, this seems like a farily trivial problems to solve.  The <ulink url="http://www.oracle.com/technetwork/java/javamail/index.html">JavaMail</ulink> API is straightforward enough to use (though a bit dated), and is included as part of the Java EE platform.</simpara>
<simpara>Unfortunately, there are many issues to consider beyond the boilerplate code required to send the email itself.</simpara>
<simpara><emphasis>Should we block (wait) while the mail message is sent to the SMTP server?</emphasis> Connecting to an external service can take some time, depending upon how it handles open connections.  The delivery of the email isn&#8217;t designed to be immediate, so there&#8217;s not much sense forcing the user to wait while we connect to an SMTP server, construct a <literal>MimeMessage</literal>, and send.</simpara>
<simpara><emphasis>What if sending the email fails?  Should the enclosing user registration action which called the email service fail, too?</emphasis>  Sending the email is, in our case, part of a welcome operation.  A new user registration doesn&#8217;t strictly <emphasis role="strong">need</emphasis> this to succeed as we won&#8217;t be relying upon email to validate the user&#8217;s identity.  Still, we&#8217;d like to make every available effort to ensure that the email goes through, independent of the user registration action.  And we&#8217;d like to have some notification and options to handle emails that were attempted to be sent, but have failed.</simpara>
<simpara><emphasis>How do we test to ensure that the emails we&#8217;ve sent are received?  How do we validate the email&#8217;s contents are correct?</emphasis>  Even if we don&#8217;t dispatch the communication with the SMTP server to a new Thread, interacting with this external process makes for an asynchronous action.  Asynchronous testing is not always the most simple process to set up, but this does not excuse us from the responsibility of ensuring that our email service is worked as designed.</simpara>
<section id="_the_smtp_service">
<title>The SMTP Service</title>
<simpara>We&#8217;ll begin our example with the construction of a generic <literal>SMTPMailService</literal>.  As the name implies, its job will be to act as our Java interface to perform SMTP operations.  Specifically, we&#8217;ll write this to send email.</simpara>
<simpara>First we&#8217;ll make a self-explanatory value object to encapsulate the fields needed to send an email message.  This is implemented as a mutable builder for ease-of-use:</simpara>
<programlisting language="java" linenumbering="unnumbered">public class MailMessageBuilder implements Serializable {

    private static final long serialVersionUID = 1L;

    private static final String[] EMPTY = new String[]{};
    private String from;
    private String subject;
    private String body;
    private String contentType;
    private final Collection&lt;String&gt; toAddresses = new HashSet&lt;String&gt;();

    public MailMessageBuilder from(final String from) throws IllegalArgumentException {
        if (from == null || from.length() == 0) {
            throw new IllegalArgumentException("from address must be specified");
        }
        this.from = from;
        return this;
    }
    // Other fluent API methods omitted for brevity; see full source for details</programlisting>
<simpara><literal>MailMessageBuilder</literal> has a <literal>build</literal> method which may then return an immutable view:</simpara>
<programlisting language="java" linenumbering="unnumbered">public MailMessage build() throws IllegalStateException {

        // Validate
        if (from == null || from.length() == 0) {
            throw new IllegalStateException("from address must be specified");
        }
        if (toAddresses.size() == 0) {
            throw new IllegalStateException("at least one to address must be specified");
        }
        if (subject == null || subject.length() == 0) {
            throw new IllegalStateException("subject must be specified");
        }
        if (body == null || body.length() == 0) {
            throw new IllegalStateException("body must be specified");
        }
        if (contentType == null || contentType.length() == 0) {
            throw new IllegalStateException("contentType must be specified");
        }

        // Construct immutable object and return
        return new MailMessage(from, toAddresses.toArray(EMPTY), subject, body, contentType);

    }</programlisting>
<simpara>It&#8217;s this immutable <literal>MailMessageBuilder.MailMessage</literal> which will be safely passed between our services.</simpara>
<simpara>With our value object defined, we can now create our <literal>SMTPMailService</literal>.  We know that we&#8217;ll need to connect to some external SMTP server via the <literal>JavaMail</literal> API, and Java EE allows injection of these via the <literal>@Resource</literal> annotation (though the mechanics of exactly where some services are bound is vendor-dependent.).  Also, we know that this <literal>SMTPMailService</literal> is meant to be shared by all users running the application, and won&#8217;t have any session-specific state.  For these reasons, we&#8217;ll implement the <literal>SMTPMailService</literal> as a Singleton Session EJB.  Note that a a Stateless Session Bean (for use of a pool of instances) might work in an equally-appropriate fashion.</simpara>
<programlisting language="java" linenumbering="unnumbered">@Singleton
@LocalBean
@TransactionAttribute(value = TransactionAttributeType.SUPPORTS)
public class SMTPMailService {</programlisting>
<simpara>The above is our Singleton bean declaration.  Of particular note is the <literal>TransactionAttributeType.SUPPORTS</literal> value for <literal>@TransactionAttribute</literal>, which will apply to all business methods of this EJB.</simpara>
<simpara>An SMTP server is an external resource which is not transactionally-aware.  Therefore, we&#8217;ll have to make note of any exceptions and ensure that if we want a transaction rolled back, we either explicitly tell that to the <literal>TransactionManager</literal> or throw an unchecked exception which will signal the EJB container to mark any currently-executing transaction for rollback.</simpara>
<simpara>We&#8217;re making a general-purpose SMTP service here, so we may not always know the appropriate actions to take with regards to transactions.  The default for EJB is <literal>@TransactionAttributeType.MANDATORY</literal>, which creates a transaction if one is not already in flight.  That&#8217;s not really appropriate here; the SMTP server with which we interact is not transactional, it it&#8217;d be silly to sacrifice the overhead of starting a transaction when we&#8217;re not even dealing with a resource which will respect its semantics!  <literal>@TransactionAttributeType.SUPPORTS</literal>, which we&#8217;ve used here, will accept existing transactions if one is in play, or do nothing if we&#8217;re invoked outside of a transactional context.</simpara>
<simpara>Now we need to define a method to do the dirty work: accept our <literal>MailMessage</literal> as a parameter and send it along to the SMTP server.  The <literal>JavaMail</literal> API will act as our conduit to connect to the SMTP server, so we&#8217;ll take advantage of Java EE&#8217;s <literal>@Resource</literal> annotation to inject some relevant supporting services into our <literal>SMTPMailService</literal>.</simpara>
<simpara>With our service and class declaration handled, we&#8217;re now ready to inject the external hooks we&#8217;ll need to send email.  The Java EE container will provide these for us:</simpara>
<programlisting language="java" linenumbering="unnumbered">@Resource(lookup = SMTPMailServiceConstants.JNDI_BIND_NAME_MAIL_SESSION)
private javax.mail.Session mailSession;

@Resource(lookup = "java:/ConnectionFactory")
private javax.jms.ConnectionFactory connectionFactory;

@Resource(lookup = SMTPMailServiceConstants.JNDI_BIND_NAME_SMTP_QUEUE)
private javax.jms.Queue smtpQueue;</programlisting>
<simpara>The <literal>@Resource.lookup</literal> attribute has vendor-specific function, but most often maps to a JNDI name.  This use case has been coded to run specifically on the JBoss family of application servers, so some adjustment to these values may be necessary in your environment.  To that end we&#8217;ve centralized some JNDI names in a small interface:</simpara>
<programlisting language="java" linenumbering="unnumbered">public interface SMTPMailServiceConstants {

    /**
     * Name in JNDI to which the SMTP {@link javax.mail.Session} will be bound
     */
    String JNDI_BIND_NAME_MAIL_SESSION = "java:jboss/mail/GeekSeekSMTP";

    /**
     * Name in JNDI to which the SMTP Queue is bound
     */
    String JNDI_BIND_NAME_SMTP_QUEUE = "java:/jms/queue/GeekSeekSMTP";
}</programlisting>
<simpara>Note that we have put into place a field called <literal>smtpQueue</literal>, of type <literal>javax.jms.Queue</literal>.  This is how we&#8217;ll handle two of the "hidden" problems with testable development of sending email raised earlier.</simpara>
<simpara>First, sending a message to a JMS Queue is a "fire and forget" operation.  Once the message is received by the queue (which is in-process, unlike our production SMTP server), control is returned to the caller and the handling of the message is processed asynchronously.  If we create a listener to pull messages off the queue and send emails, then we won&#8217;t have to wait for this process to complete.  This gives us asynchrony for free.</simpara>
<simpara>The other tangible benefit to using a JMS queue to send messages is in the guaranteed processing afforded by JMS.  If there&#8217;s a temporary error in sending the email, for instance a connection problem to the remote SMTP server, the messaging server will dutifully retry (as configured) a number of times.  This process will even survive server restarts; if for some reason all of these retries fail to yield a successful result (again, after some configured number of tries or timeout), messages can be forwarded to the DLQ (dead-letter queue) for manual inspection by system administrators later.  This gives us some assurance that we won&#8217;t lose messages we intended to send, and we also won&#8217;t have to fail our user registration process entirely if there&#8217;s some issue with sending the welcome email.</simpara>
<simpara>In WildFly / JBossAS7 / JBoss EAP, we deploy a JMS Queue with the deployment descriptor <literal>geekseek-smtp-queue-jms.xml</literal> (the filename may be anything located in the EJB JAR&#8217;s <literal>META-INF</literal> and ending with the suffix <literal>-jms.xml</literal>):</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;messaging-deployment xmlns="urn:jboss:messaging-deployment:1.0"&gt;
    &lt;hornetq-server&gt;
        &lt;jms-destinations&gt;
            &lt;jms-queue name="GeekSeekSMTP"&gt;
                &lt;entry name="jms/queue/GeekSeekSMTP"/&gt;
            &lt;/jms-queue&gt;
        &lt;/jms-destinations&gt;
    &lt;/hornetq-server&gt;
&lt;/messaging-deployment&gt;</programlisting>
<simpara>This will bind a new JMS Queue to the JNDI address <literal>java:/jms/queue/GeekSeekSMTP</literal>, which we reference above in the <literal>@Resource.lookup</literal> attribute.</simpara>
<simpara>With our supporting services and resources hooked in and available to our EJB, we can code the <literal>sendMail</literal> method.  As noted before, this is likely the least interesting part of the use case, even though it&#8217;s technically the code which drives the entire feature.</simpara>
<programlisting language="java" linenumbering="unnumbered">public void sendMail(final MailMessageBuilder.MailMessage mailMessage)
  throws IllegalArgumentException {

    // Precondition check
    if (mailMessage == null) {
        throw new IllegalArgumentException("Mail message must be specified");
    }

    try {
        // Translate
        final MimeMessage mime = new MimeMessage(mailSession);
        final Address from = new InternetAddress(mailMessage.from);
        final int numToAddresses = mailMessage.to.length;
        final Address[] to = new InternetAddress[numToAddresses];
        for (int i = 0; i &lt; numToAddresses; i++) {
            to[i] = new InternetAddress(mailMessage.to[i]);
        }
        mime.setFrom(from);
        mime.setRecipients(Message.RecipientType.TO, to);
        mime.setSubject(mailMessage.subject);
        mime.setContent(mailMessage.body, mailMessage.contentType);
        Transport.send(mime);
    } // Puke on error
    catch (final javax.mail.MessagingException e) {
        throw new RuntimeException("Error in sending " + mailMessage, e);
    }
}</programlisting>
<simpara>Nothing special going on here; we translate our own value object <literal>MailMessageBuilder.MailMessage</literal> into fields required by JavaMail&#8217;s <literal>MimeMessage</literal>, and send.  Any errors we&#8217;ll wrap in a <literal>RuntimeException</literal> to be handled by the EJB container (resulting in transaction rollback if one is being used).</simpara>
<simpara>This method, of course, is synchronous up until the mail message is delivered to the SMTP server.  We noted earlier that it&#8217;s likely better in a multiuser environment to queue the mail for sending such that we don&#8217;t have to wait on interaction with this external resource, so we&#8217;ll also supply a <literal>queueMailForDelivery</literal> method to send our desired message to a JMS queue.</simpara>
<programlisting language="java" linenumbering="unnumbered">public void queueMailForDelivery(final MailMessageBuilder.MailMessage mailMessage)
        throws IllegalArgumentException {

    // Precondition check
    if (mailMessage == null) {
        throw new IllegalArgumentException("Mail message must be specified");
    }

    try {
        final Connection connection = connectionFactory.createConnection();
        final javax.jms.Session session = connection
          .createSession(false, javax.jms.Session.AUTO_ACKNOWLEDGE);
        final MessageProducer producer = session.createProducer(smtpQueue);
        final ObjectMessage jmsMessage = session.createObjectMessage(mailMessage);
        producer.send(jmsMessage);
    } catch (final JMSException jmse) {
        throw new RuntimeException("Could not deliver mail message to the outgoing queue",
          jmse);
    }
}</programlisting>
<simpara>Sending the JMS message doesn&#8217;t fully get our mail delivered, however; it just sends it to a JMS queue.  We still need a component to pull this JMS message off the queue, unwrap the <literal>MailMessage</literal> it contains, and call upon our <literal>sendMail</literal> method to send the mail.  For this we can again turn to EJB, which provides listeners to any JCA (Java Connector Architecture) backend by means of the <emphasis>Message-Driven Bean</emphasis> (MDB).  Our MDB will be configured as a JMS <literal>Queue</literal> listener, and is defined:</simpara>
<simpara><literal>org.cedj.geekseek.service.smtp.SMTPMessageConsumer</literal></simpara>
<programlisting language="java" linenumbering="unnumbered">@MessageDriven(activationConfig = {
        @ActivationConfigProperty(propertyName = "acknowledgeMode",
          propertyValue = "Auto-acknowledge"),
        @ActivationConfigProperty(propertyName = "destinationType",
          propertyValue = "javax.jms.Queue"),
        @ActivationConfigProperty(propertyName = "destination",
          propertyValue = SMTPMailServiceConstants.JNDI_BIND_NAME_SMTP_QUEUE)})
public class SMTPMessageConsumer implements MessageListener {</programlisting>
<simpara>The <literal>ActivationConfigProperty</literal> annotations are in place to tell the EJB container how to connect to the backing JCA resource, in this case our queue.  Because MBDs are business components just like EJB Session Beans, we have injection at our disposal, which we&#8217;ll use to obtain a reference back to the <literal>SMTPMailService</literal></simpara>
<programlisting language="java" linenumbering="unnumbered">@EJB
private SMTPMailService mailService;</programlisting>
<simpara>Now, our <literal>SMTPMessageConsumer</literal> is registered by the EJB container as a listener upon our queue; when a new message arrives, we&#8217;ll receive a callback to the <literal>onMessage</literal> method.  By implementing this, we can unwrap the <literal>MailMessage</literal> and send it directly to the <literal>SMTPMailService</literal> to be sent.</simpara>
<programlisting language="java" linenumbering="unnumbered">@Override
public void onMessage(final javax.jms.Message message) {

    // Casting and unwrapping
    final ObjectMessage objectMessage;
    try {
        objectMessage = ObjectMessage.class.cast(message);
    } catch (final ClassCastException cce) {
        throw new RuntimeException(
          "Incorrect message type sent to object message consumer; got:"
          + message.getClass().getSimpleName(), cce);
    }
    final MailMessageBuilder.MailMessage mailMessage;
    try {
        final Object obj = objectMessage.getObject();
        mailMessage = MailMessageBuilder.MailMessage.class.cast(obj);
    } catch (final JMSException jmse) {
        throw new RuntimeException("Could not unwrap JMS Message", jmse);
    } catch (final ClassCastException cce) {
        throw new RuntimeException("Expected message contents of type "
                + MailMessageBuilder.MailMessage.class.getSimpleName(), cce);
    }

    // Send the mail
    mailService.sendMail(mailMessage);
}</programlisting>
<simpara>These compose all the working pieces of the business logic supporting this feature.  However, the true challenge lies in verifying that everything works as expected.</simpara>
</section>
<section id="_a_test_only_smtp_server">
<title>A Test-Only SMTP Server</title>
<simpara>The JavaMail API nicely abstracts out connections to an SMTP server, and we&#8217;ve built our <literal>SMTPMailService</literal> to pull <emphasis role="strong">any</emphasis> configured JavaMail <literal>Session</literal> from JNDI.  This gives us the option to provide a test-only SMTP server for use development and staging environments with only configuration changes differing between these and the production setup.  While it&#8217;s true that this text has generally discouraged the use of mock objects and services, that&#8217;s a guideline.  In this instance, we&#8217;ll absolutely need a hook that differs from production in order to validate that emails are being delivered as expected.  Otherwise, we&#8217;d be using a real SMTP service which could send emails out to real email addresses.</simpara>
<simpara>For our own testing, we&#8217;ll aim to change not the code in our <literal>SMTPMailService</literal>, but configure it to point to an embeddable SMTP server; one that will allow us to see what messages were received and do some assertion checking to be sure the contents are as expected.  For this we look to the <ulink url="https://code.google.com/p/subetha/">SubEtha</ulink> project, an open-source Java SMTP server which fulfills our requirements nicely.</simpara>
<simpara>We&#8217;ll let our SMTP Server run in the same process as our application server and tests; this will allow us to use shared memory and set guards to handle the asynchrony implicit in dispatching messages to an SMTP server.</simpara>
<simpara>A nice technique is to install SubEtha to come up alongside our application.  In Java EE, the mechanism for creating application start events is by implementing a <literal>PostConstruct</literal> callback on a Singleton Session EJB that&#8217;s configured to eagerly-load.  This is done by defining a new service:</simpara>
<simpara><literal>org.cedj.geekseek.service.smtp.SMTPServerService</literal></simpara>
<programlisting language="java" linenumbering="unnumbered">import javax.ejb.LocalBean;
import javax.ejb.Singleton;
import javax.ejb.Startup;
import javax.ejb.TransactionAttribute;

/**
 * Test fixture; installs an embedded SMTP Server on startup, shuts it down on undeployment.
 * Allows for pluggable handling of incoming messages for use in testing.
 */
@Singleton
@Startup
@LocalBean
@TransactionAttribute(TransactionAttributeType.SUPPORTS)
public class SMTPServerService {</programlisting>
<simpara>The <literal>@Startup</literal> annotation will trigger this EJB bean instance to be created alongside application start, which in turn will lead to the container invoking the <literal>PostConstruct</literal> method:</simpara>
<programlisting language="java" linenumbering="unnumbered">private SMTPServer server;
private final PluggableReceiveHandlerMessageListener listener =
  new PluggableReceiveHandlerMessageListener();

@javax.annotation.PostConstruct
public void startup() throws Exception {
  server = new SMTPServer(new SimpleMessageListenerAdapter(listener));
  server.setBindAddress(InetAddress.getLoopbackAddress());
  server.setPort(BIND_PORT);
  server.start();
}</programlisting>
<simpara>This gives us an opportunity to create a new <literal>SMTPServer</literal> instance, register a handler (which defines what will be done when a new message is received), and start it on our configured port on <literal>localhost</literal>.  The companion <literal>PreDestroy</literal> callback method provides for graceful shutdown of this server when the application is undeployed and the Singleton EJB instance brought out of service:</simpara>
<programlisting language="java" linenumbering="unnumbered">@javax.annotation.@PreDestroy
public void shutdown() throws Exception {
  server.stop();
}</programlisting>
<simpara>In our test <literal>SMTPServerService</literal>, we also define an inner <literal>TestHandler</literal> interface;  the simple type our tests may implement, containing one method, <literal>handle(String)</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">interface TestReceiveHandler {
    void handle(String data) throws AssertionFailedError;
}</programlisting>
<simpara>The <literal>TestReceiveHandler</literal> will serve as our extension point for tests to apply behavior fitting their requirements.  This is done via the <literal>setHandler(TestReceiveHandler</literal>) method on our test EJB:</simpara>
<programlisting language="java" linenumbering="unnumbered">public void setHandler(final TestReceiveHandler handler) {
    this.listener.setHandler(handler);
}</programlisting>
<simpara>Pluggable handling in our SMTP server may then be set up on-the-fly by tests.  When a new message is received by the SMTP server, our listener will read in the contents, log them for our convenience, then call upon our <literal>TestReceiveHandler</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">private class PluggableReceiveHandlerMessageListener implements SimpleMessageListener {

    private TestReceiveHandler handler;

    @Override
    public boolean accept(String from, String recipient) {
        return true;
    }

    @Override
    public void deliver(final String from,
      final String recipient, final InputStream data)
      throws TooMuchDataException, IOException {

        // Get contents as String
        byte[] buffer = new byte[4096];
        int read;
        final StringBuilder s = new StringBuilder();
        while ((read = data.read(buffer)) != -1) {
            s.append(new String(buffer, 0, read, CHARSET));
        }
        final String contents = s.toString();
        if (log.isLoggable(Level.INFO)) {
            log.info("Received SMTP event: " + contents);
        }

        // Pluggable handling
        if (handler == null) {
            log.warning("No SMTP receive handler has been associated");
        } else {
            handler.handle(contents);
        }
    }
    void setHandler(final TestReceiveHandler handler) {
        this.handler = handler;
    }
}</programlisting>
</section>
<section id="_the_test">
<title>The Test</title>
<simpara>Our test will again use Arquillian for the container interaction as we&#8217;ve seen before, but will require no extra extensions.  Therefore the declaration here is fairly simple:</simpara>
<simpara><literal>org.cedj.geekseek.service.smtp.SMTPMailServiceTestCase</literal></simpara>
<programlisting language="java" linenumbering="unnumbered">@RunWith(Arquillian.class)
public class SMTPMailServiceTestCase {</programlisting>
<simpara>Unlike in previous examples, this time we&#8217;ll handle deployment and undeployment operations manually.  This is because we&#8217;d first like to configure the server <emphasis>before</emphasis> deployment, but <emphasis>after</emphasis> it has started.  As Arquillian currently does not provide for a lifecycle operation between the server startup and deployment, we&#8217;ll make use of ordered test methods to clearly delineate which actions should be handled when.  What we&#8217;d like to see:</simpara>
<itemizedlist>
<listitem>
<simpara>
Server start (handled automatically by Arquillian)
</simpara>
</listitem>
<listitem>
<simpara>
Server configuration
</simpara>
</listitem>
<listitem>
<simpara>
Deployment
</simpara>
</listitem>
<listitem>
<simpara>
Test methods
</simpara>
</listitem>
<listitem>
<simpara>
Undeployment
</simpara>
</listitem>
<listitem>
<simpara>
Reset server configuration
</simpara>
</listitem>
<listitem>
<simpara>
Server shutdown
</simpara>
</listitem>
</itemizedlist>
<simpara>We do manual deployment in Arquillian by associating a name with the deployment, then creating a <literal>@Deployment</literal> method just like we&#8217;ve seen before.</simpara>
<simpara>Define deployment:</simpara>
<programlisting language="java" linenumbering="unnumbered">/**
 * Name of the deployment for manual operations
 */
private static final String DEPLOYMENT_NAME = "mailService";

/**
 * Deployment to be tested; will be manually deployed/undeployed
 * such that we can configure the server first
 *
 * @return
 */
@Deployment(managed = false, name = DEPLOYMENT_NAME)
public static WebArchive getApplicationDeployment() {
    final File[] subethamailandDeps = Maven.resolver().
      loadPomFromFile("pom.xml").resolve("org.subethamail:subethasmtp")
      .withTransitivity().asFile();
    final WebArchive war = ShrinkWrap.create(WebArchive.class)
      .addAsLibraries(subethamailandDeps)
      .addClasses(SMTPMailService.class, MailMessageBuilder.class,
        SMTPMailServiceConstants.class,
        SMTPMessageConsumer.class, SMTPServerService.class)
      .addAsWebInfResource(EmptyAsset.INSTANCE, "beans.xml")
      .addAsWebInfResource("META-INF/geekseek-smtp-queue-jms.xml");
    System.out.println(war.toString(true));
    return war;
}</programlisting>
<simpara>Of special note is the <literal>Deployment.managed</literal> attribute, which when set to <literal>false</literal> will tell Arquillian that we&#8217;ll handle the act of deployment on our own.  The above method constructs us a deployment with the following layout:</simpara>
<screen>/WEB-INF/
/WEB-INF/geekseek-smtp-queue-jms.xml
/WEB-INF/lib/
/WEB-INF/lib/subethasmtp-3.1.7.jar
/WEB-INF/lib/slf4j-api-1.6.1.jar
/WEB-INF/lib/activation-1.1.jar
/WEB-INF/lib/mail-1.4.4.jar
/WEB-INF/lib/jsr305-1.3.9.jar
/WEB-INF/beans.xml
/WEB-INF/classes/
/WEB-INF/classes/org/
/WEB-INF/classes/org/cedj/
/WEB-INF/classes/org/cedj/geekseek/
/WEB-INF/classes/org/cedj/geekseek/service/
/WEB-INF/classes/org/cedj/geekseek/service/smtp/
/WEB-INF/classes/org/cedj/geekseek/service/smtp/SMTPMessageConsumer.class
/WEB-INF/classes/org/cedj/geekseek/service/smtp/SMTPMailServiceConstants.class
/WEB-INF/classes/org/cedj/geekseek/service/smtp/SMTPMailService.class
/WEB-INF/classes/org/cedj/geekseek/service/smtp/SMTPServerService$1.class
/WEB-INF/classes/org/cedj/geekseek/service/smtp/MailMessageBuilder$MailMessage.class
/WEB-INF/classes/org/cedj/geekseek/service/smtp/SMTPServerService$TestReceiveHandler.class
/WEB-INF/classes/org/cedj/geekseek/service/smtp/SMTPServerService.class
/WEB-INF/classes/org/cedj/geekseek/service/smtp/SMTPServerService$PluggableReceiveHandlerMessageListener.class
/WEB-INF/classes/org/cedj/geekseek/service/smtp/MailMessageBuilder.class</screen>
<simpara>As you can see, the SubEtha project and its dependencies are dutifully added to the <literal>WEB-INF/lib</literal> folder as we&#8217;ve requested ShrinkWrap Resolver to fetch these as configured from the project POM.</simpara>
<simpara>With the deployment accounted for, we may inject both the <literal>SMTPMailService</literal> EJB and our test <literal>SMTPServerService</literal> EJB into the test:</simpara>
<programlisting language="java" linenumbering="unnumbered">/**
 * Service which sends email to a backing SMTP Server
 */
@Inject
private SMTPMailService mailService;

/**
 * Hook into the embeddable SMTP server so we can customize its handling from the tests
 */
@Inject
private SMTPServerService smtpServerService;</programlisting>
<simpara>We can also inject a hook to manually deploy and undeploy our deployment, such that we may configure the server before our <literal>@Deployment</literal> is sent to the server.  This is done with the <literal>@ArquillianResource</literal> annotation.</simpara>
<programlisting language="java" linenumbering="unnumbered">@ArquillianResource
private Deployer deployer;</programlisting>
<simpara>At this point, Arquillian is set to run and start the server, and the deployment is defined but not yet deployed.  Next on our agenda is to configure the server; we&#8217;ll ensure this is done in the proper order by creating a test method to run first by using Arquillian&#8217;s <literal>@InSequence</literal> annotation.  Also, we don&#8217;t want this test method running inside the container (as is the default), but rather on the client process, so we&#8217;ll flag this method with <literal>@RunAsClient</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">/*
 * Lifecycle events; implemented as tests, though in truth they perform no assertions.  Used to configure
 * the server and deploy/undeploy the @Deployment archive at the appropriate times
 */

@RunAsClient
@InSequence(value = 1)
@Test
public void configureAppServer() throws Exception {

    /*
     * First configure a JavaMail Session for the Server to bind into JNDI; this
     * will be used by our MailService EJB.  In a production environment, we'll likely have configured
     * the server before it was started to point to a real SMTP server
     */
    // Code ommitted for brevity, not really relevant to
    // our objectives here

    /*
     * With the config all set and dependencies in place, now we can deploy
     */
    deployer.deploy(DEPLOYMENT_NAME);

}</programlisting>
<simpara>Yes, the code above is technically implemented as a test method, and it&#8217;d be much cleaner to fully-separate out our tests from our harness.  Future versions of Arquillian may provide more fine-grained handling of lifecycle events to accommodate that kind of separation, but for the time-being, this is our mechanism to configure running servers before issuing a deployment.</simpara>
<simpara>Now with server configuration completed and our application deployed, we&#8217;re free to write our test logic.</simpara>
<simpara>The test is fairly simple from a conceptual standpoint, though the steps we&#8217;ve taken to achieve it have admittedly involved some more work.  We&#8217;d like to:</simpara>
<itemizedlist>
<listitem>
<simpara>
Construct a mail message
</simpara>
</listitem>
<listitem>
<simpara>
Set a handler on the test SMTP service to ensure the email is in the proper form, then signal to the test that we&#8217;re ready to proceed
</simpara>
</listitem>
<listitem>
<simpara>
Send the email asynchronously
</simpara>
</listitem>
<listitem>
<simpara>
Wait on the handler to let us know that the message was received and that we may now proceed
</simpara>
</listitem>
</itemizedlist>
<simpara>The test logic looks like this:</simpara>
<programlisting language="java" linenumbering="unnumbered">    @InSequence(value = 2)
    @Test
    public void testSmtpAsync() {

        // Set the body of the email to be sent
        final String body = "This is a test of the async SMTP Service";

        // Define a barrier for us to wait upon while email is sent through the JMS Queue
        final CyclicBarrier barrier = new CyclicBarrier(2);

        // Set a handler which will ensure the body was received properly
        smtpServerService.setHandler(new SMTPServerService.TestReceiveHandler() {
            @Override
            public void handle(final String contents) throws AssertionFailedError {
                try {

                    // Perform assertion
                    Assert.assertTrue("message received does not contain body sent in email", contents.contains(body));

                    // Should probably be the second and last to arrive, but this
                    // Thread can block indefinitely w/ no timeout needed.  If
                    // the test waiting on the barrier times out, it'll trigger a test
                    // failure and undeployment of the SMTP Service
                    barrier.await();
                } catch (final InterruptedException e) {
                    // Swallow, this would occur if undeployment were triggered
                    // because the test failed (and we'd get a proper
                    // AssertionFailureError on the client side)
                } catch (final BrokenBarrierException e) {
                    throw new RuntimeException("Broken test setup", e);
                }
            }
        });

        // Construct and send the message async
        final MailMessageBuilder.MailMessage message =
                new MailMessageBuilder().from("alr@continuousdev.org").addTo("alr@continuousdev.org")
                        .subject("Test").body(body).contentType("text/plain").build();
        mailService.queueMailForDelivery(message);

        // Wait on the barrier until the message is received by the SMTP
        // server (pass) or the test times out (failure)
        try {
            barrier.await(5, TimeUnit.SECONDS);
        } catch (final InterruptedException e) {
            throw new RuntimeException("Broken test setup", e);
        } catch (final BrokenBarrierException e) {
            throw new RuntimeException("Broken test setup", e);
        } catch (final TimeoutException e) {
            // If the SMTP server hasn't processed the message in the allotted time
            Assert.fail("Test did not receive confirmation message in the allotted time");
        }
    }</programlisting>
<simpara>Walking through this, we see that first we define the subject of the email to be sent.  Then we create a <literal>java.util.concurrent.CyclicBarrier</literal> initialized to a <literal>count</literal> of <literal>2</literal>; this will be the mutual waiting point between the test and the SMTP server to coordinate that both parties have completed their actions and that control should not continue until each caller (<literal>Thread</literal>) has arrived at this waiting point.</simpara>
<simpara>The handler will perform our assertions to validate the message contents, then wait at the barrier until the test is done with its processing.</simpara>
<simpara>Meanwhile, the test will send the email via the <literal>SMTPMailService</literal>, then wait for the handler to receive the mail message and carry through the logic we&#8217;d put in place above.</simpara>
<simpara>When both the test client and the handler arrive at the <literal>CyclicBarrer</literal> and no <literal>AssertionErrors</literal> or other issues have cropped up, we know that we&#8217;re free to proceed; the test method may continue its execution until invocation is complete and it reports a success.</simpara>
<simpara>Finally, we need to be sure to undeploy the archive (remember, we&#8217;d opted for manual deployment this time around) and reset the server&#8217;s configuration.  Again, we&#8217;ll run this code in the client/test process:</simpara>
<programlisting language="java" linenumbering="unnumbered">@RunAsClient
@InSequence(value = 3)
@Test
public void resetAppServerConfig()
        throws Exception
{
    deployer.undeploy(DEPLOYMENT_NAME);

    // Server config code ommitted for brevity,
    // not really relevant to our objectives here
 }</programlisting>
<simpara>This example serves to illustrate a common and often undertested aspect of enterprise development.  Though the techniques we&#8217;ve applied here deal with external, non-transactional resources, asynchronous calling, and server configurations, this should serve as proof that even difficult cases may be adequately-tested given a little thought and effort.  It&#8217;s our belief that this will pay off dividends in avoiding production runtime errors and peace-of-mind in being armed with one more weapon in the battle to maintain a comprehensive, automated testsuite.</simpara>
</section>
</section>
</section>
<section id="_rest_and_addressable_services">
<title>REST and Addressable Services</title>
<simpara><emphasis>"Rest and be thankful." - Inscription at Rest Stop Along Scotland&#8217;s Highway A83</emphasis></simpara>
<simpara>The concepts guiding the makeup of the modern web could be considered a happy accident, or at least an implementation of ideas that had general applicability far beyond their initial design criteria.  In the late 1980s we had the hardware and software necessary for networking; low-level tools for transmitting data from one computer to another.  We even had some payload protocols and application layers available including IRC for chat, POP for email, and USENET for general discussions.  We were communicating, albeit over relatively constrained channels.</simpara>
<simpara>Out of necessity for his own research, Tim Berners-Lee of the European Organization for Nuclear Research (CERN) concocted a small receipe for publishing documents in a manner that would make his findings more accessible between departments and encourage updates over time.  Called the "WorldWideWeb" (WWW), this project <ulink url="http://cdsweb.cern.ch/record/1405411/files/ARCH-WWW-4-010.pdf">proposed</ulink> a series of simple constructs:</simpara>
<itemizedlist>
<listitem>
<simpara>
Addressable resources: a unique key or address assigned to each document
</simpara>
</listitem>
<listitem>
<simpara>
Hypertext: A unidirectional pointer to an addressable resource
</simpara>
</listitem>
<listitem>
<simpara>
Browser: A client program capable of reading hypertext-enabled documents
</simpara>
</listitem>
</itemizedlist>
<simpara>We take these concepts lightly now, but it&#8217;s worthwhile considering the paradigm shift this evoked in the early 1990s; in only ten years' time, most of the world&#8217;s university students and many homes were connected to a web that contained a marketing presense for an overwhelming majority of the Fortune 500.  These ideas ushered innovation and communication at a rate never before seen in the history of mankind.  This was instant, global publishing, and it was free.</simpara>
<simpara>Central to the makeup of the WWW was the introduction of the <emphasis>Uniform Resource Identifier</emphasis>, or URI.  The URI defined by <ulink url="http://tools.ietf.org/html/rfc3986">RFC 3986</ulink> forms the basis of an addressable resource, and has the following makeup:</simpara>
<simpara><literal>scheme ":" hierarchical-part ["?" query] ["#" fragment]</literal></simpara>
<simpara>Examples from the RFC include:</simpara>
<simpara><literal>foo://example.com:8042/over/there?name=ferret#nose</literal></simpara>
<simpara>and</simpara>
<simpara><literal>urn:example:animal:ferret:nose</literal></simpara>
<simpara>In short time, Berners-Lee introduced the first version of the <emphasis>HyperText Markup Language</emphasis> (HTML), aimed at providing a more concise vernacular for incorporating links into a common markup that browsers could format for viewing.  The WWW was built as a mechanism for <emphasis>document exchange</emphasis>, sharing of published material over a commonly-understood protocol and payload format (commonly HTML).</simpara>
<simpara>In 2000, University of California at Irvine&#8217;s Roy Fielding published his dissertation <ulink url="http://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm">"Architectural Styles and the Design of Network-based Software Architectures"</ulink>, which expanded the notion of addressing documents to include <emphasis>services</emphasis> among the data exchanged on the web, and defined a system of <emphasis>REpresentational State Transfer</emphasis> (REST).  With his background in co-authoring <ulink url="http://tools.ietf.org/html/rfc2616">RFC-2616</ulink> which defined the HTTP/1.1 protocol, Fielding was in a position of expertise to rethink how the principles of the web might be applied to services.</simpara>
<simpara>By addressing services and applying a set of conventions to these URIs, we&#8217;re able to compose a wide array of operations upon services with the following key benefits:</simpara>
<itemizedlist>
<listitem>
<simpara>
Loose coupling
</simpara>
</listitem>
<listitem>
<simpara>
Interoperability
</simpara>
</listitem>
<listitem>
<simpara>
Encapsulation
</simpara>
</listitem>
<listitem>
<simpara>
Distributed programming
</simpara>
</listitem>
<listitem>
<simpara>
Modularization
</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>Clearly the study of REST is worthy of its own text, and we&#8217;ll recommend <ulink url="http://restinpractice.com/book/"><emphasis>REST in Practice</emphasis></ulink> by Webber/Parastatidis/Robinson from O&#8217;Reilly Media to those looking to explore in greater depth.</simpara>
</note>
<simpara>REST is certainly not the first distributed architecture; <emphasis>Remote Procedure Call</emphasis> (RPC) varients have been used in various forms (ie. SOAP, XML-RPC) for a long while.  In recent years, the trend towards REST has been largely attributed to its ease-of-use and slim profile when coupled with the <emphasis>HyperText Transfer Protocol</emphasis> (HTTP), an established communication protocol providing for <emphasis>methods</emphasis> , <emphasis>headers</emphasis>, and <emphasis>return status codes</emphasis> that map well to the objectives of the caller.  In practice, the success of the WWW is inherently linked to HTTP, though this is only one protocol (scheme) that may be applied to the general guidelines of the web.  Due to its widespread usage and versatility, we&#8217;ll be employing HTTP throughout this chapter.</simpara>
<simpara>Because of its success, REST has become an abused buzzword in some circles.  It&#8217;s helpful for us to clarify the stages of compliance with a truly RESTful system, and a maturity model developed by <ulink url="http://www.crummy.com/self/">Leonard Richardson</ulink> presents four rungs of evolution.  Martin Fowler ably sums these up in his <ulink url="http://martinfowler.com/articles/richardsonMaturityModel.html">blog post</ulink>, and we&#8217;ll outline them here.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Stage 0</simpara></entry>
<entry align="left" valign="top"><simpara>Using HTTP as a transport system for arbitrary payloads; typically used in plain RPC where a caller may wish to invoke upon a server over a network.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Stage 1</simpara></entry>
<entry align="left" valign="top"><simpara>Addressable Resources; each domain object may be assigned to an address, and client requests contain all the necessary metadata needed to carry out the invocation.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Stage 2</simpara></entry>
<entry align="left" valign="top"><simpara>HTTP Verbs; in addition to assigning each domain object or service an address, we use the conventions of the HTTP methods to differentiate between a "Create", "Update," "Delete", or other actions.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Stage 3</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis>HATEOAS</emphasis>, or "Hypermedia As The Engine Of Application State", whereas requests upon a root may return a list of links to the client in order to proceed to the next available actions.  For instance, after "creating a user", the client may be given a success confirmation and shown links to "view the user", "edit the user", "view all users".  Additionally, projects with Stage 3 maturity will utilize media types (content types) to as part of content negotiation; an XML-based request should likely yield an XML-based response while a JSON request might imply a JSON response.  With media types set in the request, these can all take place using the same URI.  Stage 3 is about <emphasis>workflow</emphasis> and <emphasis>transition</emphasis>; it guides the client through the stages of the application.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>A RESTful system is always Stage 3, though this is an often-misunderstood and neglected understanding of the REST architecture, particularly for newcomers.  In layman&#8217;s terms, a Stage 3 exchange may sound a little like this:</simpara>
<itemizedlist>
<listitem>
<simpara>
<emphasis>Server</emphasis>: You&#8217;ve just created an order.  Do you want to pay?  Do you want to add more items?  Do you want to save your cart for later?  Here are the links for each of these actions.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis>Client</emphasis>: I&#8217;m following the link to save my cart, here is the request.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis>Server</emphasis>: Your cart is saved.  Do you want to continue shopping?  Do you want to view your cart?  Here are the links for these actions.
</simpara>
</listitem>
</itemizedlist>
<simpara>It&#8217;s important to consider that REST is an <emphasis>architectural style</emphasis>, agnostic of any particular programming model or language.  At its core, REST is most simply explained as an API for accessing services and domain objects over the web.</simpara>
<simpara>As the Java community has come to understand the REST principles, it has provided a mapping layer between requests and backend services: <emphasis>JAX-RS</emphasis>.</simpara>
<section id="_rest_in_enterprise_java_the_jax_rs_specification">
<title>REST in Enterprise Java: The JAX-RS Specification</title>
<simpara>The <emphasis>Java API for RESTful Web Services</emphasis>, or JAX-RS, is a specification under the direction of the Java Community Process, defined by <ulink url="http://jcp.org/aboutJava/communityprocess/final/jsr339/index.html">JSR-339</ulink> in its latest 2.0 version.  Java EE6 incorprates the 1.1 revision, as defined by <ulink url="http://jcp.org/en/jsr/detail?id=311">JSR-311</ulink>; this is the version we&#8217;ll be covering here.  From the specification document, its goals are to be/have:</simpara>
<blockquote>
<itemizedlist>
<listitem>
<simpara>
<emphasis role="strong">POJO-based</emphasis>: The API will provide a set of annotations and associated classes/interfaces that may be used
with POJOs in order to expose them as Web resources. The specification will define object lifecycle
and scope.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">HTTP-centric</emphasis>: The specification will assume HTTP is the underlying network protocol and will pro-
vide a clear mapping between HTTP and URI elements and the corresponding API classes and
annotations. The API will provide high level support for common HTTP usage patterns and will be
sufficiently flexible to support a variety of HTTP applications including WebDAV and the Atom
Publishing Protocol.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Format independence</emphasis>: The API will be applicable to a wide variety of HTTP entity body content types. It
will provide the necessary pluggability to allow additional types to be added by an application in a
standard manner.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Container independence</emphasis>: Artifacts using the API will be deployable in a variety of Web-tier containers.
The specification will define how artifacts are deployed in a Servlet container and as a JAX-WS Provider.
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Inclusion in Java EE</emphasis>: The specification will define the environment for a Web resource class hosted in a
Java EE container and will specify how to use Java EE features and components within a Web resource
class.
</simpara>
</listitem>
</itemizedlist>
</blockquote>
<note>
<simpara>As it&#8217;s not our aim to provide a comprehensive overview of JAX-RS, we recommend <ulink url="http://shop.oreilly.com/product/9780596158057.do"><emphasis>RESTful Java with JAX-RS</emphasis></ulink> by Bill Burke, member of the JSR-339 Expert Group and lead of the JBoss Community&#8217;s <ulink url="http://www.jboss.org/resteasy">RESTEasy</ulink> implementation, from O&#8217;Reilly Media.  The second revision of the book, covering the latest 2.0 version of the specification, is now <ulink url="http://shop.oreilly.com/product/0636920028925.do">on sale</ulink> for pre-order.</simpara>
</note>
<simpara><ulink url="http://jsr311.java.net/nonav/javadoc/">JAX-RS Specification API</ulink> provides a set of annotations helpful to developers seeking to map incoming HTTP-based requests to backend services.  From the docs, these include:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>ApplicationPath</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Identifies the application path that serves as the base URI for all resource URIs provided by Path.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>Consumes</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defines the media types that the methods of a resource class or MessageBodyReader can accept.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>CookieParam</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Binds the value of a HTTP cookie to a resource method parameter, resource class field, or resource class bean property.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>DefaultValue</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defines the default value of request meta-data that is bound using one of the following annotations: PathParam, QueryParam, MatrixParam, CookieParam, FormParam, or HeaderParam.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>DELETE</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates that the annotated method responds to HTTP DELETE requests.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>Encoded</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Disables automatic decoding of parameter values bound using QueryParam, PathParam, FormParam or MatrixParam.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>FormParam</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Binds the value(s) of a form parameter contained within a request entity body to a resource method parameter.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>GET</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates that the annotated method responds to HTTP GET requests.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>HEAD</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates that the annotated method responds to HTTP HEAD requests.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>HeaderParam</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Binds the value(s) of a HTTP header to a resource method parameter, resource class field, or resource class bean property.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>HttpMethod</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Associates the name of a HTTP method with an annotation.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>MatrixParam</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Binds the value(s) of a URI matrix parameter to a resource method parameter, resource class field, or resource class bean property.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>OPTIONS</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates that the annotated method responds to HTTP OPTIONS requests.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>Path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Identifies the URI path that a resource class or class method will serve requests for.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>PathParam</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Binds the value of a URI template parameter or a path segment containing the template parameter to a resource method parameter, resource class field, or resource class bean property.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>POST</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates that the annotated method responds to HTTP POST requests.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>Produces</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defines the media type(s) that the methods of a resource class or MessageBodyWriter can produce.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>PUT</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates that the annotated method responds to HTTP PUT requests.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>QueryParam</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Binds the value(s) of a HTTP query parameter to a resource method parameter, resource class field, or resource class bean property.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>These may be composed together to define the mapping between a business object&#8217;s methods and the requests it will service, as shown in the API documentation:</simpara>
<programlisting language="java" linenumbering="unnumbered">@Path("widgets/{widgetid}")
@Consumes("application/widgets+xml")
@Produces("application/widgets+xml")
public class WidgetResource {

    @GET
    public String getWidget(@PathParam("widgetid") String id) {
        return getWidgetAsXml(id);
    }

    @PUT
    public void updateWidget(@PathParam("widgetid") String id,Source update) {
        updateWidgetFromXml(id, update);
    }
    ...
 }</programlisting>
<simpara>The above defines an example of a business object which will receive requests to <literal>$applicationRoot/widgets/$widgetid</literal>, where <literal>$widgetid</literal> is the identifier of the domain object to be acted upon.  HTTP <literal>GET</literal> requests will be serviced by the <literal>getWidget</literal> method, which will receive the <literal>$widgetid</literal> as a method parameter; HTTP <literal>PUT</literal> requests will be handled by the <literal>updateWidget</literal> method.  The class-level <literal>@Consumes</literal> and <literal>@Produces</literal> annotations designate that all business methods of the class will expect and return a media type (content type) of "<literal>application/widgets+xml</literal>".</simpara>
<simpara>As the specification supplies only a contract by which JAX-RS implementations must behave, the runtime will vary between application server vendors.  For instance the Reference Implementation, <ulink url="http://jersey.java.net/">Jersey</ulink>, can be found in the <ulink url="http://glassfish.java.net/">GlassFish Application Server</ulink>, while <ulink url="http://www.wildfly.org/">WildFly</ulink> from the JBoss Community uses <ulink url="http://www.jboss.org/resteasy">RESTEasy</ulink>.</simpara>
</section>
<section id="_use_case_provide_access_to_interact_with_domain_state">
<title>Use Case: Provide Access to Interact with Domain State</title>
<simpara>Thus far, we&#8217;ve visited and described the internal mechanisms with which we interact with data.  Now we&#8217;re able to work on building an API for clients to access the domain state in a self-describing fashion, and RESTful design coupled with JAX-RS affords us the tools to expose our application&#8217;s capabilities in a commonly-understood way.</simpara>
<simpara>We&#8217;d like to encourage 3rd-party integrators - clients about whom we may not have any up-front knowledge - to view, update, and create domain objects within the GeekSeek application.  Therefore, our use case requirements will be simply summed up as:</simpara>
<blockquote>
<itemizedlist>
<listitem>
<simpara>
As a 3rd-party integrator, I should be able to perform CRUD operations upon:
</simpara>
<itemizedlist>
<listitem>
<simpara>
A Conference
</simpara>
</listitem>
<listitem>
<simpara>
Sessions within Conferences
</simpara>
</listitem>
<listitem>
<simpara>
Attachments within Sessions
</simpara>
</listitem>
<listitem>
<simpara>
Attachments within Conferences
</simpara>
</listitem>
<listitem>
<simpara>
A Venue (and associate with a Conference and/or Session)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</blockquote>
<simpara>Additionally, we want to lay out a map of the application as the client navigates through state changes.  For instance, at the root, a client should know what operations it&#8217;s capable of performing.  Once that operation is complete, a series of possible next steps should be made available to the client such that it may continue execution.  This guide is known as the <emphasis>Domain Application Protocol</emphasis> (DAP), and it acts as a slimming agent atop the wide array of possible HTTP operations in order to show the valid business processes that are available to a client as it progresses through the application&#8217;s various state changes.  It&#8217;s this DAP layer which grants us the final HATEOAS step of the Richardson Maturity Model.  Our DAP will define a series of addressable resources coupled with valid HTTP methods and media types to determine what actions are taken, and what links are to come next in the business process.</simpara>
<blockquote>
<itemizedlist>
<listitem>
<simpara>
<literal>/ application/vnd.ced+xml;type=root</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; Links
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/conference application/vnd.ced+xml;type=conference</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/venue application/vnd.ced+xml;type=venue</literal>
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/conference application/vnd.ced+xml;type=conference</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; List
</simpara>
</listitem>
<listitem>
<simpara>
<literal>POST</literal> &#8594; Add
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/conference/[c_id] application/vnd.ced+xml;type=conference</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; Single
</simpara>
</listitem>
<listitem>
<simpara>
<literal>PUT</literal> &#8594; Update
</simpara>
</listitem>
<listitem>
<simpara>
<literal>DELETE</literal> &#8594; Remove
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/conference/[c_id]/session application/vnd.ced+xml;type=session</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/venue/[v_id] application/vnd.ced+xml;type=venue</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/attachment/[a_id] application/vnd.ced+xml;type=attachment</literal>
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/conference/[c_id]/session application/vnd.ced+xml;type=session</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; List
</simpara>
</listitem>
<listitem>
<simpara>
<literal>POST</literal> &#8594; Add
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/conference/[c_id]/session/[s_id] application/vnd.ced+xml;type=session</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; Single
</simpara>
</listitem>
<listitem>
<simpara>
<literal>PUT</literal> &#8594; Update
</simpara>
</listitem>
<listitem>
<simpara>
<literal>DELETE</literal> &#8594; Remove
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/venue/[v_id]/room/[r_id] application/vnd.ced+xml;type=room</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/attachment/[a_id] application/vnd.ced+xml;type=attachment</literal>
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/venue application/vnd.ced+xml;type=venue</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; List
</simpara>
</listitem>
<listitem>
<simpara>
<literal>POST</literal> &#8594; Add
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/venue/[v_id] application/vnd.ced+xml;type=venue</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; Single
</simpara>
</listitem>
<listitem>
<simpara>
<literal>PUT</literal> &#8594; Update
</simpara>
</listitem>
<listitem>
<simpara>
<literal>DELETE</literal> &#8594; Remove
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/venue/[v_id]/room application/vnd.ced+xml;type=room</literal>
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/venue/[v_id]/room application/vnd.ced+xml;type=room</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; List
</simpara>
</listitem>
<listitem>
<simpara>
<literal>POST</literal> &#8594; Add
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/attachment/[a_id] application/vnd.ced+xml;type=attachment</literal>
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/venue/[v_id]/room/[r_id] application/vnd.ced+xml;type=room</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; Single
</simpara>
</listitem>
<listitem>
<simpara>
<literal>PUT</literal> &#8594; Update
</simpara>
</listitem>
<listitem>
<simpara>
<literal>DELETE</literal> &#8594; Remove
</simpara>
</listitem>
<listitem>
<simpara>
Link &#8594; <literal>/attachment/[a_id] application/vnd.ced+xml;type=attachment</literal>
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/attachment application/vnd.ced+xml;type=attachment</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; List
</simpara>
</listitem>
<listitem>
<simpara>
<literal>POST</literal> &#8594; Add
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<literal>/attachment/[a_id] application/vnd.ced+xml;type=attachment</literal>
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> &#8594; List
</simpara>
</listitem>
<listitem>
<simpara>
<literal>POST</literal> &#8594; Add
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</blockquote>
<simpara>The DAP above can be conceptually understood as a site map for services, and it defines the API for users of the system.  By designing to the DAP, we provide clients with a robust mechanism by which the details of attaining each resource or invoking the application&#8217;s services can be read as the client navigates from state to state.</simpara>
</section>
<section id="_the_implementation">
<title>The Implementation</title>
<simpara>With our requirements defined, we&#8217;re free to start implementation.  Remember that our primary goal here is to create HTTP endpoints at the locations defined by our DAP, and we want to ensure that they perform the appropriate action and return the contracted response.  By using JAX-RS we&#8217;ll be making business objects and defining the mapping between the path, query parameters, and media types of the request before taking action and supplying the correct response.</simpara>
<simpara>The first step is to let the container know that we have a JAX-RS component in our application; this is done by defining a <literal>javax.ws.rs.ApplicationPath</literal> annotation atop a subclass of <literal>javax.ws.rs.core.Application</literal>.  Here we provide this in <literal>org.geekseek.rest.GeekSeekApplication</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">import javax.ws.rs.ApplicationPath;
import javax.ws.rs.core.Application;

@ApplicationPath("api")
public class GeekSeekApplication extends Application {

}</programlisting>
<simpara>This will be picked up by the container and signal that requests to paths under the <literal>$applicationRoot/api</literal> pattern will be serviced by JAX-RS.</simpara>
<section id="_repository_resources">
<title>Repository Resources</title>
<simpara>Looking over our requirements, we see that all paths in our DAP are capable of performing CRUD operations.  Therefore, it makes sense for us to define a base upon which individual resources can build, while giving persistence capabilities to create, read, update, and delete.  In GeekSeek, we&#8217;ll handle this by making a generic <literal>RepositoryResource</literal> base to give us a hook into the <literal>Repository</literal> abstractions detailed in Chapter 5.  Let&#8217;s walk through <literal>org.cedj.geekseek.web.rest.core.RepositoryResource</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">public abstract class RepositoryResource&lt;
  DOMAIN extends Identifiable&amp;Timestampable,
  REP extends Representation&lt;DOMAIN&gt;&gt;
    implements Resource {</programlisting>
<simpara>Simple enough; an abstract class notes we&#8217;ll be extending this later for more specific resources that interact with a <literal>Respository</literal>.  Let&#8217;s define the base media types our application will be using.  Remember; media types are a key part of the maturity model in handling the types of responses to be returned given the input from the request.  For example, a JSON request should yield a JSON response in our known format.</simpara>
<programlisting language="java" linenumbering="unnumbered">protected static final String BASE_XML_MEDIA_TYPE = "application/vnd.ced+xml";
protected static final String BASE_JSON_MEDIA_TYPE = "application/vnd.ced+json";</programlisting>
<simpara>Next up, some fields which will be set later by subclasses; this composes our abstraction point which will need specialization later.</simpara>
<programlisting language="java" linenumbering="unnumbered">private Class&lt;? extends Resource&gt; resourceClass;
private Class&lt;DOMAIN&gt; domainClass;
private Class&lt;REP&gt; representationClass;</programlisting>
<simpara>We&#8217;ll also use some instance members to be injected by either the CDI (<literal>@Inject</literal>) or JAX-RS (<literal>@Context</literal>) containers:</simpara>
<programlisting language="java" linenumbering="unnumbered">@Context
private UriInfo uriInfo;

@Context
private HttpHeaders headers;

@Inject
private Repository&lt;DOMAIN&gt; repository;

@Inject
private RepresentationConverter&lt;REP, DOMAIN&gt; converter;</programlisting>
<simpara>The <literal>@Context</literal> annotation will help us gain access into the context of the request in-flight; information about the URI or HTTP headers.  The <literal>Repository</literal> is how we&#8217;ll access the persistence layer, and the <literal>RepresentationConverter</literal> will be responsible for mapping between the client payload and our own entity object model.</simpara>
<simpara>Now let&#8217;s make sure that subclasses set our extension fields properly:</simpara>
<programlisting language="java" linenumbering="unnumbered">public RepositoryResource(Class&lt;? extends Resource&gt; resourceClass,
  Class&lt;DOMAIN&gt; domainClass,
  Class&lt;REP&gt; representationClass) {
        this.resourceClass = resourceClass;
        this.domainClass = domainClass;
        this.representationClass = representationClass;
    }</programlisting>
<simpara>That should do it for the fields needed by our <literal>RepositoryResource</literal>.  Time to do something interesting; we want to map HTTP <literal>POST</literal> requests of our JSON and XML media types defined above to create a new entity.  With a couple of annotations and a few lines of logic in a business method, JAX-RS can handle that for us:</simpara>
<programlisting language="java" linenumbering="unnumbered">@POST
@Consumes({ BASE_JSON_MEDIA_TYPE, BASE_XML_MEDIA_TYPE })
public Response create(REP representation) {
    DOMAIN entity = getConverter().to(
      uriInfo,representation);
    getRepository().store(entity);
    return Response.created(
            UriBuilder.fromResource(getResourceClass()).segment("{id}").build(entity.getId())).build();
}</programlisting>
<simpara>The <literal>@POST</literal> annotation defines that this method will service HTTP <literal>POST</literal> requests, and the <literal>@Consumes</literal> annotation designates the valid media types.  The JAX-RS container will then map requests meeting those criteria to this <literal>create</literal> method, passing along the <literal>Representation</literal> of our <literal>Domain</literal> object.  From there we may get a hook to the <literal>Repository</literal>, store the entity, and issue an HTTP <literal>Response</literal> to the client.  Of importance is that we let the client know the ID of the entity which was created as part of the response; in this case, the ID is the URI to the newly-created resource which may take form similar to <literal>Response: 201 Location: resource-uri</literal>.</simpara>
<simpara>We&#8217;ll handle the other CRUD operations in similar fashion:</simpara>
<programlisting language="java" linenumbering="unnumbered">@DELETE
@Path("/{id}")
public Response delete(@PathParam("id") String id) {
    DOMAIN entity = getRepository().get(id);
    if (entity == null) {
        return Response.status(Status.NOT_FOUND).build();
    }
    getRepository().remove(entity);
    return Response.noContent().build();
}

@GET
@Path("/{id}")
@Produces({ BASE_JSON_MEDIA_TYPE, BASE_XML_MEDIA_TYPE })
public Response get(@PathParam("id") String id) {
    DOMAIN entity = getRepository().get(id);
    if (entity == null) {
        return Response.status(Status.NOT_FOUND).type(
            getMediaType()).build();
    }

    return Response.ok(
      getConverter().from(uriInfo, entity))
          .type(getMediaType())
          .lastModified(entity.getLastModified())
          .build();
}

@PUT
@Path("/{id}")
@Consumes({ BASE_JSON_MEDIA_TYPE, BASE_XML_MEDIA_TYPE })
public Response update(@PathParam("id") String id,
    REP representation) {
    DOMAIN entity = getRepository().get(id);
    if (entity == null) {
        return Response.status(Status.BAD_REQUEST)
          .build();
    }

    getConverter().update(
        uriInfo, representation, entity);
    getRepository().store(entity);

    return Response.noContent().build();
}</programlisting>
<simpara>Note that for <literal>GET</literal>, <literal>PUT</literal>, and <literal>DELETE</literal> operations we must know which entity to work with, so we use the <literal>@Path</literal> annotation to define a path parameter as part of the request, and pass this along as a <literal>PathParam</literal> to the method when it&#8217;s invoked.  We also are sure to use the correct HTTP response codes when the situation warrants:</simpara>
<itemizedlist>
<listitem>
<simpara>
NotFound(404)
</simpara>
</listitem>
<listitem>
<simpara>
Created(201) with Hedader: Location On
</simpara>
</listitem>
<listitem>
<simpara>
NoContent(204) On DELETE or successful update
</simpara>
</listitem>
<listitem>
<simpara>
BadRequest(400) On attemped PUT of a missing resource
</simpara>
</listitem>
</itemizedlist>
<simpara>With this base class in place, we have effectively made a nice mapping between the DAP API as part of our requirements and the backend <literal>Repository</literal> and JPA.  Incoming client requests to are mapped to business methods, which in turn delegate the appropriate action to the persistence layer and supply a response.</simpara>
<simpara>Let&#8217;s have a look at a concrete implementation of the <literal>RepositoryResource</literal>, one that handles interaction with <literal>User</literal> domain objects.  We&#8217;ve aptly named this the <literal>org.cedj.geekseek.web.rest.user.UserResource</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">@ResourceModel
@Path("/user")
public class UserResource
    extends RepositoryResource&lt;User, UserRepresentation&gt; {

    private static final String USER_XML_MEDIA_TYPE =
        BASE_XML_MEDIA_TYPE + "; type=user";
    private static final String USER_JSON_MEDIA_TYPE =
        BASE_JSON_MEDIA_TYPE + "; type=user";

    public UserResource() {
        super(UserResource.class, User.class, UserRepresentation.class);
    }

    @Override
    public String getResourceMediaType() {
        return USER_XML_MEDIA_TYPE;
    }

    @Override
    protected String[] getMediaTypes() {
        return new String[]{USER_XML_MEDIA_TYPE, USER_JSON_MEDIA_TYPE};
    }
}</programlisting>
<simpara>Because we inherit all of the support to interact with JPA from the parent <literal>RepositoryResource</literal>, this class needs to do little more than:</simpara>
<itemizedlist>
<listitem>
<simpara>
Note that we are an <literal>@ResourceModel</literal>, a custom type which is a CDI Stereotype to add interceptors.  We explain this in greater depth below.
</simpara>
</listitem>
<listitem>
<simpara>
Define a path for the resource, in this case, "/user" under the JAX-RS application root.
</simpara>
</listitem>
<listitem>
<simpara>
Supply the custom media types for user representations.
</simpara>
</listitem>
<listitem>
<simpara>
Set the resource type, the domain object type, and the representation type in the constructor.
</simpara>
</listitem>
</itemizedlist>
<simpara>Now we can handle CRUD operations for <literal>User</literal> domain objects; similar implementations to this are also in place for <literal>Conference</literal>, <literal>Session</literal>, etc.</simpara>
</section>
<section id="_the_representation_converter">
<title>The Representation Converter</title>
<simpara>We&#8217;ve seen that the underlying domain model implemented in JPA is not the same as the REST model we&#8217;re exposing to clients. While EE allows us to annotate JPA models with JAX-B bindings etc, we likely would like to keep the two models separate as the REST model may:</simpara>
<itemizedlist>
<listitem>
<simpara>
Contain less data
</simpara>
</listitem>
<listitem>
<simpara>
Combine JPA models into one unified view
</simpara>
</listitem>
<listitem>
<simpara>
Link resources
</simpara>
</listitem>
<listitem>
<simpara>
Render itself in multiple different representations and formats
</simpara>
</listitem>
</itemizedlist>
<simpara>Additionally, some resources act as proxy resources and has no representation on their own.  To allow these resources to operate in a modular fashion we need a way to describe conversion, for example: the relation resource links users to a conference (attendees, speakers). The relation it self knows nothing about the source or target types, but it knows how to get a converter that supports converting between these types.  To handle this, we supply the <literal>org.cedj.geekseek.web.rest.core.RepresentationConverter</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">public interface RepresentationConverter&lt;REST, SOURCE&gt; {

    Class&lt;REST&gt; getRepresentationClass();

    Class&lt;SOURCE&gt; getSourceClass();

    REST from(UriInfo uriInfo, SOURCE source);

    Collection&lt;REST&gt; from(UriInfo uriInfo, Collection&lt;SOURCE&gt; sources);

    SOURCE to(UriInfo uriInfo, REST representation);

    SOURCE update(UriInfo uriInfo, REST representation, SOURCE target);

    Collection&lt;SOURCE&gt; to(UriInfo uriInfo, Collection&lt;REST&gt; representations);</programlisting>
<simpara>Inside the above interface is also a base implementation to handle the conversion, <literal>RepresentationConverter.Base</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">public abstract static class Base&lt;REST, SOURCE&gt;
    implements RepresentationConverter&lt;REST, SOURCE&gt; {

    private Class&lt;REST&gt; representationClass;
    private Class&lt;SOURCE&gt; sourceClass;

    protected Base() {}

    public Base(Class&lt;REST&gt; representationClass,
        Class&lt;SOURCE&gt; sourceClass) {
        this.representationClass = representationClass;
        this.sourceClass = sourceClass;
    }

    @Override
    public Collection&lt;REST&gt; from(UriInfo uriInfo,
        Collection&lt;SOURCE&gt; ins) {
        Collection&lt;REST&gt; out = new ArrayList&lt;REST&gt;();
        for(SOURCE in : ins) {
            out.add(from(uriInfo, in));
        }
        return out;
    }

    @Override
    public Collection&lt;SOURCE&gt; to(UriInfo uriInfo,
        Collection&lt;REST&gt; ins) {
        Collection&lt;SOURCE&gt; out = new ArrayList&lt;SOURCE&gt;();
        for(REST in : ins) {
             out.add(to(uriInfo, in));
        }
            return out;
    }

    ...
}</programlisting>
<simpara>CDI will dutifully inject the appropriate instance of this converter where required, for instance in this field of the <literal>org.cedj.geekseek.web.rest.conference.ConferenceResource</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">@Inject
private RepresentationConverter&lt;SessionRepresentation,
    Session&gt; sessionConverter;</programlisting>
<simpara>Through these converters we may easily delegate the messy business of parsing the media type payload formats to and from our own interal domain objects.</simpara>
</section>
<section id="_the_literal_resourcemodel_literal">
<title>The <literal>@ResourceModel</literal></title>
<simpara>As JAX-RS 1.x does not define an interceptor model, we need to apply these on our own in order to activate cross-cutting concerns such as security, validation, and resource linking to our JAX-RS endpoints.  This is easily enough accomplished by using the stereotype feature of CDI, where we may create our own annotation type (which itself has annotations); wherever our custom type is applied, the metadata we specify upon the stereotype will propagate.  So we may create an annotation to apply all of the features we&#8217;d like upon a <literal>RepositoryResource</literal>, and we call it <literal>org.cedj.geekseek.web.rest.core.annotation.ResourceModel</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">@Secured
@Linked
@Validated
@RequestScoped
@Stereotype
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.TYPE)
public @interface ResourceModel {

}</programlisting>
<simpara>By placing this <literal>@ResourceModel</literal> annotation atop, for instance, <literal>UserResource</literal> as we&#8217;ve done above, this JAX-RS resource will now be <literal>@Secured</literal>, <literal>@Linked</literal>, <literal>@Validated</literal>, and <literal>@RequestScoped</literal>.  This is a nice shortcut provided by CDI to compose behaviours together in one definition.</simpara>
</section>
<section id="_literal_linkablerepresentation_literal">
<title><literal>LinkableRepresentation</literal></title>
<simpara>As you may have noticed from our DAP, we have a series of paths which accept a source media type and return another media type representing the data in question.  These are modeled by our <literal>org.cedj.geekseek.web.rest.core.Representation</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">public interface Representation&lt;X&gt; {

    Class&lt;X&gt; getSourceType();

    String getRepresentationType();
}</programlisting>
<simpara>Some paths are linkable; they contain pointers to resources that aren&#8217;t in the domain model itself.  For example, a <literal>Session</literal> in a <literal>Conference</literal> is in the <literal>Conference</literal> domain, because a <literal>Conference</literal> contains N <literal>Session</literal> entities.  A <literal>Conference</literal> may have a tracker (<literal>User</literal>), someone "following" the <literal>Conference</literal> for updates; this further links into the <literal>User</literal> domain via a <literal>Relation</literal> domain.  While each domain entity is separate, once we start to draw relationships between them, it&#8217;s helpful to consider a mechanism to link together these bonds.</simpara>
<simpara>So while domain model links are handled directly by JPA, the <literal>Representation</literal> and a <literal>RepresentationConverter</literal> into the target formats, the relationships need to be addressed slightly differently.</simpara>
<simpara>For this we may introduce the notion of a <literal>org.cedj.geekseek.web.rest.core.LinkableRepresentation</literal>; a <literal>Representation</literal> type capable of coupling a source type with a series of links:</simpara>
<programlisting language="java" linenumbering="unnumbered">public abstract class LinkableRepresenatation&lt;X&gt; implements Representation&lt;X&gt; {

    private List&lt;ResourceLink&gt; links;
    private Class&lt;X&gt; sourceType;
    private String representationType;
    private UriInfo uriInfo;

    protected LinkableRepresenatation() {}

    public LinkableRepresenatation(Class&lt;X&gt; sourceType, String representationType, UriInfo uriInfo) {
        this.sourceType = sourceType;
        this.representationType = representationType;
        this.uriInfo = uriInfo;
    }

    @XmlElement(name = "link", namespace = "urn:ced:link")
    public List&lt;ResourceLink&gt; getLinks() {
        if (this.links == null) {
            this.links = new ArrayList&lt;ResourceLink&gt;();
        }
        return links;
    }

    public void addLink(ResourceLink link) {
        getLinks().add(link);
    }

    public boolean doesNotContainRel(String rel) {
        return !containRel(rel);
    }

    public boolean containRel(String rel) {
        if(links == null || links.size() == 0) {
            return false;
        }
        for(ResourceLink link : links) {
            if(rel.equals(link.getRel())) {
                return true;
            }
        }
        return false;
    }

    @Override @XmlTransient
    public Class&lt;X&gt; getSourceType() {
        return sourceType;
    }

    @Override @XmlTransient
    public String getRepresentationType() {
        return representationType;
    }

    @XmlTransient
    public UriInfo getUriInfo() {
        return uriInfo;
    }
}</programlisting>
<simpara>In the previous section above, we see that our <literal>@ResourceModel</literal> stereotype is <literal>org.cedj.geekseek.web.rest.core.annotation.Linked</literal>, a custom annotation of our own:</simpara>
<programlisting language="java" linenumbering="unnumbered">@InterceptorBinding
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.TYPE)
public @interface Linked {

}</programlisting>
<simpara>This indicates that we&#8217;ll apply an interceptor called <literal>org.cedj.geekseek.web.rest.core.interceptor.LinkedInterceptor</literal> to anything with this annotation.  <literal>LinkedInterceptor</literal> has the responsibility to determine if the invocation has a linkable representation, and if so, link all of the <literal>LinkableRepresentation</literal> view together.  Anything with the <literal>@Linked</literal> annotation will run this interceptor, including our <literal>@ResourceModel</literal>.</simpara>
<simpara>The reasoning behind this approach is: some <literal>Representation</literal> objects are linkable.  Via the <literal>@ResourceModel</literal> (which contains <literal>@Linked</literal>), a link provider may link a given resource to some other resource.  This way, we may draw relationships between resources (entities) that are not described in the by JPA.  The interceptor is implemented like so:</simpara>
<programlisting language="java" linenumbering="unnumbered">@Linked
@Interceptor
public class LinkedInterceptor {

    @Inject
    private Instance&lt;LinkProvider&gt; linkProviers;

    @AroundInvoke
    public Object link(InvocationContext ic) throws Exception {
        Object obj = ic.proceed();
        if(hasLinkableRepresentations(obj)) {
            linkAllRepresentations(obj);
        }
        return obj;
    }

    private boolean hasLinkableRepresentations(Object obj) {
        return locateLinkableRepresenatation(obj) != null;
    }

    private LinkableRepresenatation&lt;?&gt; locateLinkableRepresenatation(Object obj) {
        if(obj instanceof Response) {
            Object entity = ((Response)obj).getEntity();
            if(entity instanceof LinkableRepresenatation) {
                return (LinkableRepresenatation&lt;?&gt;)entity;
            }
        }
        return null;
    }

    private void linkAllRepresentations(Object obj) {
        LinkableRepresenatation&lt;?&gt; linkable = locateLinkableRepresenatation(obj);
        for(LinkProvider linker : linkProviers) {
            linker.appendLinks(linkable);
        }
    }
}</programlisting>
</section>
<section id="_literal_resourcelink_literal">
<title><literal>ResourceLink</literal></title>
<simpara>Recall from our DAP that many requests are to return a link to other resources as the client makes its way through state changes in the application.  A link is really a value object to encapsulate a media type, href (link), and relation.  We provide this in <literal>org.cedj.geekseek.web.rest.core.ResourceLink</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">public class ResourceLink {

    private String rel;
    private URI href;
    private String type;

    public ResourceLink(String rel, URI href, String media) {
        this.rel = rel;
        this.href = href;
        this.type = media;
    }

    @XmlAttribute
    public String getHref() {
        if (href == null) {
            return null;
        }
        return href.toASCIIString();
    }

    @XmlAttribute
    public String getRel() {
        return rel;
    }

    @XmlAttribute
    public String getMediaType() {
        return type;
    }

    public void setHref(String href) {
        this.href = URI.create(href);
    }

    public void setRel(String rel) {
        this.rel = rel;
    }

    public void setType(String type) {
        this.type = type;
    }
}</programlisting>
<simpara><literal>LinkableRepresentation</literal> will use this value object in particular to handle its linking strategy between disparate entities that are not related in the JPA model.</simpara>
</section>
</section>
<section id="_requirement_test_scenarios_2">
<title>Requirement Test Scenarios</title>
<simpara>With our implementation in place leveraging JAX-RS to map our DAP to business methods, we&#8217;re set to test our endpoints.  The core areas we want to assert are the expected responses from requests to:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>PUT</literal> data
</simpara>
</listitem>
<listitem>
<simpara>
<literal>GET</literal> data
</simpara>
</listitem>
<listitem>
<simpara>
<literal>POST</literal> data
</simpara>
</listitem>
<listitem>
<simpara>
<literal>DELETE</literal> data
</simpara>
</listitem>
<listitem>
<simpara>
Obtain the appropriate links
</simpara>
</listitem>
</itemizedlist>
<section id="_a_black_box_test">
<title>A Black-Box Test</title>
<simpara>The general flow of our first test will be to model a user&#8217;s actions as she navigates through the site.  To accomplish execution of the test methods in sequence, we&#8217;ll use Arquilian&#8217;s <literal>@InSequence</literal> annotation to signal the order of test execution.  This will really position the test class as more of a "test scenario", with each test method acting as the separate tests which must maintain a proper order.  In this fashion, we will follow the normal REST client flow from point A to B to C and so on.  We&#8217;re going to execute requests to:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>GET</literal> The Root resource
</simpara>
</listitem>
<listitem>
<simpara>
Locate the <literal>Conference</literal> link
</simpara>
</listitem>
<listitem>
<simpara>
<literal>POST</literal> to create a new <literal>Conference</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>GET</literal> to read the created <literal>Conference</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Locate the <literal>Session</literal> link
</simpara>
</listitem>
<listitem>
<simpara>
<literal>POST</literal> to create a new <literal>Session</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>GET</literal> to read the created <literal>Session</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>PUT</literal> to update the <literal>Session</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>DELETE</literal> to delete the <literal>Session</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>PUT</literal> to update the <literal>Conference</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>DELETE</literal> to delete the <literal>Conference</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>This will be a pure client-side test; it requires <emphasis>something</emphasis> deployed which will talk to the REST APIs.  We have provided this logic in <literal>org.cedj.geekseek.web.rest.conference.test.integration.story.CreateConferenceAndSessionStory</literal>:</simpara>
<programlisting language="java" linenumbering="unnumbered">@RunWith(Arquillian.class)
public class CreateConferenceAndSessionStory {

    private static String uri_conference = null;
    private static String uri_conferenceInstance = null;
    private static String uri_session = null;
    private static String uri_sessionInstance = null;

    @ArquillianResource
    private URL base;

    @BeforeClass
    public static void setup() {
        RestAssured.filters(
                ResponseLoggingFilter.responseLogger(),
                new RequestLoggingFilter());
    }</programlisting>
<simpara>The <literal>@RunWith</literal> annotation above should be familiar by now; Arquillian will be handling the test lifecycle for us.  As noted above, it&#8217;s good practice to allow Arquillian to inject the base URL of the application by using <literal>@ArquillianResource</literal>.  And because we&#8217;re not bound to any frameworks in particular, we may also use the <ulink url="https://code.google.com/p/rest-assured/">REST-assured</ulink> project to provide us with a clean DSL to validate our REST services.</simpara>
<simpara>Notably missing from this declaration is the <literal>@Deployment</literal> method, which we supply in <literal>CreateConferenceAndSessionStoryTestCase</literal> so we may decouple the test scenario from the test deployment logic; this encourages re-use for running the same tests with different deployments so we may further integrate other layers later.  The deployment method for our purposes here looks like:</simpara>
<programlisting language="java" linenumbering="unnumbered">@Deployment(testable = false)
public static WebArchive deploy() {
    return ConferenceRestDeployments.conference()
      .addAsWebInfResource(new File("src/main/resources/META-INF/beans.xml"));
}</programlisting>
<simpara>Because this is a black-box test, we set <literal>testable</literal> to <literal>false</literal> to tell Arquillian not to equip the deployment with any additional test runners; we don&#8217;t want to test in-container here, but rather run requests from the outside of the server and analyze the response.  The test should verify a behavior, not any internal details.  We could likely write a test where we employ sharing of objects and this might be easier to code and update, but could also sneak in unexpected client changes which should have been caught by the tests.  We&#8217;re interested only in testing the contract between the client and the server, which is specified by our DAP.  Thus, black-box testing is an appropriate solution in this case.</simpara>
<simpara>In this deployment, we&#8217;ll also use "fake" implementations for the Repository / JPA layer; these are provided by the <literal>TestConferenceRepository</literal> and <literal>TestSessionRepository</literal> test classes which simulate the JPA layer for testing purposes.  We won&#8217;t be hitting the database for the tests at this level of integration.  Later on, when we fully-integrate the application, we&#8217;ll bring JPA back into the picture.</simpara>
<programlisting language="java" linenumbering="unnumbered">@ApplicationScoped
public abstract class TestRepository&lt;
  T extends Identifiable&gt; implements Repository&lt;T&gt; { .. }

public class TestConferenceRepository extends
  TestRepository&lt;Conference&gt; { .. }</programlisting>
<simpara>On to the tests:</simpara>
<programlisting language="java" linenumbering="unnumbered">// Story: As a 3rd party Integrator I should be able locate the Conference root Resource
@Test @InSequence(0)
public void shouldBeAbleToLocateConferenceRoot() throws Exception {
        //uri_conference = new URL(base, "api/conference").toExternalForm();
        uri_conference =
              given().
              then().
                  contentType(BASE_MEDIA_TYPE).
                  statusCode(Status.OK.getStatusCode()).
                  root("root").
                      body("link.find {it.@rel == 'conference'}.size()", equalTo(1)).
              when().
                  get(new URL(base, "api/").toExternalForm()).
              body().
                  path("root.link.find {it.@rel == 'conference'}.@href");
    }</programlisting>
<simpara>Our first test is charged with locating the conference root at the base URL + "api" (as we&#8217;d implemented using the <literal>@ApplicationPath</literal> annotation in our application).  We set the media type and expect to have our links for the conference returned to the client matching the <literal>@Path</literal> annotation we have sitting atop our <literal>ConferenceResource</literal> class (baseURL + "api" + "conference").  The <literal>@InSequence</literal> annotation set to value of <literal>0</literal> will ensure that this test is run first.</simpara>
<simpara>Assuming that&#8217;s successful, we may move on to our next test, creating a conference:</simpara>
<programlisting language="java" linenumbering="unnumbered">// Story: As a 3rd party Integrator I should be able create a Conference
@Test @InSequence(1)
public void shouldBeAbleToCreateConference() throws Exception { .. }
...</programlisting>
<simpara>The rest of the test class contains test logic to fulfill our test requirements above.</simpara>
</section>
<section id="_validating_the_http_contracts_with_warp">
<title>Validating the HTTP Contracts with Warp</title>
<simpara>Above we&#8217;ve ensured that the responses from the server are in expected form.  We&#8217;d additionally like to certify that our service is obeying the general contracts of HTTP.  As by definition this will involve a lot of client-side requests and parsing of server responses, it&#8217;ll be helpful for us to avoid writing a lot of custom code to negotiate the mapping.  For these tasks, we introduce an extension to Arquillian which is aimed at making this type of testing easier.</simpara>
</section>
<section id="_arquillian_warp">
<title>Arquillian Warp</title>
<simpara>Arquillian Warp fills the void between client- and server-side testing.</simpara>
<simpara>Using Warp, we may initiate an HTTP request using a client-side testing tool such as WebDriver and, in the same request cycle, execute in-container server-side tests. This powerful combination lets us cover integration across client and server.</simpara>
<simpara>Warp effectively removes the need for mocking and opens new possibilities for debugging.  It also allows us to know as little or as much of the application under test as you want.</simpara>
<section id="_gray_box_testing">
<title>Gray-Box Testing</title>
<simpara>Initially, Warp can be used from any black-box testing tool (like HttpClient, REST client, Selenium WebDriver, etc.). But it allows us to hook into the server request lifecycle and verify what happens inside the box (referred to as white-box testing). Thus, we identify Warp as a hybrid "gray-box" testing framework.</simpara>
</section>
<section id="_integration_testing">
<title>Integration Testing</title>
<simpara>No matter the granularity of our tests, Warp fits the best integration level of testing with an overlap to functional testing. You may either test components, application API or functional behavior.</simpara>
</section>
<section id="_technology_independence">
<title>Technology Independence</title>
<simpara>Whatever client-side tools we use for emiting an HTTP request, Warp allows us to assert and verify logic on a most appropriate place of client-server request lifecycle.</simpara>
</section>
<section id="_use_cases">
<title>Use Cases</title>
<simpara>Warp can:</simpara>
<itemizedlist>
<listitem>
<simpara>
Send a payload to a server
</simpara>
</listitem>
<listitem>
<simpara>
Verify an incoming request
</simpara>
</listitem>
<listitem>
<simpara>
Assert the state of a server context
</simpara>
</listitem>
<listitem>
<simpara>
Verify that a given event was fired during request processing
</simpara>
</listitem>
<listitem>
<simpara>
Verify a completed response
</simpara>
</listitem>
<listitem>
<simpara>
Send a payload to a client
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_deploying_warp">
<title>Deploying Warp</title>
<simpara>Thanks to an ability to bring an arbitrary payload to a server and hook into server-lifecycle, we can use Warp in partially-implemented projects. We do not require the database layer to be implemented in order to test UI logic. This is especially useful for projects based on loosely-coupled components (e.g. CDI).</simpara>
</section>
<section id="_supported_tools_and_frameworks">
<title>Supported Tools and Frameworks</title>
<simpara>====== Cross-protocol</simpara>
<simpara>Warp currently supports only the HTTP protocol, but conceptually it can be used with any protocol where we are able to intercept client-to-server communication on both, the client and the server.</simpara>
<simpara>====== Client-Side Testing Tools</simpara>
<simpara>Warp supports any client-side tools if you are using them in a way that requests can be intercepted (in a case of HTTP protocol, you need to communicate through a proxy instead of direct communication with a server).</simpara>
<simpara>Examples of such libraries/frameworks:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>URL#getResourceAsStream()</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Apache HTTP Client
</simpara>
</listitem>
<listitem>
<simpara>
Selenium WebDriver
</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>In order to use Warp, you should inject an @ArquillianResource URL into the test case, which points to the proxy automatically.</simpara>
</note>
</section>
<section id="_frameworks">
<title>Frameworks</title>
<simpara>Warp currently focuses on frameworks based on the Servlets API, but it provides special hooks and additional support for:</simpara>
<itemizedlist>
<listitem>
<simpara>
JSF
</simpara>
</listitem>
<listitem>
<simpara>
JAX-RS (REST)
</simpara>
</listitem>
<listitem>
<simpara>
Spring MVC
</simpara>
</listitem>
</itemizedlist>
<simpara>For more information about Warp, visit arquillian.org[arquillian.org].</simpara>
</section>
</section>
<section id="_test_harness_setup">
<title>Test Harness Setup</title>
<simpara>We&#8217;ll start by enabling the Arquillian Warp in the POM&#8217;s <literal>dependencyManagement</literal> section:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;dependency&gt;
    &lt;groupId&gt;org.jboss.arquillian.extension&lt;/groupId&gt;
    &lt;artifactId&gt;arquillian-warp-bom&lt;/artifactId&gt;
    &lt;version&gt;${version.arquillian_warp}&lt;/version&gt;
    &lt;scope&gt;import&lt;/scope&gt;
    &lt;type&gt;pom&lt;/type&gt;
&lt;/dependency&gt;</programlisting>
<simpara>The above will lock down the versions correctly such that all Warp modules are of the expected version.  A <literal>dependency</literal> declaration in the <literal>dependencies</literal> section will make Warp available for our use:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;dependency&gt;
    &lt;groupId&gt;org.jboss.arquillian.extension&lt;/groupId&gt;
    &lt;artifactId&gt;arquillian-warp-impl&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;</programlisting>
</section>
<section id="_the_http_contracts_test">
<title>The HTTP Contracts Test</title>
<simpara>Now we&#8217;d like to test details of the REST service behavior; we&#8217;ll use Warp to allow easy control over permutations of data.  Again, we&#8217;ll be swapping out alternate <literal>Repository</literal> implementations to  bypass JPA and real peristence; we&#8217;re just interested in the HTTP request/response interactions at this stage.</simpara>
<simpara>What we&#8217;d like to do in this test is create <literal>Conference</literal> domain objects on the client side and transfer them to the server.  Warp will allow us to control which data to fetch through the JAX-RS layer.  For instance, from the abstract base of the <literal>ConferenceResourceSpecificationTestCase</literal>, which is annotated with <literal>@WarpTest</literal> to activate Warp:</simpara>
<programlisting language="java" linenumbering="unnumbered">@Test
public void shouldReturnOKOnGETResource() throws Exception {
    final DOMAIN domain = createDomainObject();

    Warp.initiate(new Activity() {
        @Override
        public void perform() {
            responseValidation(
                given().
                then().
                    contentType(getTypedMediaType())
            , domain).
            when().
                get(createRootURL() + "/{id}",
                    domain.getId()).body();
        }
    }).inspect(
        new SetupRepository&lt;DOMAIN&gt;(
            getDomainClass(), domain));
}</programlisting>
<simpara>Here we use Warp to produce the data we want the REST layer to receive, and validate that we obtain the correct HTTP response for a valid <literal>GET</literal> request.</simpara>
<simpara>Running this test locally, we&#8217;ll see that Warp constructs an HTTP <literal>GET</literal> request for us:</simpara>
<screen>GET /9676980f-2fc9-4103-ae28-fd0261d1d7c3/api/conference/ac5390ad-5483-4239-850c-62efaeee7bf1 HTTP/1.1[\r][\n]
Accept: application/vnd.ced+xml; type=conference[\r][\n]
Host: 127.0.1.1:18080[\r][\n]
Connection: Keep-Alive[\r][\n]
Accept-Encoding: gzip,deflate[\r][\n]</screen>
<simpara>Because we&#8217;ve coded our JAX-RS endpoints and backing business objects correctly, we&#8217;ll receive the expected reply (an HTTP <literal>200 OK</literal> status):</simpara>
<screen>&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;&lt;ns3:conference xmlns:ns2="urn:ced:link" xmlns:ns3="urn:ced:conference"&gt;&lt;ns2:link href="http://127.0.1.1:18080/9676980f-2fc9-4103-ae28-fd0261d1d7c3/api/conference/ac5390ad-5483-4239-850c-62efaeee7bf1" rel="self"/&gt;&lt;ns2:link href="http://127.0.1.1:18080/9676980f-2fc9-4103-ae28-fd0261d1d7c3/api/conference/ac5390ad-5483-4239-850c-62efaeee7bf1/session" rel="session"/&gt;&lt;end&gt;2013-08-21T00:14:44.159-04:00&lt;/end&gt;&lt;name&gt;Name&lt;/name&gt;&lt;start&gt;2013-08-21T00:14:44.159-04:00&lt;/start&gt;&lt;tagLine&gt;TagLine&lt;/tagLine&gt;&lt;/ns3:conference&gt;"
HTTP/1.1 200 OK
X-Arq-Enrichment-Response=3778738317992283532
Last-Modified=Wed, 21 Aug 2013 04:14:44 GMT
Content-Type=application/vnd.ced+xml; type=conference
Content-Length=564
Via=1.1.overdrive.home

&lt;ns3:conference xmlns:ns3="urn:ced:conference"&gt;
  &lt;ns2:link xmlns:ns2="urn:ced:link"
    href="http://127.0.1.1:18080/9676980f-2fc9-4103-ae28-fd0261d1d7c3/api/conference/ac5390ad-5483-4239-850c-62efaeee7bf1"
    rel="self"/&gt;
  &lt;ns2:link xmlns:ns2="urn:ced:link"
    href="http://127.0.1.1:18080/9676980f-2fc9-4103-ae28-fd0261d1d7c3/api/conference/ac5390ad-5483-4239-850c-62efaeee7bf1/session"
    rel="session"/&gt;
  &lt;end&gt;
    2013-08-21T00:14:44.159-04:00
  &lt;/end&gt;
  &lt;name&gt;
    Name
  &lt;/name&gt;
  &lt;start&gt;
    2013-08-21T00:14:44.159-04:00
  &lt;/start&gt;
  &lt;tagLine&gt;
    TagLine
  &lt;/tagLine&gt;
&lt;/ns3:conference&gt;</screen>
<simpara>The response will contain our links to related resources, as well as information about the requested <literal>Conference</literal> object in the XML <literal>xmlns:ns3="urn:ced:conference"</literal> format.  Using Warp we may interact with and perform validations upon these types of payloads with ease.</simpara>
<simpara>There are plenty of other detailed Warp examples throughout the tests of the REST modules in the GeekSeek application code; we advise readers to peruse the source for additional ideas in using this very powerful tool for white-box testing of the request/response model.</simpara>
</section>
</section>
</section>
<section id="_assembly_and_deployment">
<title>Assembly and Deployment</title>
<simpara><emphasis>"The road to success is always under construction." - Lily Tomlin</emphasis></simpara>
<simpara>To this point, we&#8217;ve focused primarily on the testable development of our modules and have taken some selective slices out for examination and testing.  The time has come for us to address full integration by bringing everything together into a single deployable unit.</simpara>
<simpara>Additionally, we&#8217;ll look at some alternative (and arguably more enterprise-ready) runtimes for our application.  Ideally, we&#8217;d like to be in a position where our test environment is aligned as closely as possible to that which will be run in production, and we&#8217;ll further aim to automate the process of deployment.  By removing human interaction as much as possible, our potential for mistakes decreases and we learn to rely instead on our testsuite as a guardian of code quality.</simpara>
<simpara>This chapter will ultimately link a <literal>git push</literal> to validate new commits in a <emphasis>continuous integration</emphasis> server before deploying the new version of our application into the publicly-accessible web.  Whether you go straight to production or first to a staging environment, these steps should outline a smooth transition from development to real application use.</simpara>
<section id="_obtaining_jboss_eap">
<title>Obtaining JBoss EAP</title>
<simpara><emphasis>JBoss Enterprise Application Platform</emphasis> (EAP) is Red Hat&#8217;s supportable application server distribution born from the community open-source <emphasis>WildFly</emphasis> project (formerly known as the JBoss Application Server).  A full discussion of the relationship and differences between community and supportable middleware is detailed by Red Hat <ulink url="http://www.redhat.com/products/jbossenterprisemiddleware/community-enterprise/">here</ulink>, and some of the most important points are:</simpara>
<itemizedlist>
<listitem>
<simpara>
The community projects are built to innovate quickly and push new features at a rapid rate.
</simpara>
</listitem>
<listitem>
<simpara>
Supportable products are intended to have a multi-year life span, and receive updates and bug fixes over this time period.
</simpara>
</listitem>
<listitem>
<simpara>
A support contract and SLA may be purchased for supportable products.
</simpara>
</listitem>
</itemizedlist>
<simpara>In March of 2013, JBoss Senior Director of Engineering <ulink url="https://community.jboss.org/blogs/mark.little/2013/03/07/eap-binaries-available-for-all-developers">announced</ulink> that EAP binaries and its dependencies will be made freely-available (at no monetary cost) through a <emphasis>0-dollar subscription</emphasis> through Red Hat.  As this runtime comes with no obligation and allows us a migration path to support if our little <emphasis>GeekSeek</emphasis> business were to need it, we&#8217;ll opt for EAP as our target runtime.</simpara>
<simpara>EAP has some additional differences with WildFly which become very apparent during our development experience.  Though EAP is available for free, there is a <emphasis>Terms and Conditions</emphasis> prerequisite to its use, and therefore is not currently-available in the JBoss Nexus or Maven Central repositories.  We&#8217;ll have to perform some extra steps to setup our environments for EAP before we can enable this option in our builds.</simpara>
<simpara>First, let&#8217;s obtain the EAP distribution and private JBoss EAP Maven Repository.  This is done from the <ulink url="http://www.jboss.org/jbossas/downloads/">JBoss Downloads</ulink> page.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/download_eap.png"/>
  </imageobject>
  <textobject><phrase>Download JBoss EAP</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Once we agree to the Terms and Conditions, the links to download will begin the process.  Both the EAP distribution and the EAP Maven Repository are bundled as ZIP files.</simpara>
<simpara>Let&#8217;s install EAP by unzipping it into a location on the filesystem.  Anywhere will do; for instance in *nix-like systems we may handle this from the command-line:</simpara>
<screen>~ $&gt; mkdir -p /home/alr/opt/jboss/eap; cd /home/alr/opt/jboss/eap
eap $&gt; mv /home/alr/Downloads/jboss-eap-6.1.0.zip .
eap $&gt; unzip jboss-eap-6.1.0.zip</screen>
<simpara>Using the above, we&#8217;d now have EAP installed at <literal>/home/alr/opt/jboss/eap/jboss-eap-6.1/</literal>.</simpara>
<simpara>Now let&#8217;s place our EAP Maven repository somewhere useful.  It might be enticing to mix in these artifacts with our default Maven repository (typically located at <literal><emphasis>USER_HOME</emphasis>/.m2/repository</literal>), but let&#8217;s keep things separated and create a new extension repo for our product bits.  This way we&#8217;ll have the option of enabling this repository explicitly in our builds and won&#8217;t ever have to worry about placing these artifacts alongside ones found in Maven Central.  We&#8217;ll choose <literal><emphasis>USER_HOME</emphasis>/.m2/jboss-eap-6.1.0.GA-maven-repository</literal> (the default folder name contained inside the ZIP, under our user&#8217;s Maven directory):</simpara>
<screen>Downloads $&gt; unzip jboss-eap-6.1.0-maven-repository.zip
Downloads $&gt; mv jboss-eap-6.1.0-maven-repository ~/.m2/
Downloads $&gt; rm jboss-eap-6.1.0-maven-repository.zip</screen>
</section>
<section id="_running_against_jboss_eap">
<title>Running Against JBoss EAP</title>
<simpara>With our EAP installation in place, we&#8217;re now in a position to exercise our application against this server instead of WildFly, which we&#8217;ve used up to this point as a convenient default.</simpara>
<section id="_using_the_eap_remote_container">
<title>Using the EAP Remote Container</title>
<simpara>First we&#8217;ll run EAP as a standalone process.  Opening a terminal or console window, let&#8217;s <literal>cd</literal> into the directory in which we unzipped the distribution.  From there we may export an environment variable to set <literal>JBOSS_HOME</literal> to the present working directory (using the <literal>export</literal> command on *nix systems or simply <literal>set</literal> on Windows machines):</simpara>
<screen>$&gt; cd /home/alr/opt/jboss/eap/jboss-eap-6.1/
jboss-eap-6.1 $&gt; export JBOSS_HOME=`pwd`</screen>
<simpara>Now we&#8217;ll launch the EAP server in standalone (non-domain) mode by using the provided scripts in the <literal>bin</literal> directory:</simpara>
<screen>jboss-eap-6.1 $&gt; cd bin
bin $&gt; ./standalone.sh
=================================
  JBoss Bootstrap Environment
  JBOSS_HOME: /home/alr/opt/jboss/eap/jboss-eap-6.1
  JAVA: /home/alr/opt/oracle/java/jdk7/bin/java
  JAVA_OPTS:  -server -XX:+UseCompressedOops -Xms1303m
     -Xmx1303m -XX:MaxPermSize=256m -Djava.net.preferIPv4Stack=true
     -Djboss.modules.system.pkgs=org.jboss.byteman
     -Djava.awt.headless=true
=================================
...output trimmed
02:57:43,593 INFO  [org.jboss.as] (Controller Boot Thread) JBAS015874: JBoss EAP 6.1.0.GA
   (AS 7.2.0.Final-redhat-8) started in 2404ms -
   Started 123 of 177 services (53 services
   are passive or on-demand)</screen>
<simpara>And with that, we have our server process running and ready to receive deployments or service requests.  As noted in the above output, the startup sequence is complete on our machines in about 2.4 seconds.  You may ensure that everything is working correctly or find links to the web-based management interface by pointing your browser to <literal>http://localhost:8080</literal>:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/eap_home_page.png"/>
  </imageobject>
  <textobject><phrase>EAP Home Page</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Let&#8217;s leave this as-is for the time being, and open a new console window (or tab) in the <emphasis>GeekSeek</emphasis> application&#8217;s source root.</simpara>
<simpara>Our experience with Arquillian up to this point has been using a <emphasis>managed</emphasis> container configuration; this has ceded the responsibility of server startup and shutdown to Arquillian during the <literal>Before Suite</literal> and <literal>After Suite</literal> test lifecycle events.  Now that we&#8217;ve already got a server booted, we can let Arquillian bypass these steps to use a previously-bootstrapped process, which gives us some benefits:</simpara>
<itemizedlist>
<listitem>
<simpara>
We save the time needed to start/stop a server alongside each test suite.
</simpara>
</listitem>
<listitem>
<simpara>
A server does not have to be running locally; the server process may be housed on a separate physical machine accessible on the network.
</simpara>
</listitem>
</itemizedlist>
<simpara>We&#8217;ve provided a Maven profile <literal>arq-jbosseap-remote</literal> to run our Arquillian tests against a running EAP process on the local machine.  From the <emphasis>GeekSeek</emphasis> source code root, simply pass this profile as an argument using the <literal>-P</literal> switch to the <literal>mvn</literal> command and instead of using the default WildFly managed container (which will automatically start/stop), we&#8217;ll instead use our running server that we&#8217;d started earlier.</simpara>
<screen>code $&gt; mvn clean install -Parq-jbosseap-remote</screen>
<simpara>The build will run as we&#8217;ve seen before, only this time you&#8217;ll be able to see in the server console some activity resulting from the deployments made and tests run, for instance:</simpara>
<screen>03:35:30,984 INFO  [org.jboss.as.server]
  (management-handler-thread - 1) JBAS018559:
  Deployed "015c84ea-1a41-4e37-957a-f2433f201a23.war"
  (runtime-name : "015c84ea-1a41-4e37-957a-f2433f201a23.war")</screen>
<simpara>This may be a preferable technique to employ while developing; at the start of the day you may launch the server and keep it running as an external process, and run your tests without the overhead of waiting for server start and stop, as well as the unzipping process (and resulting file I/O) to create local WildFly installation directories under <literal>target</literal> for testing.  On our machines, this cuts the total build time from around 3:30 to 2:11 as we exercise quite a few test suites and hence remove a good number of start/stop lifecycle events by using the remote container.</simpara>
<simpara>As we&#8217;re done with the EAP instance we&#8217;d started earlier, let&#8217;s end the process.</simpara>
<screen>bin $&gt; ^C
03:45:58,876 INFO  [org.jboss.as]
  (MSC service thread 1-5) JBAS015950:
  JBoss EAP 6.1.0.GA (AS 7.2.0.Final-redhat-8)
  stopped in 127ms</screen>
</section>
<section id="_using_the_eap_managed_container">
<title>Using the EAP Managed Container</title>
<simpara>Of course, the <emphasis>GeekSeek</emphasis> examples also make EAP available for use in <emphasis>managed</emphasis> mode, as we&#8217;ve used before.  As EAP is not currently-available as a distribution in a Maven repository, it&#8217;ll take a few extra steps for us to enable this layout.</simpara>
<simpara>Remember that we above downloaded the EAP Maven Repository.  This is an <emphasis>extension</emphasis> repo; it&#8217;s meant to serve as an addition to a standard repo like that offered by JBoss Nexus or Maven Central.  As such, it contains EAP-specific artifacts and dependencies only.</simpara>
<simpara>Let&#8217;s begin by unpacking this into a new repository alongside the default <literal>~/.m2/repository</literal> repo:</simpara>
<screen>~ $&gt; cd ~/.m2/
.m2 $&gt; mv /home/alr/Downloads/jboss-eap-6.1.0-maven-repository.zip .
.m2 $&gt; unzip jboss-eap-6.1.0-maven-repository.zip
.m2 $&gt; rm jboss-eap-6.1.0-maven-repository.zip</screen>
<simpara>This will leave us with a our new EAP extension repository <literal>jboss-eap-6.1.0.GA-maven-repository</literal> under our <literal>.m2/</literal> directory.</simpara>
<simpara>Now we must let Maven know about our new repository, so we may define it in the default user-level <literal>~/.m2/settings.xml</literal>.  Note that we&#8217;re actually free to use any settings file we choose, though if we opt outside of the default settings file we&#8217;ll have to manually specify our settings configuration to the <literal>mvn</literal> command using the <literal>-s /path/to/settings/file</literal> switch.</simpara>
<simpara>Add our repository definition inside of a profile, so that we can enable this at-will without affecting other projects.  In this case we create the <literal>jboss-eap-6.1.0</literal> profile:</simpara>
<screen>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"&gt;
...
&lt;profiles&gt;
  &lt;profile&gt;
    &lt;id&gt;jboss-eap-6.1.0&lt;/id&gt;
    &lt;repositories&gt;
      &lt;repository&gt;
        &lt;id&gt;jboss-eap-6.1.0-maven-repository&lt;/id&gt;
        &lt;name&gt;JBoss EAP 6.1.0 Repository&lt;/name&gt;
        &lt;url&gt;file://${user.home}/.m2/jboss-eap-6.1.0.GA-maven-repository&lt;/url&gt;
        &lt;layout&gt;default&lt;/layout&gt;
        &lt;releases&gt;
          &lt;enabled&gt;true&lt;/enabled&gt;
          &lt;updatePolicy&gt;never&lt;/updatePolicy&gt;
        &lt;/releases&gt;
        &lt;snapshots&gt;
          &lt;enabled&gt;false&lt;/enabled&gt;
          &lt;updatePolicy&gt;never&lt;/updatePolicy&gt;
        &lt;/snapshots&gt;
      &lt;/repository&gt;
    &lt;/repositories&gt;
  &lt;/profile&gt;
  ...
&lt;/profiles&gt;
...
&lt;/settings&gt;</screen>
<simpara>Now, we&#8217;ll need to again find our EAP ZIP.  Then, using the profile we&#8217;ve created above, we&#8217;ll deploy our EAP distribution ZIP as a proper Maven artifact into the repository using the Maven <literal>deploy</literal> plugin.  Remember to pass in our profile from above using the <literal>-P</literal> switch:</simpara>
<screen>mvn deploy:deploy-file -DgroupId=org.jboss.as \
  -DartifactId=jboss-as-dist \
  -Dversion=eap-6.1.0 \
  -Dpackaging=zip \
  -Dfile=/home/alr/Downloads/jboss-eap-6.1.0.zip \
  -DrepositoryId=jboss-eap-6.1.0-maven-repository \
  -Durl=file:///home/alr/.m2/jboss-eap-6.1.0.GA-maven-repository \
  -Pjboss-eap-6.1.0</screen>
<simpara>If we&#8217;ve set everything up correctly, we&#8217;ll see output:</simpara>
<screen>[INFO] Scanning for projects...
...
[INFO]
[INFO] --- maven-deploy-plugin:2.7:deploy-file (default-cli) @ standalone-pom ---
Uploading: file:///home/alr/.m2/jboss-eap-6.1.0.GA-maven-repository/org/jboss/as/jboss-as-dist/eap-6.1.0/jboss-as-dist-eap-6.1.0.zip
Uploaded: file:///home/alr/.m2/jboss-eap-6.1.0.GA-maven-repository/org/jboss/as/jboss-as-dist/eap-6.1.0/jboss-as-dist-eap-6.1.0.zip (112789 KB at 50828.7 KB/sec)
Uploading: file:///home/alr/.m2/jboss-eap-6.1.0.GA-maven-repository/org/jboss/as/jboss-as-dist/eap-6.1.0/jboss-as-dist-eap-6.1.0.pom
Uploaded: file:///home/alr/.m2/jboss-eap-6.1.0.GA-maven-repository/org/jboss/as/jboss-as-dist/eap-6.1.0/jboss-as-dist-eap-6.1.0.pom (431 B at 420.9 KB/sec)
Downloading: file:///home/alr/.m2/jboss-eap-6.1.0.GA-maven-repository/org/jboss/as/jboss-as-dist/maven-metadata.xml
Uploading: file:///home/alr/.m2/jboss-eap-6.1.0.GA-maven-repository/org/jboss/as/jboss-as-dist/maven-metadata.xml
Uploaded: file:///home/alr/.m2/jboss-eap-6.1.0.GA-maven-repository/org/jboss/as/jboss-as-dist/maven-metadata.xml (313 B at 305.7 KB/sec)
...
[INFO] BUILD SUCCESS
[INFO] Total time: 2.911s
[INFO] Finished at: Mon Jun 03 05:30:53 MST 2013
[INFO] Final Memory: 5M/102M</screen>
<simpara>And in the <literal>~/.m2/jboss-eap-6.1.0.GA-maven-repository/org/jboss/as/jboss-as-dist</literal> directory, we should see our EAP distribution ZIP along with some Maven-generated metadata files:</simpara>
<screen>$&gt; ls -R
.:
eap-6.1.0           maven-metadata.xml.md5
maven-metadata.xml  maven-metadata.xml.sha1

./eap-6.1.0:
jboss-as-dist-eap-6.1.0.pom
jboss-as-dist-eap-6.1.0.pom.md5
jboss-as-dist-eap-6.1.0.pom.sha1
jboss-as-dist-eap-6.1.0.zip
jboss-as-dist-eap-6.1.0.zip.md5
jboss-as-dist-eap-6.1.0.zip.sha1</screen>
<simpara>Now, assuming we enable the <literal>jboss-eap-6.1.0</literal> profile in our builds, we&#8217;ll be able to use EAP just as we had for WildFly, as we&#8217;ve assigned it to a proper Maven artifact in the coordinate space <literal>org:jboss.as:jboss-as-dist:eap-6.1.0</literal>.</simpara>
<simpara>To run our <emphasis>GeekSeek</emphasis> build with tests against EAP in managed mode, apply the <literal>jboss-eap-6.1.0</literal> profile to enable our custom repository, and the <literal>arq-jbosseap-managed</literal> profile to configure Arquillian with the proper adaptors:</simpara>
<screen>code $&gt; mvn clean install -Parq-jbosseap-managed,jboss-eap-6.1.0</screen>
<simpara>In this fashion, we can now automate our testing with EAP just as we&#8217;ve been doing with WildFly.</simpara>
</section>
</section>
<section id="_continuous_integration_and_the_authoritative_build_server">
<title>Continuous Integration and the Authoritative Build Server</title>
<simpara>The practice of <emphasis>continuous integration</emphasis> involves the frequent pushing of code to a shared mainline, then executing a robust testsuite against it.  Ideally each commit will be tested in this fashion, and while we should strive to run as many tests as are appropriate locally before pushing code to the source repository for all to see, the most reliable agent to verify correctness is our <emphasis>authoritative build server</emphasis>.</simpara>
<simpara>Our goal here is to set up a continuous integration environment which will serve two primary purposes:</simpara>
<itemizedlist>
<listitem>
<simpara>
Run the testsuite in a controlled environment when a <literal>git push</literal> is made to the authoritative source repository
</simpara>
</listitem>
<listitem>
<simpara>
Trigger the deployment of the latest version of our application upon build success
</simpara>
</listitem>
</itemizedlist>
<simpara>In this way we chain events together in order to automate the human action of a code commit all the way through deployment to a publicly-accessible application server.</simpara>
<simpara>While we have our choice of build servers and cloud services backing them, we&#8217;ve chosen for our examples the <ulink url="http://jenkins-ci.org/">Jenkins CI Server</ulink> (the project forked off <ulink url="http://hudson-ci.org/">Hudson</ulink>) run by the <ulink url="http://www.cloudbees.com/">CloudBees</ulink> service.  Of course, we could install a CI server and maintain it ourselves, but the excellent folks at CloudBees have proven more than capable at keeping our infrastructure running, patched, and updated.  Additionally, they offer a few extension services (which we&#8217;ll soon see) that fit well with our desired use cases.</simpara>
<simpara>It&#8217;s worth noting that the CloudBees team has kindly provided the Arquillian and ShrinkWrap communities with gratis service and support over the past several years, so we&#8217;d like to thank them for their contributions in keeping the open-source ecosystem running smoothly.</simpara>
<section id="_configuring_the_emphasis_geekseek_emphasis_build_on_cloudbees">
<title>Configuring the <emphasis>GeekSeek</emphasis> Build on CloudBees</title>
<simpara>As our eventual deployment target will be EAP, we&#8217;re going to configure CloudBees as our authoritative build server to execute Arquillian tests against the EAP runtime.  Just as we&#8217;d run a few extra steps on our local environment to equip the backing Maven repositories with an EAP distribution, we&#8217;ll have to make the same artifacts available to our CloudBees Jenkins instance.  Luckily, we&#8217;ve already done most of that work locally, so this will mainly be an issue of copying over the EAP Maven repository we already have.</simpara>
<simpara>First we&#8217;ll log into our CloudBees account and select to enter the Jenkins Dashboard from within CloudBees Central.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/cloudbees_jenkins_button.png"/>
  </imageobject>
  <textobject><phrase>CloudBees Jenkins</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>We&#8217;ll create a <literal>New Job</literal>, assigning it our project name of <emphasis>GeekSeek</emphasis> and selecting a <literal>Maven2/Maven3 Build</literal> configuration template.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/cloudbees_new_job.png"/>
  </imageobject>
  <textobject><phrase>CloudBees New Job</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>The next step is to configure the build parameters.  First let&#8217;s set the <literal>SCM</literal> section to point to our authoritative Git repository; this is where the build will pull code.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/cloudbees_scm.png"/>
  </imageobject>
  <textobject><phrase>CloudBees SCM</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Now we&#8217;ll tell Maven how to run the build; remember, we want to enable the <literal>arq-jbosseap-managed</literal> profile, so we&#8217;ll note that in the <literal>Goals and options</literal> section.  Also, enable our alternative settings file which will expose our <literal>private</literal> repository to our build.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/cloudbees_build_config.png"/>
  </imageobject>
  <textobject><phrase>CloudBees Build Config</phrase></textobject>
</inlinemediaobject></simpara>
</section>
<section id="_populating_cloudbees_jenkins_with_the_eap_repository">
<title>Populating CloudBees Jenkins with the EAP Repository</title>
<simpara>CloudBees offers a series of Maven repositories associated with each Jenkins domain.  These are documented <ulink url="http://wiki.cloudbees.com/bin/view/DEV/CloudBees+Private+Maven+Repository">here</ulink>, and of particular note is the <literal>private</literal> repository that is made available to us.  We&#8217;ll be able to write to it and place in artifacts demanded by our builds, yet the visibility permissions associated with the <literal>private</literal> repo will block the rest of the world from seeing or accessing these resources.</simpara>
<simpara>To copy our EAP Maven Repository into the CloudBees Jenkins <literal>private</literal> repo, we&#8217;ll make use of the WebDAV protocol, an extension of HTTP which permits writing to WWW resources.  There are a variety of system-dependent tools to mount DAV volumes, and CloudBees addresses some known working techniques in their <ulink url="http://wiki.cloudbees.com/bin/view/DEV/Mounting+DAV+Repositories">documentation</ulink>.  For illustrative purposes, we&#8217;ll apply *nix-specific software in this guide, loosely based off the <ulink url="http://wiki.cloudbees.com/bin/view/DEV/CloudBees+Maven+Repository+-+Mounting">CloudBees Linux Documentation</ulink>.</simpara>
<simpara>First we need to install the <ulink url="http://savannah.nongnu.org/projects/davfs2">davfs2</ulink> project, a set of libraries enabling the mounting of a WebDAV resource as a standard logical volume.  In most Linux-based systems with a package manager, installation may be done using <literal>apt-get</literal> or <literal>yum</literal>:</simpara>
<screen>$&gt; sudo apt-get install davfs2</screen>
<simpara>or</simpara>
<screen>$&gt; sudo yum install davfs2</screen>
<simpara>Next we&#8217;ll ensure that our <literal>/etc/conf/davfs2/davfs2.conf</literal> configuration file is set up appropriately; be sure to edit yours to match the following:</simpara>
<screen>$&gt; cat /etc/davfs2/davfs2.conf
use_locks 0
ask_auth 1
if_match_bug 1</screen>
<simpara>The last line is unique to Ubuntu-based x64 systems, details: <ulink url="https://bugs.launchpad.net/ubuntu/+source/davfs2/+bug/466960">https://bugs.launchpad.net/ubuntu/+source/davfs2/+bug/466960</ulink></simpara>
<simpara>Now we may create a directory which will act as our mounting point; we&#8217;ve chosen <literal>/mnt/cloudbees/arquillian/private</literal>:</simpara>
<screen>$&gt; mkdir -p /mnt/cloudbees/arquillian/private</screen>
<simpara>The <literal>fstab</literal> utility on *nix systems acts to automatically handle mounting to registered endpoints.  It&#8217;s configured in <literal>/etc/fstab</literal>, so using your favorite text editor, add the following line (replacing your own parameters) to the configuration:</simpara>
<screen># Arquillian WebDAV on CloudBees
https://repository-{domainId}.forge.cloudbees.com/private/ {/mnt/location/path} davfs rw,user,noauto,conf=/etc/davfs2/davfs2.conf,uid=$UID 0 0</screen>
<simpara>The <literal>private</literal> repository requires authentication, so we must add authentication information to <literal>/etc/davfs2/secrets</literal>:</simpara>
<screen>{/mnt/location/path}   {cloudbees username}   {password}</screen>
<simpara>Note the CloudBees username here is available on the details page under "Authenticated Access", located at <ulink url="https://forge.cloudbees.com/a/">https://forge.cloudbees.com/a/</ulink><emphasis>domainId</emphasis>/repositories/private:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/cloudbees_auth_access.png"/>
  </imageobject>
  <textobject><phrase>CloudBees Authenticated Access</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Now we should be ready to mount our volume (subsequent reboots to the system should do this automatically due to our <literal>fstab</literal> configuration).</simpara>
<screen>$&gt; sudo mount /mnt/cloudbees/arquillian/private/</screen>
<simpara>With our volume mounted, any file activities we make under <literal>/mnt/cloudbees/arquillian/private/</literal> will be reflected in our remote <literal>private</literal> CloudBees Maven Repository.  Let&#8217;s copy the contents of the JBoss EAP Maven Repository into <literal>private</literal>:</simpara>
<screen>sudo cp -Rv ~/.m2/jboss-eap-6.1.0.GA-maven-repository/* \
  /mnt/cloudbees/arquillian/private/</screen>
<simpara>This may take some time as we copy all artifacts and the directory structure over the network.</simpara>
<simpara>We must also enable this private repository in our build configuration.  In the private repo (which we have mounted) is a file <literal>maven/settings.xml</literal>.  We&#8217;ll edit it to add the following sections:</simpara>
<simpara>Under <literal>&lt;servers&gt;</literal>:</simpara>
<screen>&lt;server&gt;
  &lt;id&gt;cloudbees-private-maven-repository&lt;/id&gt;
  &lt;username&gt;{authorized_username}&lt;/username&gt;
  &lt;password&gt;{authorized_password}&lt;/password&gt;
  &lt;filePermissions&gt;664&lt;/filePermissions&gt;
  &lt;directoryPermissions&gt;775&lt;/directoryPermissions&gt;
&lt;/server&gt;</screen>
<simpara>And under <literal>&lt;profiles&gt;</literal>:</simpara>
<screen>&lt;profile&gt;
  &lt;id&gt;cloudbees.private.maven.repository&lt;/id&gt;
  &lt;activation&gt;
    &lt;property&gt;
      &lt;name&gt;!cloudbees.private.maven.repository.off&lt;/name&gt;
    &lt;/property&gt;
  &lt;/activation&gt;
  &lt;repositories&gt;
  &lt;repository&gt;
    &lt;id&gt;cloudbees-private-maven-repository&lt;/id&gt;
    &lt;url&gt;https://repository-arquillian.forge.cloudbees.com/private&lt;/url&gt;
    &lt;releases&gt;
      &lt;enabled&gt;true&lt;/enabled&gt;
    &lt;/releases&gt;
    &lt;snapshots&gt;
      &lt;enabled&gt;false&lt;/enabled&gt;
    &lt;/snapshots&gt;
  &lt;/repository&gt;
 &lt;/repositories&gt;
&lt;/profile&gt;</screen>
<simpara>Keep in mind that some mounting systems (including <literal>davfs2</literal>) may cache content locally, and avoid flushing bytes to the remote CloudBees DAV repository immediately for performance reasons.  In order to force a flush, we can unmount, then remount the volume:</simpara>
<screen>$&gt; sudo umount /mnt/cloudbees/arquillian/private
$&gt; sudo mount -a</screen>
<simpara>Note: it&#8217;s not atypical for large hold times while the cache synchronizes over the network:</simpara>
<screen>/sbin/umount.davfs: waiting while mount.davfs (pid 11125) synchronizes the cache ....</screen>
<simpara>Now we can manually trigger a build of our project, and if all&#8217;s set up correctly, we&#8217;ll see our test result come out clear.</simpara>
</section>
<section id="_automatic_building_on_literal_git_push_literal_events">
<title>Automatic Building on <literal>Git Push</literal> Events</title>
<simpara>Let&#8217;s take things one step further in terms of automation.  We don&#8217;t have to press the <literal>Build Now</literal> button on our CI server every time we&#8217;d like to run a build.  With some extra configuration we can set up a trigger for new <literal>git push</literal> events on the authoritative source repository to start a new CI build.</simpara>
<simpara>CloudBees <ulink url="http://developer.cloudbees.com/bin/view/DEV/GitHub+Commit+Hooks+HOWTO">documents this process</ulink>, and we&#8217;ll follow along these guidelines.</simpara>
<simpara>First we must log into the CloudBees Jenkins home and select the "GitHub" plugin for installation at the <literal>Manage Jenkins</literal> &gt; <literal>Manage Plugins</literal> screen.  Jenkins will download and install the plugin, then reboot the instance.  Then we may go to <literal>Manage Jenkins</literal> &gt; <literal>Configure System</literal> and select "Manually manage hook URLs" under the "GitHub Web Hook" setting.  Save and exit the screen.</simpara>
<simpara>With our Jenkins instance configured, now we should enable GitHub triggers in our build job configuration.  Check the box "Build when a change is pushed to GitHub" under "Build Triggers" on the build configuration page, then save.</simpara>
<simpara>That will handle the CloudBees Jenkins side of the integration.</simpara>
<simpara>In GitHub, we may now visit our repository&#8217;s home, and select <literal>Settings</literal> &gt; <literal>Service Hooks</literal> &gt; <literal>WebHook URLs</literal>.  Add a URL with the format <literal>https://<emphasis>domainId</emphasis>.ci.cloudbees.com/github-webhook</literal>.  This will instruct GitHub to send an HTTP POST request to CloudBees containing information about the new push, and CloudBees will take it from there.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/github_webhook_urls.png"/>
  </imageobject>
  <textobject><phrase>GitHub WebHook URLs</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>From here on out, new commits pushed to the GitHub repository will trigger a build on the CloudBees Jenkins instance.  In this way we can nicely create a pipeline of build-related actions, triggered easily by our committing new work upstream.</simpara>
<simpara>Note that this is simply one mechanism of chaining together actions from a git push, and it relies on the GitHub and CloudBees services specifically.  Of course, there are many other custom and thirdparty services available, and the choice will ultimately be yours based upon your needs.  This configuration is offered merely to prove the concept and provide a base implementation (and also it drives the software examples for this book).</simpara>
</section>
</section>
<section id="_pushing_to_staging_and_production">
<title>Pushing to Staging and Production</title>
<simpara>With a working build to validate our tests and assemble the final deployable unit(s), we&#8217;re now free to push our application out to a publicly-accessible runtime.  In most cases, we&#8217;d like to first target a staging server that may be accessed only by members of our team before going public, but the choice for that extra stage is left to the reader&#8217;s discretion.  For the purposes of our <emphasis>GeekSeek</emphasis> application, we&#8217;ll allow commits that pass the testsuite to go straight to the public WWW on OpenShift.</simpara>
<section id="_setting_up_the_openshift_application">
<title>Setting Up the OpenShift Application</title>
<simpara>First, let&#8217;s create our new application by logging into OpenShift and selecting <literal>Add Application</literal>:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/button_add_application.png"/>
  </imageobject>
  <textobject><phrase>Add Application</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>As EAP will be our target runtime, we&#8217;ll select the "JBoss Enterprise Application Platform 6.0" cartridge, a pre-built environment for applications targeting EAP.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/cartridge_selection_jboss-eap.png"/>
  </imageobject>
  <textobject><phrase>JBoss EAP Cartridge</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Next we&#8217;ll assign our application with a name unique to our account&#8217;s domain.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/new_app_name.png"/>
  </imageobject>
  <textobject><phrase>New App Name</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>And when we&#8217;ve reviewed the configuration, hitting "Create Application" will instruct OpenShift to provision a new namespace and backing infrastructure for our application.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/button_create_application.png"/>
  </imageobject>
  <textobject><phrase>Create Application</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>When the process is completed, a default landing page will be accessible to us (and anyone in the world) from the browser.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/welcome_to_openshift.png"/>
  </imageobject>
  <textobject><phrase>Welcome to OpenShift</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>The default DNS record will be in format <literal>http://<emphasis>appName</emphasis>-<emphasis>domainId</emphasis>.rhcloud.com</literal>.  It&#8217;s likely that this isn&#8217;t really the name we desire for public consumption, so let&#8217;s add our own custom DNS name.</simpara>
<simpara>This is a two step process:</simpara>
<simpara>1) Create a DNS entry with your domain registrar or DNS Management interface to point to <literal>http://<emphasis>appName</emphasis>-<emphasis>domainId</emphasis>.rhcloud.com</literal>.  In our case, we&#8217;ll opt for a subdomain, which amounts to a <literal>CNAME</literal> record.  Consult your domain authority for the specifics of this step, but generally you might be presented with a screen that looks similar to:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/cname_add.png"/>
  </imageobject>
  <textobject><phrase>Add CNAME</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>2) Add an "alias" in your OpenShift application&#8217;s configuration.  This may be done via the web interface:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/alias_add.png"/>
  </imageobject>
  <textobject><phrase>Add Alias</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Alternatively, you may acquire the <ulink url="https://www.openshift.com/developers/rhc-client-tools-install">OpenShift client-side command-line tools</ulink>.  These rely on a Ruby installation of 1.8.7 or greater on your system, and are obtained by installing a Ruby gem:</simpara>
<screen>$&gt; sudo gem install rhc</screen>
<simpara>Once the gem is installed, you may add the domain record to OpenShift using the command <literal>rhc alias add <emphasis>appName</emphasis> <emphasis>alias</emphasis> -l <emphasis>username</emphasis></literal>, for instance:</simpara>
<screen>$&gt; $ rhc alias add geekseek geekseek.continuousdev.org -l admin@continuousdev.org
Password: *****************

Alias 'geekseek.continuousdev.org' has been added.</screen>
<simpara>Assuming the CNAME is properly set up with your domain registrar, the record has percolated through the network&#8217;s DNS tree (which may or may not take some time), and the alias is set up correctly, your application should now be available directly at the provided alias.  In our case, this is <literal>http://geekseek.continuousdev.org/</literal>.</simpara>
</section>
<section id="_removing_the_default_openshift_application">
<title>Removing the Default OpenShift Application</title>
<simpara>Now let&#8217;s clear the way for our real application.  First we&#8217;ll clone the OpenShift application repository into our local workspace.  The Git URL for your application is displayed on the application&#8217;s status screen on your OpenShift account.  The <literal>git clone</literal> command will look a little like this:</simpara>
<screen>$&gt; git clone ssh://(somehash))@geekseek-continuousdev.rhcloud.com/~/git/geekseek.git/
Cloning into 'geekseek'...
The authenticity of host 'geekseek-continuousdev.rhcloud.com (72.44.62.62)' can't be established.
RSA key fingerprint is cf:ee:77:cb:0e:fc:02:d7:72:7e:ae:80:c0:90:88:a7.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'geekseek-continuousdev.rhcloud.com,72.44.62.62' (RSA) to the list of known hosts.
remote: Counting objects: 39, done.
remote: Compressing objects: 100% (31/31), done.
remote: Total 39 (delta 1), reused 0 (delta 0)
Receiving objects: 100% (39/39), 19.98 KiB, done.
Resolving deltas: 100% (1/1), done.</screen>
<simpara>Now we have a full copy of the OpenShift application&#8217;s repository on our local disk.  Because we don&#8217;t need the default landing page shown in the screenshot above, we can safely remove it.  This is easily enough done by <literal>cd</literal>-ing into our repository directory, removing the files in question with <literal>git rm</literal>, committing the changes, and then pushing the commit to the remote OpenShift repository.</simpara>
<screen>$&gt; cd geekseek
geekseek $&gt;  git rm -rf pom.xml src/
rm 'pom.xml'
rm 'src/main/java/.gitkeep'
rm 'src/main/resources/.gitkeep'
rm 'src/main/webapp/WEB-INF/web.xml'
rm 'src/main/webapp/images/jbosscorp_logo.png'
rm 'src/main/webapp/index.html'
rm 'src/main/webapp/snoop.jsp'
geekseek $&gt; git commit -m 'Remove OpenShift default application structure'
geekseek $&gt; git push origin master</screen>
<simpara>When the <literal>git push</literal> command concludes and the remote build is complete, reloading our application in the web browser should now yield us a blank page, as we&#8217;ve deleted the only content in the OpenShift repo.  We&#8217;ll replace that with fresh content from our CI builds.</simpara>
</section>
<section id="_pushing_from_the_ci_build_job_to_openshift">
<title>Pushing From the CI Build Job to OpenShift</title>
<simpara>The final piece of the automated deployment puzzle lies in deploying artifacts built from our CI server into our runtime environment.  In our case, this amounts to configuring the CloudBees Jenkins instance to perform some Git operations against our OpenShift repository.</simpara>
<simpara>We&#8217;ll need to allow access for CloudBees Jenkins to interact with the OpenShift repository.  On the "Configure" screen for our CI job is a section entitled "CloudBees <ulink url="mailto:DEV@Cloud">DEV@Cloud</ulink> Authorization", which contains our public key.  Copy this to your OS&#8217;s clipboard.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/cloudbees_ssh.png"/>
  </imageobject>
  <textobject><phrase>CloudBees SSH Public Key</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Then log into your OpenShift Management Console and select <ulink url="https://openshift.redhat.com/app/console/settings">Settings</ulink>; there will be a dialog to manage the public keys allowed access to our repository.  Add the CloudBees Jenkins key by pasting it here.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/openshift_public_keys.png"/>
  </imageobject>
  <textobject><phrase>OpenShift Public Keys</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>Switching back to our Jenkins job configuration screen, towards the bottom is a section where we may add "Post Build" steps.  Let&#8217;s create a shell-based action which will be set to execute only upon successful build.</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/ch11-assembly_deployment/cloudbees_post_build.png"/>
  </imageobject>
  <textobject><phrase>CloudBees Post Build</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>The following script will handle the task for us.</simpara>
<screen>if [ -d geekseek ]; then
  cd geekseek
  if [ -f deployments/ROOT.war ]; then
    rm -rf deployments/ROOT.war
  fi
  git pull origin master
else
  git clone ssh://51abd6c84382ec5c160002e2@geekseek-continuousdev.rhcloud.com/~/git/geekseek.git/
  cd geekseek
fi

cp $WORKSPACE/code/application/application/target/*.war deployments/ROOT.war
touch deployments/ROOT.WAR.dodeploy
git add -Av
COMMIT_MESSAGE='Updated application from '
COMMIT_MESSAGE=$COMMIT_MESSAGE$BUILD_URL
git commit -m "$COMMIT_MESSAGE"
git push origin master</screen>
<simpara>Let&#8217;s see what&#8217;s going on here.  First we have some bash logic to either clone the remote OpenShift repository if this node hasn&#8217;t already, or update the existing copy.  Then we copy the final deployable web application WAR into the <literal>deployments</literal> directory of the repository, renaming it to <literal>ROOT.war</literal> so that this acts as our application servicing requests from the web root.  Also, we&#8217;ll add or update an empty <literal>ROOT.war.dodeploy</literal> file to let OpenShift know that we want this application deployed when it&#8217;s discovered (full documentation on this feature is <ulink url="https://access.redhat.com/site/documentation/en-US/OpenShift/2.0/html/User_Guide/sect-OpenShift-User_Guide-Deploying_JBoss_Applications-Example_JBoss_Application_Deployment_Workflows.html">available on the OpenShift site</ulink>).  Finally, we add our changes to be staged for commit, perform the commit, and then push the changes to our remote OpenShift repository.</simpara>
<simpara>As we&#8217;ve seen before, OpenShift will dutifully exercise the remote operations to redeploy our application and make it available for our use.</simpara>
<simpara>Using the OpenShift client command-line tools, we can tail the server logs for the application to monitor status:</simpara>
<screen>$&gt; rhc tail {openshift_appname} -l {openshift_username}</screen>
<simpara>If we look closely, we&#8217;ll see that the application has deployed, and is ready for use!</simpara>
<screen>2013/06/04 05:38:52,413 INFO  [org.jboss.as.server]
  (ServerService Thread Pool -- 36) JBAS018559:
  Deployed "ROOT.war" (runtime-name : "ROOT.war")</screen>
</section>
</section>
</section>
</article>
